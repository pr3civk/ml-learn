{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a86b868",
   "metadata": {},
   "source": [
    "# Kluczowe pojÄ™cia i krÃ³tkie opisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1efa3c",
   "metadata": {},
   "source": [
    "- **Machine Learning** â€“ dziedzina nauki dajÄ…ca komputerom moÅ¼liwoÅ›Ä‡ uczenia siÄ™ bez koniecznoÅ›ci ich jawnego programowania.  \n",
    "\n",
    "- **Training Set (dane uczÄ…ce)** â€“ przykÅ‚adowe dane uÅ¼ywane do trenowania modelu, skÅ‚adajÄ…ce siÄ™ z prÃ³bek (sample).  \n",
    "\n",
    "- **Accuracy** â€“ konkretna miara wydajnoÅ›ci modelu, czÄ™sto stosowana w zadaniach klasyfikacyjnych.  \n",
    "\n",
    "- **Data Mining** â€“ analizowanie zbioru danych w celu poszukiwania ukrytych wzorcÃ³w.  \n",
    "\n",
    "- **NLP (Natural Language Processing)** â€“ przetwarzanie jÄ™zyka naturalnego; dziedzina AI zajmujÄ…ca siÄ™ analizÄ…, rozumieniem i generowaniem ludzkiego jÄ™zyka przez komputery.  \n",
    "\n",
    "- **RNN (Recurrent Neural Network)** â€“ rekurencyjna sieÄ‡ neuronowa; sieÄ‡ przetwarzajÄ…ca dane sekwencyjne (np. tekst, dÅºwiÄ™k) poprzez zapamiÄ™tywanie wczeÅ›niejszych stanÃ³w.  \n",
    "\n",
    "- **CNN (Convolutional Neural Network)** â€“ konwolucyjna sieÄ‡ neuronowa; model szczegÃ³lnie skuteczny w rozpoznawaniu obrazÃ³w dziÄ™ki operacjom splotu.  \n",
    "\n",
    "- **NLU (Natural Language Understanding)** â€“ rozumienie jÄ™zyka naturalnego; poddziedzina NLP skupiajÄ…ca siÄ™ na interpretacji znaczenia wypowiedzi.  \n",
    "\n",
    "- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** â€“ algorytm grupowania na podstawie gÄ™stoÅ›ci punktÃ³w; wykrywa skupiska danych i odrzuca szum.  \n",
    "\n",
    "- **MNIST (Modified National Institute of Standards and Technology dataset)** â€“ popularny zbiÃ³r danych zawierajÄ…cy rÄ™cznie pisane cyfry, uÅ¼ywany do trenowania i testowania modeli ML.  \n",
    "\n",
    "- **Transformator (Transformer)** â€“ architektura sieci neuronowych oparta na mechanizmie uwagi (attention); podstawa modeli jÄ™zykowych, takich jak GPT czy BERT.  \n",
    "\n",
    "- **Redukcja wymiarowoÅ›ci (Dimensionality Reduction)** â€“ proces upraszczania danych przez zmniejszenie liczby cech przy zachowaniu najwaÅ¼niejszych informacji.  \n",
    "\n",
    "- **Splot (Convolution)** â€“ operacja matematyczna w CNN, ktÃ³ra wyÅ‚apuje lokalne wzorce w danych (np. krawÄ™dzie na obrazie).  \n",
    "\n",
    "- **Regresja liniowa (Linear Regression)** â€“ metoda przewidywania wartoÅ›ci ciÄ…gÅ‚ych poprzez dopasowanie prostej linii do danych.  \n",
    "\n",
    "- **Regresja wielomianowa (Polynomial Regression)** â€“ rozszerzenie regresji liniowej, w ktÃ³rej zaleÅ¼noÅ›Ä‡ miÄ™dzy zmiennymi jest opisana wielomianem.  \n",
    "\n",
    "- **Random Forest Regression (Regresja lasu losowego)** â€“ metoda oparta na wielu drzewach decyzyjnych, uÅ›redniajÄ…ca ich wyniki w celu zwiÄ™kszenia dokÅ‚adnoÅ›ci.  \n",
    "\n",
    "- **Decision Tree** to model uczenia maszynowego uÅ¼ywany zarÃ³wno w **klasyfikacji**, jak i **regresji**.  DziaÅ‚a podobnie do procesu podejmowania decyzji przez czÅ‚owieka â€” zadaje kolejne pytania, aÅ¼ dojdzie do odpowiedzi.\n",
    "\n",
    "- **SVM (Support Vector Machine)** â€“ maszyna wektorÃ³w noÅ›nych; algorytm klasyfikacji i regresji, ktÃ³ry znajduje granicÄ™ maksymalnie oddzielajÄ…cÄ… klasy.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251c5f",
   "metadata": {},
   "source": [
    "# Wykorzystanie ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd1ff0",
   "metadata": {},
   "source": [
    "- Problemy, ktore wymagaja czestego dostrajania algorytmu lub korzystanie z dlugich list regul.\n",
    "\n",
    "- Zlozonoe problemy, ktorych nie da sie rozwiazac tradycyjnymi metodami\n",
    "\n",
    "- Zmiennych srodowisk ( `model ml` moze sie dostosowac szybko do nowych danych i byc aktualizowany z latwoscia w dowolnym momencie )\n",
    "\n",
    "- Do analizy ogromnej ilosci danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1b538",
   "metadata": {},
   "source": [
    "# Rodzaje systemÃ³w ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bb40a",
   "metadata": {},
   "source": [
    "- **Nadzorowanie w fazie uczenia** - (uczenie nadzorowane, nienadzorowane, pÃ³Å‚nadzorowane, samonadzorowane, wzmocnienie itd.)\n",
    "\n",
    "- **Uczenie siÄ™ w czasie rzeczywistym** - (u. przyrostowe, wsadowe)\n",
    "\n",
    "- **SposÃ³b pracy** - proste porÃ³wnanie nowych punktÃ³w danychze znanymi punktami, lub wykrywanie wzorcÃ³w w `training set` i tworzenie modelu predykcyjnego \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2a8ec",
   "metadata": {},
   "source": [
    "## Uczenie nadzorowane (Supervised Learning)\n",
    "\n",
    "#### Etykieta (Label) i Cel (Target)\n",
    "\n",
    "- **Etykieta (Label)** â€“ to **prawidÅ‚owa odpowiedÅº** w danych uczÄ…cych, ktÃ³rej model uÅ¼ywa do nauki.  \n",
    "- **Cel (Target)** â€“ to **wartoÅ›Ä‡, ktÃ³rÄ… model ma przewidzieÄ‡** podczas dziaÅ‚ania na nowych danych.  \n",
    "W praktyce oba pojÄ™cia czÄ™sto oznaczajÄ… to samo â€“ wynik, do ktÃ³rego model dÄ…Å¼y.\n",
    "\n",
    "#### ğŸ”¹ PrzykÅ‚ad:\n",
    "\n",
    "| Powierzchnia (mÂ²) | Liczba pokoi | Lokalizacja | **Cena (etykieta / target)** |\n",
    "|--------------------|--------------|--------------|------------------------------|\n",
    "| 60                 | 3            | Centrum      | 520 000 zÅ‚                   |\n",
    "\n",
    "â¡ï¸ **Cechy (features):** powierzchnia, liczba pokoi, lokalizacja  \n",
    "â¡ï¸ **Etykieta / Cel:** czy email jest spamem czy nie -> SPAM / NOT SPAM\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Uczenie nadzorowane to rodzaj uczenia maszynowego, w ktÃ³rym model uczy siÄ™ na podstawie **danych oznaczonych (z etykietami)**.  \n",
    "KaÅ¼dy przykÅ‚ad w danych zawiera:\n",
    "- **wejÅ›cie/cechy (features)** â€“ czyli dane wejÅ›ciowe, np. liczba pokoi, lokalizacja, temperatura, sÅ‚owa w zdaniu,  \n",
    "- **wyjÅ›cie (label lub target value)** â€“ czyli oczekiwany wynik, np. cena domu, gatunek kwiatu, klasa obrazu.  \n",
    "\n",
    "Celem jest nauczenie modelu zaleÅ¼noÅ›ci miÄ™dzy wejÅ›ciem a wyjÅ›ciem, tak aby mÃ³gÅ‚ **przewidywaÄ‡ etykiety (lub wartoÅ›ci)** dla nowych, nieznanych danych.  \n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Regresja (Regression)\n",
    "\n",
    "Regresja to typ uczenia nadzorowanego, w ktÃ³rym celem jest **przewidywanie wartoÅ›ci liczbowych (ciÄ…gÅ‚ych)** â€” tzw. **wartoÅ›ci docelowej (target value)**.  \n",
    "Model stara siÄ™ znaleÅºÄ‡ zaleÅ¼noÅ›Ä‡ matematycznÄ… miÄ™dzy cechami (features) a wartoÅ›ciÄ…, ktÃ³rÄ… chcemy przewidzieÄ‡.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model analizuje dane wejÅ›ciowe i dopasowuje funkcjÄ™ (np. prostÄ… lub krzywÄ…), ktÃ³ra najlepiej opisuje zaleÅ¼noÅ›Ä‡ miÄ™dzy zmiennymi.  \n",
    "Podczas treningu minimalizuje rÃ³Å¼nicÄ™ miÄ™dzy przewidywanÄ… a rzeczywistÄ… wartoÅ›ciÄ… (np. za pomocÄ… bÅ‚Ä™du MSE â€“ Mean Squared Error).\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Prognozowanie cen nieruchomoÅ›ci** na podstawie powierzchni, lokalizacji i liczby pokoi.  \n",
    "- **Przewidywanie zuÅ¼ycia energii** lub wody w budynkach.  \n",
    "- **Szacowanie przyszÅ‚ej sprzedaÅ¼y** produktÃ³w lub przychodÃ³w firmy.  \n",
    "- **Prognozowanie pogody** â€“ np. temperatury lub opadÃ³w.  \n",
    "- **Przewidywanie kursÃ³w akcji lub kryptowalut** w czasie.  \n",
    "- **Modelowanie wzrostu populacji** lub trendÃ³w gospodarczych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Regresja liniowa (Linear Regression)  \n",
    "- Regresja wielomianowa (Polynomial Regression)  \n",
    "- Random Forest Regression  \n",
    "- Support Vector Regression (SVR)  \n",
    "- Sieci neuronowe (Neural Networks)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Klasyfikacja (Classification)\n",
    "\n",
    "Klasyfikacja to rodzaj uczenia nadzorowanego, w ktÃ³rym celem jest **przypisanie danych do jednej lub wielu kategorii (klas)**.  \n",
    "Model nie przewiduje liczby, lecz **etykietÄ™** â€” np. â€kotâ€ / â€piesâ€, â€spamâ€ / â€nie spamâ€.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model uczy siÄ™ rozrÃ³Å¼niaÄ‡ wzorce w danych, tak aby dla nowych przykÅ‚adÃ³w mÃ³gÅ‚ zdecydowaÄ‡, do ktÃ³rej klasy naleÅ¼Ä….  \n",
    "Podczas uczenia minimalizuje liczbÄ™ bÅ‚Ä™dnych przypisaÅ„ (np. za pomocÄ… funkcji strat cross-entropy).\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Filtracja spamu** â€“ rozpoznawanie, czy e-mail to spam czy wiadomoÅ›Ä‡ prawidÅ‚owa.  \n",
    "- **Rozpoznawanie obrazÃ³w** â€“ np. identyfikacja obiektÃ³w (samochÃ³d, czÅ‚owiek, drzewo).  \n",
    "- **Diagnostyka medyczna** â€“ klasyfikacja, czy pacjent ma danÄ… chorobÄ™ na podstawie wynikÃ³w badaÅ„.  \n",
    "- **Analiza nastrojÃ³w (sentiment analysis)** â€“ okreÅ›lenie, czy opinia jest pozytywna, neutralna, czy negatywna.  \n",
    "- **Wykrywanie oszustw finansowych** â€“ klasyfikacja transakcji jako prawdziwe lub podejrzane.  \n",
    "- **Rozpoznawanie mowy lub tekstu** â€“ np. komendy gÅ‚osowe lub analiza jÄ™zyka naturalnego.  \n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Logistic Regression  \n",
    "- Decision Tree  \n",
    "- Random Forest  \n",
    "- k-NN (k-Nearest Neighbors)  \n",
    "- SVM (Support Vector Machine)  \n",
    "- Naive Bayes  \n",
    "- Sieci neuronowe (CNN, RNN)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu:\n",
    "1. **Przygotowanie danych** â€“ zebranie i oznaczenie danych (features + labels).  \n",
    "2. **PodziaÅ‚ danych** â€“ na zbiÃ³r uczÄ…cy (*training set*) i testowy (*test set*).  \n",
    "3. **Trenowanie modelu** â€“ model uczy siÄ™ zaleÅ¼noÅ›ci miÄ™dzy wejÅ›ciami a wyjÅ›ciami.  \n",
    "4. **Walidacja i testowanie** â€“ sprawdzenie, jak dobrze model dziaÅ‚a na nowych danych.  \n",
    "5. **Ewaluacja wynikÃ³w** â€“ np. przy uÅ¼yciu metryk: *accuracy, precision, recall, MSE, RÂ²*.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- Systemy rekomendacji (Netflix, Amazon, Spotify).  \n",
    "- Asystenci gÅ‚osowi (rozumienie mowy i komend).  \n",
    "- Systemy wykrywania oszustw bankowych.  \n",
    "- Ocena ryzyka kredytowego i scoring klientÃ³w.  \n",
    "- Wykrywanie defektÃ³w w produkcji przemysÅ‚owej.  \n",
    "- Automatyczne rozpoznawanie obrazu w kamerach bezpieczeÅ„stwa.  \n",
    "- Prognozowanie cen, popytu, trendÃ³w i sprzedaÅ¼y.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55efe9",
   "metadata": {},
   "source": [
    "## Uczenie nienadzorowane (Unsupervised Learning)\n",
    "\n",
    "Uczenie nienadzorowane to rodzaj uczenia maszynowego, w ktÃ³rym model uczy siÄ™ na podstawie **danych nieoznaczonych (bez etykiet)**.  \n",
    "Celem jest odkrywanie ukrytych wzorcÃ³w, struktur i zaleÅ¼noÅ›ci w danych wejÅ›ciowych, bez wczeÅ›niejszego informowania modelu, jakie sÄ… â€prawidÅ‚oweâ€ odpowiedzi. Model samodzielnie grupuje, redukuje lub identyfikuje anomalie.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Klastrowanie / Analiza SkupieÅ„ (Clustering)\n",
    "\n",
    "Klastrowanie, czÄ™sto nazywane **AnalizÄ… SkupieÅ„**, to typ uczenia nienadzorowanego, w ktÃ³rym celem jest **grupowanie podobnych punktÃ³w danych w klastry (grupy)**.  \n",
    "Model samodzielnie identyfikuje wewnÄ™trzne struktury w danych, tak aby punkty w tym samym klastrze byÅ‚y do siebie podobne (wysoka spÃ³jnoÅ›Ä‡ wewnÄ…trzklastrowa), a punkty z rÃ³Å¼nych klastrÃ³w â€“ jak najbardziej rÃ³Å¼ne (niska spÃ³jnoÅ›Ä‡ miÄ™dzyklastrowa).\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Algorytmy klastrowania analizujÄ… cechy danych i na podstawie ich podobieÅ„stwa (czÄ™sto mierzonego odlegÅ‚oÅ›ciÄ… w przestrzeni cech, np. odlegÅ‚oÅ›ciÄ… euklidesowÄ…) przypisujÄ… je do grup. Nie potrzebujÄ… z gÃ³ry okreÅ›lonych kategorii czy etykiet. Liczba klastrÃ³w moÅ¼e byÄ‡ z gÃ³ry narzucona (np. K-Means) lub odkryta przez algorytm (np. DBSCAN).\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Segmentacja klientÃ³w** â€“ grupowanie klientÃ³w na podstawie zachowaÅ„ zakupowych, danych demograficznych, historii przeglÄ…dania. Pozwala to firmom na tworzenie spersonalizowanych kampanii marketingowych i strategii produktowych.\n",
    "- **Analiza danych genetycznych i medycznych** â€“ grupowanie genÃ³w, prÃ³bek DNA, komÃ³rek lub pacjentÃ³w, aby odkryÄ‡ podobieÅ„stwa i rÃ³Å¼nice, ktÃ³re mogÄ… wskazywaÄ‡ na wspÃ³lne cechy, podtypy chorÃ³b lub reakcje na leczenie.\n",
    "- **Organizacja i eksploracja dokumentÃ³w lub artykuÅ‚Ã³w** â€“ automatyczne grupowanie tekstÃ³w o podobnej tematyce bez ich wczeÅ›niejszego tagowania. UÅ‚atwia to wyszukiwanie, przeglÄ…danie i odkrywanie nowych tematÃ³w w duÅ¼ych zbiorach danych tekstowych.\n",
    "- **Detekcja miast w danych geograficznych** â€“ grupowanie punktÃ³w danych lokalizacji (np. z GPS), aby zidentyfikowaÄ‡ obszary o wysokim zagÄ™szczeniu, co moÅ¼e odpowiadaÄ‡ miastom lub obszarom miejskim.\n",
    "- **Kompresja i segmentacja obrazÃ³w** â€“ grupowanie podobnych pikseli lub obszarÃ³w obrazu na podstawie koloru, tekstury czy jasnoÅ›ci, co moÅ¼e byÄ‡ wykorzystane do kompresji, analizy obiektÃ³w lub edycji obrazu.\n",
    "- **WstÄ™pna analiza danych** â€“ odkrywanie naturalnych grup w zbiorze danych, co moÅ¼e dostarczyÄ‡ cennych insightÃ³w przed zastosowaniem algorytmÃ³w nadzorowanych lub w celu lepszego zrozumienia danych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- K-Means\n",
    "- Hierarchical Clustering (klastrowanie hierarchiczne)\n",
    "- DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- Gaussian Mixture Models (GMM)\n",
    "- Agglomerative Clustering\n",
    "- Mean-Shift\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Redukcja WymiarowoÅ›ci (Dimensionality Reduction)\n",
    "\n",
    "Redukcja wymiarowoÅ›ci to typ uczenia nienadzorowanego, ktÃ³ry ma na celu **zmniejszenie liczby cech (zmiennych) w zbiorze danych**, jednoczeÅ›nie zachowujÄ…c jak najwiÄ™cej istotnych informacji.  \n",
    "Pomaga to w wizualizacji danych, usuwaniu szumu, kompresji danych i przyspieszaniu pracy innych algorytmÃ³w.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model znajduje sposoby na reprezentowanie danych w przestrzeni o niÅ¼szej liczbie wymiarÃ³w, tworzÄ…c nowe, syntetyczne cechy (tzw. komponenty lub embeddingi), ktÃ³re sÄ… kombinacjÄ… oryginalnych cech. Metody te mogÄ… byÄ‡ liniowe (np. PCA) lub nieliniowe (np. t-SNE, UMAP), zdolne do wykrywania bardziej zÅ‚oÅ¼onych struktur.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Wizualizacja danych wielowymiarowych** â€“ przeksztaÅ‚cenie danych z setek czy tysiÄ™cy wymiarÃ³w do 2 lub 3 wymiarÃ³w, aby mÃ³c je wykreÅ›liÄ‡ i zrozumieÄ‡ strukturÄ™, dostrzec klastry lub anomalie. Jest to kluczowy krok w eksploracyjnej analizie danych.\n",
    "- **Kompresja obrazÃ³w i dÅºwiÄ™ku** â€“ redukcja liczby pikseli, kanaÅ‚Ã³w kolorÃ³w lub prÃ³bek sygnaÅ‚u przy zachowaniu akceptowalnej jakoÅ›ci wizualnej/sÅ‚uchowej, co zmniejsza wymagania dotyczÄ…ce przechowywania i przesyÅ‚ania danych.\n",
    "- **Przygotowanie danych do uczenia nadzorowanego** â€“ zmniejszenie liczby cech wejÅ›ciowych dla klasyfikatorÃ³w lub regresorÃ³w, aby zapobiec nadmiernemu dopasowaniu (overfitting), zmniejszyÄ‡ zÅ‚oÅ¼onoÅ›Ä‡ obliczeniowÄ… i poprawiÄ‡ generalizacjÄ™ modelu.\n",
    "- **Redukcja szumu (denoising)** â€“ usuniÄ™cie zbÄ™dnych, redundantnych lub maÅ‚o istotnych cech, ktÃ³re mogÄ… wprowadzaÄ‡ szum do modelu i pogarszaÄ‡ jego wydajnoÅ›Ä‡.\n",
    "- **Uczenie embeddingÃ³w** â€“ tworzenie niskowymiarowych, gÄ™stych reprezentacji (wektorÃ³w) dla zÅ‚oÅ¼onych obiektÃ³w, takich jak sÅ‚owa (word embeddings), obrazy czy uÅ¼ytkownicy, ktÃ³re zachowujÄ… semantyczne lub strukturalne relacje.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- PCA (Principal Component Analysis â€“ Analiza SkÅ‚adowych GÅ‚Ã³wnych)\n",
    "- t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "- UMAP (Uniform Manifold Approximation and Projection)\n",
    "- Autoenkodery (Autoencoders â€“ w sieciach neuronowych)\n",
    "- NMF (Non-negative Matrix Factorization)\n",
    "- LLE (Locally Linear Embedding)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Wizualizacja (Visualization)\n",
    "\n",
    "Wizualizacja danych w kontekÅ›cie uczenia nienadzorowanego to proces **graficznego przedstawiania zÅ‚oÅ¼onych danych**, aby uÅ‚atwiÄ‡ zrozumienie ich struktury, wzorcÃ³w, klastrÃ³w, anomalii i relacji miÄ™dzy cechami, czÄ™sto po przeprowadzeniu redukcji wymiarowoÅ›ci. ChoÄ‡ nie jest to algorytm uczenia maszynowego per se, jest to nieodzowne narzÄ™dzie do interpretacji wynikÃ³w nienadzorowanych modeli.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Wykorzystuje siÄ™ rÃ³Å¼ne techniki graficzne (wykresy punktowe, mapy cieplne, dendrogramy, wykresy 3D) do przedstawienia danych w sposÃ³b, ktÃ³ry jest Å‚atwy do odbioru przez czÅ‚owieka. CzÄ™sto wizualizacja jest efektem zastosowania metod redukcji wymiarowoÅ›ci, ktÃ³re transformujÄ… dane do 2 lub 3 wymiarÃ³w, umoÅ¼liwiajÄ…c ich wykreÅ›lenie.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Wizualizacja klastrÃ³w** â€“ przedstawienie punktÃ³w danych w 2D/3D, gdzie punkty naleÅ¼Ä…ce do tego samego klastra sÄ… oznaczone tym samym kolorem lub ksztaÅ‚tem. Pozwala to na ocenÄ™ jakoÅ›ci klastrowania i zrozumienie, jakie cechy charakteryzujÄ… poszczegÃ³lne grupy.\n",
    "- **Odkrywanie anomalii** â€“ punkty danych, ktÃ³re sÄ… wizualnie odseparowane od gÅ‚Ã³wnych skupisk, mogÄ… wskazywaÄ‡ na anomalie.\n",
    "- **Eksploracja danych** â€“ szybkie dostrzeÅ¼enie relacji miÄ™dzy zmiennymi, wykrycie brakujÄ…cych danych, obserwacja rozkÅ‚adÃ³w cech czy identyfikacja korelacji.\n",
    "- **Ocena jakoÅ›ci redukcji wymiarowoÅ›ci** â€“ sprawdzenie, czy metoda redukcji wymiarowoÅ›ci skutecznie zachowaÅ‚a strukturÄ™ danych, np. czy klastry sÄ… nadal dobrze rozdzielone po projekcji na niÅ¼sze wymiary.\n",
    "- **Komunikacja wynikÃ³w** â€“ prezentowanie zÅ‚oÅ¼onych analiz szerszej publicznoÅ›ci w przystÄ™pny i intuicyjny sposÃ³b.\n",
    "\n",
    "#### Popularne techniki i narzÄ™dzia:\n",
    "- Wykresy punktowe (Scatter Plots)\n",
    "- Macierze wykresÃ³w punktowych (Scatter Plot Matrices)\n",
    "- Wykresy 3D\n",
    "- Mapy cieplne (Heatmaps)\n",
    "- Dendrogramy (dla klastrowania hierarchicznego)\n",
    "- Wykresy radarowe\n",
    "- Biblioteki Python: Matplotlib, Seaborn, Plotly, Altair\n",
    "- NarzÄ™dzia: Tableau, Power BI, Qlik Sense\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Wykrywanie Anomalii (Anomaly Detection)\n",
    "\n",
    "Wykrywanie anomalii to typ uczenia nienadzorowanego, ktÃ³ry ma na celu **identyfikacjÄ™ punktÃ³w danych, ktÃ³re znacznie odbiegajÄ… od wiÄ™kszoÅ›ci danych** (tzw. odstÄ™pstw lub outlierÃ³w).  \n",
    "Anomalie czÄ™sto wskazujÄ… na nietypowe, interesujÄ…ce lub problematyczne zdarzenia.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model uczy siÄ™ \"normalnego\" wzorca danych, a nastÄ™pnie identyfikuje punkty, ktÃ³re sÄ… na tyle rÃ³Å¼ne od tego wzorca, Å¼e moÅ¼na je uznaÄ‡ za anomalie. Nie potrzebuje wczeÅ›niejszych etykiet anomalii (choÄ‡ moÅ¼e byÄ‡ wspierane przez nadzÃ³r). PodejÅ›cia obejmujÄ… metody statystyczne, oparte na gÄ™stoÅ›ci, odlegÅ‚oÅ›ci czy modelach uczenia maszynowego.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Wykrywanie oszustw finansowych** â€“ identyfikacja nietypowych transakcji kartÄ… kredytowÄ…, ktÃ³re mogÄ… wskazywaÄ‡ na oszustwo, lub podejrzanych roszczeÅ„ ubezpieczeniowych.\n",
    "- **Monitorowanie sieci komputerowych** â€“ wykrywanie nietypowego ruchu sieciowego, ktÃ³ry moÅ¼e sygnalizowaÄ‡ atak hakerski, zÅ‚oÅ›liwe oprogramowanie lub naruszenie bezpieczeÅ„stwa.\n",
    "- **Diagnostyka usterek maszyn i konserwacja predykcyjna** â€“ monitorowanie danych z sensorÃ³w maszyn (np. wibracje, temperatura, zuÅ¼ycie energii) w celu wykrycia nietypowych wzorcÃ³w wskazujÄ…cych na zbliÅ¼ajÄ…cÄ… siÄ™ awariÄ™ lub potrzebÄ™ serwisu.\n",
    "- **Kontrola jakoÅ›ci w produkcji przemysÅ‚owej** â€“ automatyczna identyfikacja produktÃ³w z wadami, ktÃ³re odbiegajÄ… od normy, na podstawie danych z kamer lub sensorÃ³w.\n",
    "- **Monitorowanie zdrowia pacjentÃ³w** â€“ wykrywanie nietypowych odczytÃ³w z urzÄ…dzeÅ„ medycznych (np. EKG, glukometr, smartwatche), ktÃ³re mogÄ… wskazywaÄ‡ na nagÅ‚y problem zdrowotny lub pogorszenie stanu.\n",
    "- **Analiza danych z sensorÃ³w IoT** â€“ wykrywanie nieprawidÅ‚owoÅ›ci w odczytach z czujnikÃ³w w inteligentnych domach, miastach czy rolnictwie, np. awarii sprzÄ™tu czy nietypowych warunkÃ³w Å›rodowiskowych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Isolation Forest\n",
    "- One-Class SVM (Support Vector Machine dla jednej klasy)\n",
    "- Local Outlier Factor (LOF)\n",
    "- DBSCAN (moÅ¼e byÄ‡ uÅ¼ywany do wykrywania punktÃ³w nieprzypisanych do klastrÃ³w)\n",
    "- Autoenkodery (wersje do wykrywania anomalii, gdzie duÅ¼y bÅ‚Ä…d rekonstrukcji wskazuje na anomaliÄ™)\n",
    "- K-Nearest Neighbors (k-NN) na podstawie odlegÅ‚oÅ›ci do sÄ…siadÃ³w\n",
    "- Statystyczne metody: 3-Sigma Rule, Box Plots\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie ReguÅ‚ Asocjacyjnych (Association Rule Learning)\n",
    "\n",
    "Uczenie reguÅ‚ asocjacyjnych to typ uczenia nienadzorowanego, ktÃ³ry ma na celu **odkrywanie interesujÄ…cych relacji i zaleÅ¼noÅ›ci miÄ™dzy zmiennymi w duÅ¼ych zbiorach danych**, czÄ™sto w kontekÅ›cie danych transakcyjnych.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model szuka czÄ™sto wystÄ™pujÄ…cych razem zestawÃ³w elementÃ³w (np. produktÃ³w w koszyku zakupowym) i na ich podstawie generuje reguÅ‚y typu \"JeÅ›li kupiono X, to prawdopodobnie kupiono teÅ¼ Y\". Mierzy siÄ™ wsparcie (support), ufnoÅ›Ä‡ (confidence) i lift, aby oceniÄ‡ istotnoÅ›Ä‡ tych reguÅ‚.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Analiza koszyka zakupowego (Market Basket Analysis)** â€“ identyfikacja produktÃ³w, ktÃ³re czÄ™sto sÄ… kupowane razem (np. \"Klienci, ktÃ³rzy kupujÄ… pieluchy, czÄ™sto kupujÄ… teÅ¼ piwo\", \"JeÅ›li klient kupi kawÄ™ i cukier, prawdopodobnie kupi teÅ¼ mleko\"). Pomaga to w ukÅ‚adaniu towarÃ³w w sklepach, ofertach promocyjnych, cross-sellingu czy rekomendacjach online.\n",
    "- **Optymalizacja ukÅ‚adu sklepu internetowego lub fizycznego** â€“ umieszczanie czÄ™sto kupowanych razem produktÃ³w w pobliÅ¼u siebie w celu zwiÄ™kszenia sprzedaÅ¼y.\n",
    "- **Systemy rekomendacji** â€“ sugerowanie produktÃ³w na podstawie tego, co inni klienci z podobnymi preferencjami kupili (np. \"CzÄ™sto kupowane razem z tym produktem\").\n",
    "- **Analiza danych medycznych** â€“ odkrywanie powiÄ…zaÅ„ miÄ™dzy objawami, diagnozami, wynikami badaÅ„ i lekami, ktÃ³re mogÄ… wspieraÄ‡ badania medyczne i decyzje kliniczne.\n",
    "- **ZarzÄ…dzanie zapasami** â€“ przewidywanie popytu na produkty komplementarne, aby zoptymalizowaÄ‡ stany magazynowe.\n",
    "- **Wykrywanie wzorcÃ³w w danych sekwencyjnych** â€“ znajdowanie czÄ™sto wystÄ™pujÄ…cych sekwencji zdarzeÅ„ lub czynnoÅ›ci (np. w logach systemowych).\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Apriori\n",
    "- FP-Growth (Frequent Pattern Growth)\n",
    "- ECLAT\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu nienadzorowanego:\n",
    "1. **Przygotowanie danych** â€“ zebranie, wstÄ™pne oczyszczenie i ewentualne przeksztaÅ‚cenie danych (bez etykiet).  \n",
    "2. **WybÃ³r algorytmu** â€“ w zaleÅ¼noÅ›ci od celu (klastrowanie, redukcja, anomalia, reguÅ‚y asocjacyjne).  \n",
    "3. **Trenowanie modelu** â€“ model samodzielnie odkrywa struktury i wzorce w danych.  \n",
    "4. **Ocena, interpretacja i wizualizacja wynikÃ³w** â€“ analiza odkrytych wzorcÃ³w (np. wizualizacja klastrÃ³w, analiza komponentÃ³w, identyfikacja anomalii, interpretacja reguÅ‚).  \n",
    "5. **Dostosowanie parametrÃ³w** â€“ iteracyjne poprawianie modelu i algorytmu w celu uzyskania optymalnych i sensownych wynikÃ³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- Segmentacja rynku i personalizacja ofert marketingowych.\n",
    "- Wizualizacja i eksploracja zÅ‚oÅ¼onych zbiorÃ³w danych dla lepszego zrozumienia.\n",
    "- Kompresja danych, optymalizacja przechowywania i przesyÅ‚ania.\n",
    "- Wykrywanie oszustw, bÅ‚Ä™dÃ³w, usterek i zagroÅ¼eÅ„ bezpieczeÅ„stwa.\n",
    "- Ulepszanie systemÃ³w rekomendacyjnych poprzez odkrywanie ukrytych powiÄ…zaÅ„.\n",
    "- Uczenie siÄ™ cech (feature learning) dla innych modeli nadzorowanych (jako pre-processing).\n",
    "- WstÄ™pne badanie danych i generowanie hipotez przed zastosowaniem bardziej zaawansowanych technik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57260d4",
   "metadata": {},
   "source": [
    "## Uczenie PÃ³Å‚-nadzorowane (Semi-supervised Learning)\n",
    "\n",
    "Uczenie pÃ³Å‚-nadzorowane to rodzaj uczenia maszynowego, ktÃ³ry Å‚Ä…czy w sobie elementy **uczenia nadzorowanego** i **nienadzorowanego**. Model uczy siÄ™ na podstawie **niewielkiej iloÅ›ci danych oznaczonych (z etykietami)** oraz **duÅ¼ej iloÅ›ci danych nieoznaczonych (bez etykiet)**.  \n",
    "Jest to szczegÃ³lnie przydatne w sytuacjach, gdy etykietowanie danych jest kosztowne, czasochÅ‚onne lub wymaga specjalistycznej wiedzy.\n",
    "\n",
    "#### Dlaczego Semi-supervised Learning?\n",
    "- **Ograniczone etykiety:** Wiele realnych problemÃ³w ma dostÄ™p do duÅ¼ej iloÅ›ci danych, ale tylko niewielka ich czÄ™Å›Ä‡ jest etykietowana.\n",
    "- **Wykorzystanie nieoznaczonych danych:** Dane nieoznaczone zawierajÄ… cenne informacje o strukturze rozkÅ‚adu danych, ktÃ³re mogÄ… pomÃ³c modelowi lepiej uogÃ³lniaÄ‡.\n",
    "- **Zmniejszenie kosztÃ³w:** Redukuje potrzebÄ™ rÄ™cznego etykietowania ogromnych zbiorÃ³w danych.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie oparte na spÃ³jnoÅ›ci (Consistency Regularization / Self-training)\n",
    "\n",
    "Uczenie oparte na spÃ³jnoÅ›ci to podejÅ›cie, w ktÃ³rym model jest trenowany tak, aby jego przewidywania dla danych nieoznaczonych byÅ‚y **spÃ³jne** nawet po niewielkich perturbacjach danych wejÅ›ciowych lub samego modelu. Self-training jest pokrewnÄ… technikÄ…, gdzie model \"etykietuje\" dane nieoznaczone.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "1.  **Self-training:** Model jest poczÄ…tkowo trenowany na maÅ‚ym zbiorze danych oznaczonych. NastÄ™pnie uÅ¼ywa siÄ™ go do przewidywania etykiet dla danych nieoznaczonych. Te \"pseudo-etykiety\" sÄ… dodawane do zbioru treningowego (czÄ™sto z wysokÄ… pewnoÅ›ciÄ…), a model jest ponownie trenowany. Proces moÅ¼e byÄ‡ iteracyjny.\n",
    "2.  **Consistency Regularization:** Model jest trenowany tak, aby jego wyjÅ›cia dla nieoznaczonych danych byÅ‚y podobne, nawet jeÅ›li te dane zostanÄ… lekko zmienione (np. dodanie szumu, drobne transformacje obrazu). Dodaje siÄ™ czÅ‚on regularyzacyjny do funkcji straty, ktÃ³ry karze za niespÃ³jne przewidywania.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Klasyfikacja obrazÃ³w z ograniczonymi etykietami** â€“ np. rozpoznawanie gatunkÃ³w zwierzÄ…t, gdzie mamy tylko kilka zdjÄ™Ä‡ z etykietami, ale tysiÄ…ce nieoznaczonych. Model uczy siÄ™ na etykietowanych, a nastÄ™pnie generuje pseudo-etykiety dla reszty.\n",
    "- **Analiza tekstu (NLP)** â€“ klasyfikacja sentymentu, wykrywanie spamu, gdzie dostÄ™pnych jest wiele nieoznaczonych tekstÃ³w, ale etykietowanie jest kosztowne.\n",
    "- **Rozpoznawanie mowy** â€“ poprawa dokÅ‚adnoÅ›ci modeli rozpoznawania mowy poprzez wykorzystanie duÅ¼ych zbiorÃ³w nieoznaczonych nagraÅ„ audio.\n",
    "- **Diagnostyka medyczna** â€“ wspomaganie klasyfikacji chorÃ³b na podstawie obrazÃ³w medycznych (np. MRI, RTG), gdzie etykietowanie wymaga ekspertÃ³w.\n",
    "- **Systemy rekomendacji** â€“ wykorzystanie nieoznaczonych danych o interakcjach uÅ¼ytkownikÃ³w do poprawy rekomendacji.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Pseudo-Labeling\n",
    "- Mean Teacher\n",
    "- Pi-Model\n",
    "- Temporal Ensembling\n",
    "- MixMatch, FixMatch (zaawansowane techniki consistency regularization)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie oparte na grafach (Graph-based Semi-supervised Learning)\n",
    "\n",
    "Uczenie oparte na grafach wykorzystuje strukturÄ™ grafu, gdzie punkty danych sÄ… wierzchoÅ‚kami, a krawÄ™dzie reprezentujÄ… podobieÅ„stwo miÄ™dzy nimi. Informacje z etykietowanych wierzchoÅ‚kÃ³w sÄ… \"rozprzestrzeniane\" na nieoznaczone wierzchoÅ‚ki wzdÅ‚uÅ¼ krawÄ™dzi grafu.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Tworzy siÄ™ graf, w ktÃ³rym kaÅ¼dy punkt danych jest wÄ™zÅ‚em. KrawÄ™dzie Å‚Ä…czÄ… podobne punkty danych, a ich wagi odzwierciedlajÄ… stopieÅ„ podobieÅ„stwa. Etykiety z nielicznych oznaczonych wÄ™zÅ‚Ã³w sÄ… propagowane przez graf do nieoznaczonych wÄ™zÅ‚Ã³w, zakÅ‚adajÄ…c, Å¼e podobne wÄ™zÅ‚y powinny mieÄ‡ podobne etykiety.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Klasyfikacja dokumentÃ³w** â€“ tworzenie grafu, gdzie dokumenty sÄ… wÄ™zÅ‚ami, a krawÄ™dzie Å‚Ä…czÄ… podobne dokumenty. Etykiety z kilku oznaczonych dokumentÃ³w sÄ… propagowane na resztÄ™.\n",
    "- **Analiza sieci spoÅ‚ecznoÅ›ciowych** â€“ klasyfikacja uÅ¼ytkownikÃ³w (np. identyfikacja botÃ³w, segmentacja grup interesu) na podstawie ich poÅ‚Ä…czeÅ„ i aktywnoÅ›ci, gdzie tylko niewielka czÄ™Å›Ä‡ uÅ¼ytkownikÃ³w jest etykietowana.\n",
    "- **Bioinformatyka** â€“ klasyfikacja biaÅ‚ek lub genÃ³w na podstawie ich interakcji i podobieÅ„stwa sekwencji.\n",
    "- **Wykrywanie oszustw** â€“ budowanie grafu transakcji lub uÅ¼ytkownikÃ³w i propagowanie informacji o znanych oszustwach na powiÄ…zane, nieoznaczone wÄ™zÅ‚y.\n",
    "- **Segmentacja obrazÃ³w** â€“ tworzenie grafu z pikseli lub superpikseli obrazu i propagowanie etykiet z kilku oznaczonych regionÃ³w na resztÄ™.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Label Propagation (Propagacja etykiet)\n",
    "- Label Spreading\n",
    "- Graph Convolutional Networks (GCNs) â€“ w kontekÅ›cie gÅ‚Ä™bokiego uczenia na grafach\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie oparte na modelach generatywnych (Generative Models for Semi-supervised Learning)\n",
    "\n",
    "Uczenie oparte na modelach generatywnych zakÅ‚ada, Å¼e dane pochodzÄ… z pewnego rozkÅ‚adu, ktÃ³ry moÅ¼na modelowaÄ‡. Modele te prÃ³bujÄ… nauczyÄ‡ siÄ™ tego rozkÅ‚adu, co pozwala im wykorzystaÄ‡ zarÃ³wno dane oznaczone, jak i nieoznaczone.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model generatywny (np. GMM, VAE, GAN) uczy siÄ™ wspÃ³lnego rozkÅ‚adu prawdopodobieÅ„stwa dla danych wejÅ›ciowych i etykiet. Dane nieoznaczone pomagajÄ… modelowi lepiej zrozumieÄ‡ strukturÄ™ danych wejÅ›ciowych, co z kolei poprawia jego zdolnoÅ›Ä‡ do klasyfikacji danych oznaczonych.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Klasyfikacja obrazÃ³w** â€“ wykorzystanie VAE lub GAN do nauczenia siÄ™ reprezentacji obrazÃ³w, co pomaga w klasyfikacji nawet z ograniczonymi etykietami.\n",
    "- **Rozpoznawanie wzorcÃ³w** â€“ budowanie modelu, ktÃ³ry potrafi generowaÄ‡ nowe przykÅ‚ady danych, co Å›wiadczy o zrozumieniu ich struktury.\n",
    "- **Segmentacja obrazÃ³w** â€“ modele generatywne mogÄ… pomÃ³c w nauczeniu siÄ™, jak wyglÄ…dajÄ… rÃ³Å¼ne regiony obrazu, nawet jeÅ›li tylko niewielka ich czÄ™Å›Ä‡ jest etykietowana.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Gaussian Mixture Models (GMM)\n",
    "- Variational Autoencoders (VAEs)\n",
    "- Generative Adversarial Networks (GANs) w trybie pÃ³Å‚-nadzorowanym (SGAN)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie oparte na redukcji wymiarowoÅ›ci (Dimensionality Reduction for Semi-supervised Learning)\n",
    "\n",
    "ChociaÅ¼ redukcja wymiarowoÅ›ci jest technikÄ… nienadzorowanÄ…, moÅ¼e byÄ‡ wykorzystana w kontekÅ›cie pÃ³Å‚-nadzorowanym, aby znaleÅºÄ‡ reprezentacjÄ™ danych, ktÃ³ra jest optymalna zarÃ³wno dla struktury danych (nienadzorowane), jak i dla zadania klasyfikacji (nadzorowane).\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "NiektÃ³re algorytmy redukcji wymiarowoÅ›ci mogÄ… uwzglÄ™dniaÄ‡ dostÄ™pne etykiety, aby znaleÅºÄ‡ projekcjÄ™, ktÃ³ra nie tylko zmniejsza wymiarowoÅ›Ä‡, ale takÅ¼e maksymalizuje separacjÄ™ klas. Inne metody nienadzorowane (np. PCA) mogÄ… byÄ‡ uÅ¼yte jako pre-processing, a nastÄ™pnie na zredukowanych danych stosuje siÄ™ techniki pÃ³Å‚-nadzorowane.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Wizualizacja danych z etykietami i bez** â€“ uÅ¼ycie t-SNE lub UMAP do wizualizacji danych, gdzie punkty z etykietami sÄ… wyrÃ³Å¼nione, co pomaga w ocenie, czy struktura danych wspiera separacjÄ™ klas.\n",
    "- **Poprawa wydajnoÅ›ci klasyfikatorÃ³w** â€“ redukcja wymiarowoÅ›ci danych wejÅ›ciowych przed zastosowaniem algorytmu pÃ³Å‚-nadzorowanego lub nadzorowanego, co moÅ¼e zmniejszyÄ‡ szum i poprawiÄ‡ generalizacjÄ™.\n",
    "- **Uczenie reprezentacji** â€“ tworzenie niskowymiarowych embeddingÃ³w, ktÃ³re sÄ… uÅ¼yteczne zarÃ³wno dla zadaÅ„ nienadzorowanych (np. klastrowanie), jak i nadzorowanych (np. klasyfikacja).\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Semi-supervised PCA (SSPCA)\n",
    "- Linear Discriminant Analysis (LDA) â€“ choÄ‡ gÅ‚Ã³wnie nadzorowane, moÅ¼e byÄ‡ adaptowane\n",
    "- Manifold Learning (np. Isomap, LLE) w poÅ‚Ä…czeniu z etykietami\n",
    "- Autoenkodery z dodatkowÄ… funkcjÄ… straty dla etykiet\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu pÃ³Å‚-nadzorowanego:\n",
    "1. **Przygotowanie danych** â€“ zebranie danych, podziaÅ‚ na maÅ‚y zbiÃ³r oznaczony i duÅ¼y zbiÃ³r nieoznaczony.  \n",
    "2. **WybÃ³r algorytmu** â€“ w zaleÅ¼noÅ›ci od dostÄ™pnych danych i problemu (np. self-training, graph-based).  \n",
    "3. **Trenowanie modelu** â€“ model uczy siÄ™, wykorzystujÄ…c zarÃ³wno etykiety, jak i strukturÄ™ danych nieoznaczonych.  \n",
    "4. **Walidacja i testowanie** â€“ ocena modelu na zbiorze testowym (z etykietami).  \n",
    "5. **Ewaluacja wynikÃ³w** â€“ przy uÅ¼yciu metryk klasyfikacji (accuracy, precision, recall, F1-score).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Rozpoznawanie obrazÃ³w i wideo** â€“ klasyfikacja obiektÃ³w, segmentacja, detekcja twarzy, gdzie etykietowanie kaÅ¼dego piksela jest niemoÅ¼liwe.\n",
    "- **Przetwarzanie jÄ™zyka naturalnego (NLP)** â€“ klasyfikacja tekstu, analiza sentymentu, rozpoznawanie encji, gdzie dostÄ™pnych jest wiele nieoznaczonych tekstÃ³w.\n",
    "- **Bioinformatyka** â€“ klasyfikacja danych genetycznych, analiza ekspresji genÃ³w, gdzie etykietowanie prÃ³bek jest kosztowne.\n",
    "- **Diagnostyka medyczna** â€“ wspomaganie klasyfikacji chorÃ³b na podstawie obrazÃ³w medycznych lub danych pacjentÃ³w.\n",
    "- **Wykrywanie oszustw i anomalii** â€“ wykorzystanie nieoznaczonych danych do lepszego zrozumienia \"normalnego\" zachowania i skuteczniejszego wykrywania odstÄ™pstw.\n",
    "- **Personalizacja i systemy rekomendacji** â€“ wykorzystanie nieoznaczonych danych o zachowaniach uÅ¼ytkownikÃ³w do poprawy rekomendacji.\n",
    "- **Uczenie robotÃ³w** â€“ roboty mogÄ… uczyÄ‡ siÄ™ na podstawie niewielkiej liczby demonstracji (etykiet) i duÅ¼ej liczby nieoznaczonych interakcji ze Å›rodowiskiem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3948247",
   "metadata": {},
   "source": [
    "## Uczenie Samonadzorowane (Self-supervised Learning - SSL)\n",
    "\n",
    "Uczenie samonadzorowane to rodzaj uczenia maszynowego, w ktÃ³rym model uczy siÄ™ na podstawie **danych nieoznaczonych**, ale generuje **wÅ‚asne \"pseudo-etykiety\"** z tych danych, aby rozwiÄ…zaÄ‡ tzw. **zadanie pretekstowe (pretext task)**.  \n",
    "Celem nie jest rozwiÄ…zanie samego zadania pretekstowego, lecz nauczenie modelu **ogÃ³lnych, uÅ¼ytecznych reprezentacji (embeddingÃ³w)** danych, ktÃ³re mogÄ… byÄ‡ nastÄ™pnie wykorzystane do rozwiÄ…zywania innych, bardziej zÅ‚oÅ¼onych zadaÅ„ (tzw. **zadaÅ„ downstream**), czÄ™sto z uÅ¼yciem uczenia nadzorowanego.\n",
    "\n",
    "#### Dlaczego Self-supervised Learning?\n",
    "- **Brak etykiet:** Podobnie jak w uczeniu nienadzorowanym, SSL nie wymaga rÄ™cznie etykietowanych danych.\n",
    "- **Bogatsze reprezentacje:** W przeciwieÅ„stwie do tradycyjnego uczenia nienadzorowanego (np. klastrowania), SSL czÄ™sto prowadzi do nauki bardziej semantycznie bogatych i ogÃ³lnych reprezentacji, ktÃ³re sÄ… bardzo skuteczne w transfer learningu.\n",
    "- **SkalowalnoÅ›Ä‡:** MoÅ¼liwoÅ›Ä‡ wykorzystania ogromnych, nieoznaczonych zbiorÃ³w danych (np. miliardÃ³w obrazÃ³w, terabajtÃ³w tekstu) do wstÄ™pnego trenowania.\n",
    "- **Most miÄ™dzy unsupervised a supervised:** UmoÅ¼liwia wykorzystanie nienadzorowanych danych do \"rozgrzania\" modelu, ktÃ³ry nastÄ™pnie jest dostrajany (fine-tuned) na maÅ‚ym zbiorze danych oznaczonych.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zadania Pretekstowe (Pretext Tasks)\n",
    "\n",
    "Zadania pretekstowe to specjalnie zaprojektowane zadania, ktÃ³re model rozwiÄ…zuje na danych nieoznaczonych, aby nauczyÄ‡ siÄ™ uÅ¼ytecznych reprezentacji. Model generuje wÅ‚asne etykiety dla tych zadaÅ„.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Dane wejÅ›ciowe sÄ… modyfikowane w kontrolowany sposÃ³b (np. maskowanie czÄ™Å›ci obrazu, tasowanie zdaÅ„), a model jest trenowany, aby przewidzieÄ‡ oryginalny stan lub brakujÄ…cÄ… czÄ™Å›Ä‡. RozwiÄ…zujÄ…c te \"sztuczne\" problemy, model uczy siÄ™ rozumieÄ‡ strukturÄ™, kontekst i semantykÄ™ danych.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Przewidywanie brakujÄ…cych fragmentÃ³w obrazu (Image Inpainting/Context Prediction):** Model otrzymuje obraz z zamaskowanym fragmentem i musi przewidzieÄ‡, co siÄ™ tam znajdowaÅ‚o. Uczy siÄ™ relacji przestrzennych i semantycznych obiektÃ³w.\n",
    "- **Przewidywanie wzglÄ™dnej pozycji fragmentÃ³w obrazu (Relative Patch Prediction):** Model otrzymuje centralny fragment obrazu i kilka innych fragmentÃ³w, a jego zadaniem jest przewidzenie, gdzie te inne fragmenty znajdowaÅ‚y siÄ™ wzglÄ™dem centralnego. Uczy siÄ™ relacji przestrzennych.\n",
    "- **Kolorowanie obrazÃ³w czarno-biaÅ‚ych (Colorization):** Model otrzymuje obraz czarno-biaÅ‚y i musi przewidzieÄ‡ jego kolory. Uczy siÄ™ rozpoznawaÄ‡ obiekty i ich typowe barwy.\n",
    "- **Generowanie nastÄ™pnego sÅ‚owa/maskowanie sÅ‚Ã³w (Next Word Prediction/Masked Language Modeling):** W NLP, model otrzymuje sekwencjÄ™ sÅ‚Ã³w i musi przewidzieÄ‡ nastÄ™pne sÅ‚owo (np. GPT) lub zamaskowane sÅ‚owa w zdaniu (np. BERT). Uczy siÄ™ gramatyki, skÅ‚adni i semantyki jÄ™zyka.\n",
    "- **Przewidywanie rotacji obrazu (Rotation Prediction):** Model otrzymuje obraz obrÃ³cony o losowy kÄ…t i musi przewidzieÄ‡ ten kÄ…t. Uczy siÄ™ rozpoznawania obiektÃ³w niezaleÅ¼nie od ich orientacji.\n",
    "- **Kontrastowe uczenie siÄ™ (Contrastive Learning):** Model uczy siÄ™, aby podobne przykÅ‚ady (np. rÃ³Å¼ne augmentacje tego samego obrazu) miaÅ‚y podobne reprezentacje, a niepodobne przykÅ‚ady â€“ rÃ³Å¼ne. Jest to obecnie jedna z najskuteczniejszych metod SSL.\n",
    "\n",
    "#### Popularne algorytmy/techniki (przykÅ‚ady zadaÅ„ pretekstowych):\n",
    "- **Dla obrazÃ³w:** Jigsaw Puzzles, Rotation Prediction, Context Prediction, Colorization, SimCLR, MoCo, BYOL (ostatnie trzy to metody kontrastowe).\n",
    "- **Dla tekstu:** Masked Language Modeling (BERT), Next Sentence Prediction (BERT), Next Token Prediction (GPT), ELECTRA.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Transfer Learning (Przenoszenie Wiedzy)\n",
    "\n",
    "Transfer Learning to kluczowy element i gÅ‚Ã³wna zaleta uczenia samonadzorowanego. Polega na **przenoszeniu wiedzy (nauczenia siÄ™ reprezentacji) z jednego zadania (zadania pretekstowego SSL) do innego, czÄ™sto bardziej zÅ‚oÅ¼onego zadania (zadania downstream)**.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "1.  **Pre-training (WstÄ™pne trenowanie):** Model (np. duÅ¼a sieÄ‡ neuronowa) jest trenowany na ogromnym zbiorze danych nieoznaczonych, rozwiÄ…zujÄ…c zadanie pretekstowe SSL. W tym etapie model uczy siÄ™ ogÃ³lnych, niskopoziomowych i wysokopoziomowych cech danych (np. krawÄ™dzie, tekstury, ksztaÅ‚ty dla obrazÃ³w; gramatyka, semantyka dla tekstu).\n",
    "2.  **Fine-tuning (Dostrajanie):** Nauczenie reprezentacje (wagi i bias sieci) sÄ… nastÄ™pnie wykorzystywane jako punkt wyjÅ›cia dla nowego zadania (np. klasyfikacji obrazÃ³w, analizy sentymentu), ktÃ³re ma dostÄ™p do maÅ‚ego zbioru danych oznaczonych. Zazwyczaj dodaje siÄ™ nowÄ…, maÅ‚Ä… warstwÄ™ wyjÅ›ciowÄ…, ktÃ³ra jest trenowana na danych oznaczonych, a reszta modelu jest albo zamroÅ¼ona, albo trenowana z bardzo maÅ‚ym wspÃ³Å‚czynnikiem uczenia.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Rozpoznawanie obiektÃ³w na obrazach medycznych:** WstÄ™pne trenowanie modelu na miliardach ogÃ³lnych obrazÃ³w (np. ImageNet, ale bez etykiet, uÅ¼ywajÄ…c SSL), a nastÄ™pnie dostrajanie go na maÅ‚ym zbiorze obrazÃ³w medycznych (np. RTG klatki piersiowej) z etykietami.\n",
    "- **Klasyfikacja tekstu w rzadkich jÄ™zykach:** WstÄ™pne trenowanie modelu jÄ™zykowego (np. BERT) na ogromnym korpusie tekstu w jÄ™zyku angielskim (lub innym bogatym w dane), a nastÄ™pnie dostrajanie go na maÅ‚ym zbiorze danych w rzadkim jÄ™zyku do zadania klasyfikacji.\n",
    "- **Personalizacja asystentÃ³w gÅ‚osowych:** WstÄ™pne trenowanie modelu na ogÃ³lnych danych audio, a nastÄ™pnie dostrajanie go do rozpoznawania mowy konkretnego uÅ¼ytkownika.\n",
    "- **Wykrywanie oszustw:** WstÄ™pne trenowanie modelu na duÅ¼ej iloÅ›ci nieoznaczonych danych transakcyjnych, aby nauczyÄ‡ siÄ™ \"normalnych\" wzorcÃ³w, a nastÄ™pnie dostrajanie go do wykrywania oszustw na maÅ‚ym zbiorze etykietowanych transakcji.\n",
    "\n",
    "#### KorzyÅ›ci z Transfer Learningu w SSL:\n",
    "- **Lepsza wydajnoÅ›Ä‡:** Modele osiÄ…gajÄ… znacznie lepsze wyniki, nawet z maÅ‚Ä… iloÅ›ciÄ… danych oznaczonych.\n",
    "- **Szybszy trening:** WstÄ™pnie wytrenowany model szybciej konwerguje podczas dostrajania.\n",
    "- **Mniejsze zapotrzebowanie na dane:** Zmniejsza potrzebÄ™ posiadania ogromnych, etykietowanych zbiorÃ³w danych dla kaÅ¼dego nowego zadania.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ PorÃ³wnanie Self-supervised Learning (SSL) z Unsupervised Learning (UL)\n",
    "\n",
    "ChociaÅ¼ SSL jest formÄ… uczenia nienadzorowanego, istnieje kluczowa rÃ³Å¼nica w ich celach i metodologii:\n",
    "\n",
    "| Cecha                  | Uczenie Nienadzorowane (Unsupervised Learning - UL)                               | Uczenie Samonadzorowane (Self-supervised Learning - SSL)                               |\n",
    "| :--------------------- | :-------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |\n",
    "| **Cel gÅ‚Ã³wny**         | Odkrywanie ukrytych struktur w danych (np. klastry, redukcja wymiarowoÅ›ci).       | Uczenie siÄ™ ogÃ³lnych, uÅ¼ytecznych reprezentacji danych do **transferu wiedzy**.        |\n",
    "| **Etykiety**           | Brak etykiet.                                                                     | Brak rÄ™cznych etykiet. Model **generuje wÅ‚asne \"pseudo-etykiety\"** z danych.            |\n",
    "| **Zadanie**            | BezpoÅ›rednie rozwiÄ…zanie problemu (np. klastrowanie klientÃ³w).                    | RozwiÄ…zanie **zadania pretekstowego**, ktÃ³re jest Å›rodkiem do celu (nauki reprezentacji). |\n",
    "| **WyjÅ›cie**            | Klastry, zredukowane wymiary, wykryte anomalie.                                   | **Reprezentacje (embeddingi)** danych, ktÃ³re sÄ… wejÅ›ciem dla kolejnych zadaÅ„.          |\n",
    "| **Zastosowanie**       | Segmentacja, wizualizacja, detekcja anomalii, analiza koszyka.                    | **Pre-training** dla zadaÅ„ nadzorowanych (klasyfikacja, detekcja obiektÃ³w, NLP).       |\n",
    "| **Typowe algorytmy**   | K-Means, PCA, DBSCAN, Isolation Forest, Apriori.                                  | BERT, GPT, SimCLR, MoCo, BYOL (czÄ™sto oparte na gÅ‚Ä™bokich sieciach neuronowych).       |\n",
    "| **ZÅ‚oÅ¼onoÅ›Ä‡ modelu**   | CzÄ™sto prostsze modele, choÄ‡ mogÄ… byÄ‡ teÅ¼ gÅ‚Ä™bokie autoenkodery.                   | Zazwyczaj **gÅ‚Ä™bokie sieci neuronowe** (transformery, konwolucyjne).                   |\n",
    "\n",
    "**Kluczowa rÃ³Å¼nica:**\n",
    "UL skupia siÄ™ na **bezpoÅ›rednim odkrywaniu wzorcÃ³w** w danych. SSL natomiast skupia siÄ™ na **uczeniu siÄ™ reprezentacji**, ktÃ³re sÄ… tak dobre, Å¼e mogÄ… byÄ‡ **przeniesione** do innych zadaÅ„, czÄ™sto nadzorowanych, znaczÄ…co poprawiajÄ…c ich wydajnoÅ›Ä‡, nawet przy maÅ‚ej iloÅ›ci etykiet. SSL jest czÄ™sto postrzegane jako sposÃ³b na \"rozgrzanie\" duÅ¼ych modeli gÅ‚Ä™bokiego uczenia, aby byÅ‚y bardziej efektywne w pÃ³Åºniejszym dostrajaniu.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu samonadzorowanego:\n",
    "1. **Przygotowanie danych** â€“ zebranie duÅ¼ego zbioru danych nieoznaczonych.  \n",
    "2. **Definicja zadania pretekstowego** â€“ zaprojektowanie zadania, ktÃ³re pozwoli modelowi nauczyÄ‡ siÄ™ uÅ¼ytecznych reprezentacji.  \n",
    "3. **Trenowanie modelu (Pre-training)** â€“ model uczy siÄ™ rozwiÄ…zywaÄ‡ zadanie pretekstowe, generujÄ…c wÅ‚asne pseudo-etykiety.  \n",
    "4. **Ekstrakcja reprezentacji** â€“ po pre-treningu, warstwy modelu (z wyjÄ…tkiem warstwy wyjÅ›ciowej zadania pretekstowego) sÄ… wykorzystywane do ekstrakcji embeddingÃ³w.  \n",
    "5. **Dostrajanie (Fine-tuning)** â€“ na maÅ‚ym zbiorze danych oznaczonych, model jest dostrajany do wÅ‚aÅ›ciwego zadania (downstream task).  \n",
    "6. **Ewaluacja wynikÃ³w** â€“ ocena modelu na zbiorze testowym dla zadania downstream.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Przetwarzanie jÄ™zyka naturalnego (NLP):** Modele takie jak BERT, GPT-3/4, T5 sÄ… trenowane samonadzorowanie na ogromnych korpusach tekstu, a nastÄ™pnie dostrajane do tÅ‚umaczenia maszynowego, generowania tekstu, analizy sentymentu, odpowiadania na pytania.\n",
    "- **Wizja komputerowa:** Modele trenowane samonadzorowanie (np. SimCLR, MoCo) na miliardach obrazÃ³w, a nastÄ™pnie dostrajane do klasyfikacji obrazÃ³w, detekcji obiektÃ³w, segmentacji, rozpoznawania twarzy, nawet z bardzo maÅ‚Ä… iloÅ›ciÄ… etykiet.\n",
    "- **Rozpoznawanie mowy:** WstÄ™pne trenowanie na duÅ¼ych zbiorach audio, a nastÄ™pnie dostrajanie do transkrypcji mowy, identyfikacji mÃ³wcy.\n",
    "- **Bioinformatyka:** Uczenie reprezentacji sekwencji DNA/RNA/biaÅ‚ek, ktÃ³re mogÄ… byÄ‡ nastÄ™pnie uÅ¼yte do przewidywania funkcji biaÅ‚ek, wykrywania mutacji.\n",
    "- **Robotyka:** Uczenie siÄ™ reprezentacji Å›rodowiska i interakcji na podstawie nieoznaczonych danych z sensorÃ³w, co pomaga robotom w nawigacji i manipulacji.\n",
    "- **Medycyna:** WstÄ™pne trenowanie na duÅ¼ych zbiorach nieoznaczonych obrazÃ³w medycznych, a nastÄ™pnie dostrajanie do diagnozy chorÃ³b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72935d52",
   "metadata": {},
   "source": [
    "## Uczenie ze Wzmocnieniem (Reinforcement Learning - RL)\n",
    "\n",
    "Uczenie ze wzmocnieniem to zupeÅ‚nie inny paradygmat uczenia maszynowego, w ktÃ³rym system uczÄ…cy, zwany w tym kontekÅ›cie **agentem**, moÅ¼e **obserwowaÄ‡ Å›rodowisko**, **wybieraÄ‡ i wykonywaÄ‡ akcje**, a w zamian otrzymuje **nagrody** (lub kary w postaci negatywnych nagrÃ³d).  \n",
    "Agent musi samodzielnie nauczyÄ‡ siÄ™, jaka jest najlepsza strategia, zwana **politykÄ… (policy)**, aby z czasem uzyskaÄ‡ jak najwiÄ™cej nagrÃ³d. Polityka definiuje, jakÄ… akcjÄ™ agent powinien wybraÄ‡ w danej sytuacji.\n",
    "\n",
    "#### Dlaczego Reinforcement Learning?\n",
    "- **Interakcja ze Å›rodowiskiem:** RL jest idealne do problemÃ³w, gdzie system musi podejmowaÄ‡ sekwencjÄ™ decyzji w dynamicznym Å›rodowisku.\n",
    "- **Brak etykiet:** Nie wymaga rÄ™cznie etykietowanych danych wejÅ›cia-wyjÅ›cia; uczy siÄ™ na podstawie prÃ³b i bÅ‚Ä™dÃ³w oraz otrzymywanych nagrÃ³d.\n",
    "- **Optymalizacja dÅ‚ugoterminowa:** Skupia siÄ™ na maksymalizacji skumulowanej nagrody w czasie, a nie tylko na natychmiastowych korzyÅ›ciach.\n",
    "- **Autonomiczne systemy:** UmoÅ¼liwia tworzenie systemÃ³w, ktÃ³re uczÄ… siÄ™ adaptowaÄ‡ i optymalizowaÄ‡ swoje zachowanie w zÅ‚oÅ¼onych scenariuszach.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Agent i Åšrodowisko (Agent and Environment)\n",
    "\n",
    "W uczeniu ze wzmocnieniem, interakcja odbywa siÄ™ miÄ™dzy **agentem** a **Å›rodowiskiem**.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "- **Agent:** To system uczÄ…cy siÄ™, ktÃ³ry podejmuje decyzje. Obserwuje stan Å›rodowiska, wybiera akcjÄ™ do wykonania i otrzymuje nagrodÄ™ (lub karÄ™) oraz nowy stan Å›rodowiska.\n",
    "- **Åšrodowisko:** To Å›wiat, w ktÃ³rym dziaÅ‚a agent. Reaguje na akcje agenta, zmieniajÄ…c swÃ³j stan i dostarczajÄ…c nagrody.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Robot kroczÄ…cy:** Robot (agent) obserwuje swoje poÅ‚oÅ¼enie i rÃ³wnowagÄ™ (stan Å›rodowiska), wykonuje ruchy nogami (akcje), a otrzymuje nagrody za utrzymanie rÃ³wnowagi i poruszanie siÄ™ do przodu, a kary za upadek.\n",
    "- **Gra w Go (AlphaGo):** Program AlphaGo (agent) obserwuje planszÄ™ (stan Å›rodowiska), wykonuje ruch (akcjÄ™), a otrzymuje nagrody za wygrane partie i kary za przegrane.\n",
    "- **Autonomiczny samochÃ³d:** SamochÃ³d (agent) obserwuje drogÄ™, inne pojazdy, znaki (stan Å›rodowiska), wykonuje akcje (przyspieszanie, hamowanie, skrÄ™canie), a otrzymuje nagrody za bezpiecznÄ… jazdÄ™ i dotarcie do celu, a kary za kolizje czy naruszenia przepisÃ³w.\n",
    "- **System zarzÄ…dzania energiÄ…:** System (agent) obserwuje zuÅ¼ycie energii, ceny, prognozy pogody (stan Å›rodowiska), podejmuje decyzje o wÅ‚Ä…czeniu/wyÅ‚Ä…czeniu urzÄ…dzeÅ„ (akcje), a otrzymuje nagrody za oszczÄ™dnoÅ›ci i kary za przekroczenie limitÃ³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Akcje, Stany i Nagrody (Actions, States, and Rewards)\n",
    "\n",
    "To podstawowe elementy, ktÃ³re definiujÄ… interakcjÄ™ agenta ze Å›rodowiskiem.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "- **Akcje (Actions):** Decyzje, ktÃ³re agent moÅ¼e podjÄ…Ä‡ w danym stanie Å›rodowiska. MogÄ… byÄ‡ dyskretne (np. \"idÅº w lewo\", \"kup\") lub ciÄ…gÅ‚e (np. \"przyspiesz o 0.5 m/sÂ²\").\n",
    "- **Stany (States):** Reprezentacja aktualnej sytuacji Å›rodowiska, ktÃ³rÄ… agent moÅ¼e obserwowaÄ‡. Stan zawiera wszystkie istotne informacje potrzebne agentowi do podjÄ™cia decyzji.\n",
    "- **Nagrody (Rewards):** SygnaÅ‚ zwrotny od Å›rodowiska, ktÃ³ry informuje agenta o jakoÅ›ci jego ostatniej akcji. Nagrody sÄ… kluczowe dla uczenia siÄ™ polityki. Celem agenta jest maksymalizacja skumulowanej nagrody w czasie.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Gra w szachy:**\n",
    "    - **Akcje:** Wykonanie ruchu figurÄ….\n",
    "    - **Stany:** UkÅ‚ad figur na szachownicy.\n",
    "    - **Nagrody:** +1 za wygranÄ…, -1 za przegranÄ…, 0 za remis lub ruchy poÅ›rednie.\n",
    "- **ZarzÄ…dzanie magazynem:**\n",
    "    - **Akcje:** ZamÃ³wienie towaru, wysyÅ‚ka towaru.\n",
    "    - **Stany:** Poziom zapasÃ³w, prognozy popytu.\n",
    "    - **Nagrody:** + za zysk ze sprzedaÅ¼y, - za koszty magazynowania, - za brak towaru.\n",
    "- **Sterowanie robotem przemysÅ‚owym:**\n",
    "    - **Akcje:** Ruch ramienia robota w okreÅ›lonym kierunku.\n",
    "    - **Stany:** Pozycja ramienia, poÅ‚oÅ¼enie obiektu.\n",
    "    - **Nagrody:** + za prawidÅ‚owe chwycenie obiektu, - za upuszczenie obiektu.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Polityka (Policy)\n",
    "\n",
    "Polityka to **strategia** agenta, ktÃ³ra definiuje, jakÄ… akcjÄ™ powinien wybraÄ‡ w danej sytuacji (stanie Å›rodowiska). Jest to \"mÃ³zg\" agenta, ktÃ³ry kieruje jego zachowaniem.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Polityka moÅ¼e byÄ‡ deterministyczna (dla danego stanu zawsze wybiera tÄ™ samÄ… akcjÄ™) lub stochastyczna (dla danego stanu wybiera akcjÄ™ z pewnym prawdopodobieÅ„stwem). Celem uczenia ze wzmocnieniem jest znalezienie optymalnej polityki, ktÃ³ra maksymalizuje oczekiwanÄ… skumulowanÄ… nagrodÄ™.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Polityka AlphaGo:** AlphaGo nauczyÅ‚o siÄ™ swojej zwyciÄ™skiej polityki poprzez analizÄ™ milionÃ³w gier i rozgrywanie wielu gier przeciwko sobie. Polityka ta definiowaÅ‚a, jaki ruch wykonaÄ‡ w kaÅ¼dej moÅ¼liwej konfiguracji planszy Go.\n",
    "- **Polityka robota kroczÄ…cego:** Polityka robota moÅ¼e definiowaÄ‡, jak poruszaÄ‡ nogami w zaleÅ¼noÅ›ci od aktualnego stanu rÃ³wnowagi i prÄ™dkoÅ›ci, aby utrzymaÄ‡ siÄ™ na nogach i iÅ›Ä‡ do przodu.\n",
    "- **Polityka systemu rekomendacji:** Polityka moÅ¼e decydowaÄ‡, jaki produkt zarekomendowaÄ‡ uÅ¼ytkownikowi w zaleÅ¼noÅ›ci od jego historii przeglÄ…dania i zakupÃ³w, aby zmaksymalizowaÄ‡ prawdopodobieÅ„stwo zakupu.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu (Reinforcement Learning):\n",
    "1. **Definicja Å›rodowiska i nagrÃ³d** â€“ okreÅ›lenie, jak agent bÄ™dzie wchodziÅ‚ w interakcje ze Å›wiatem i jakie nagrody bÄ™dzie otrzymywaÅ‚.  \n",
    "2. **Inicjalizacja polityki** â€“ poczÄ…tkowa, czÄ™sto losowa, strategia agenta.  \n",
    "3. **Interakcja ze Å›rodowiskiem** â€“ agent obserwuje stan, wybiera akcjÄ™ zgodnie z politykÄ…, wykonuje jÄ…, otrzymuje nagrodÄ™ i nowy stan.  \n",
    "4. **Aktualizacja polityki** â€“ na podstawie otrzymanych nagrÃ³d, agent modyfikuje swojÄ… politykÄ™, aby w przyszÅ‚oÅ›ci podejmowaÄ‡ lepsze decyzje.  \n",
    "5. **Iteracja** â€“ proces interakcji i aktualizacji powtarza siÄ™ wielokrotnie, aÅ¼ agent nauczy siÄ™ optymalnej polityki.  \n",
    "6. **Zastosowanie polityki** â€“ po nauczeniu, agent stosuje wyuczonÄ… politykÄ™ do rozwiÄ…zywania problemu (np. AlphaGo stosujÄ…ce wyuczonÄ… politykÄ™ w grze przeciwko mistrzowi).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Robotyka:** Uczenie robotÃ³w chodzenia, manipulacji obiektami, nawigacji w zÅ‚oÅ¼onych Å›rodowiskach.\n",
    "- **Gry:** Tworzenie agentÃ³w AI, ktÃ³rzy potrafiÄ… graÄ‡ w gry (szachy, Go, gry wideo) na poziomie mistrzowskim lub ponadludzkim (np. AlphaGo, AlphaStar, OpenAI Five).\n",
    "- **Autonomiczne pojazdy:** Uczenie samochodÃ³w, jak bezpiecznie i efektywnie jeÅºdziÄ‡, unikaÄ‡ przeszkÃ³d, parkowaÄ‡.\n",
    "- **Systemy rekomendacji:** Optymalizacja rekomendacji produktÃ³w, filmÃ³w czy muzyki w celu maksymalizacji zaangaÅ¼owania uÅ¼ytkownika.\n",
    "- **ZarzÄ…dzanie zasobami:** Optymalizacja zuÅ¼ycia energii w centrach danych, zarzÄ…dzanie ruchem w sieciach telekomunikacyjnych.\n",
    "- **Finanse:** Optymalizacja strategii handlowych, zarzÄ…dzanie portfelem inwestycyjnym.\n",
    "- **Medycyna:** Optymalizacja planÃ³w leczenia, dawkowania lekÃ³w w czasie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c575e99",
   "metadata": {},
   "source": [
    "## Uczenie Wsadowe (Batch Learning)\n",
    "\n",
    "Uczenie wsadowe to paradygmat uczenia maszynowego, w ktÃ³rym system **nie jest zdolny do uczenia siÄ™ przyrostowego**. Oznacza to, Å¼e model musi byÄ‡ **trenowany przy uÅ¼yciu wszystkich dostÄ™pnych danych jednoczeÅ›nie**.  \n",
    "Proces ten zazwyczaj wymaga znacznych zasobÃ³w obliczeniowych i czasu, dlatego jest typowo przeprowadzany **offline**. Po wytrenowaniu system jest uruchamiany w Å›rodowisku produkcyjnym i dziaÅ‚a, stosujÄ…c wyuczonÄ… wiedzÄ™, bez dalszego uczenia siÄ™.\n",
    "\n",
    "#### Dlaczego Batch Learning?\n",
    "- **Prostota implementacji:** Jest to czÄ™sto najprostszy sposÃ³b na trenowanie modeli, szczegÃ³lnie dla problemÃ³w, gdzie dane sÄ… stabilne.\n",
    "- **StabilnoÅ›Ä‡ modelu:** Model jest trenowany na caÅ‚ym zbiorze danych, co czÄ™sto prowadzi do stabilniejszych i bardziej uogÃ³lniajÄ…cych wynikÃ³w, jeÅ›li dane nie zmieniajÄ… siÄ™ szybko.\n",
    "- **Kontrolowane Å›rodowisko:** Idealne dla Å›rodowisk, gdzie model jest regularnie aktualizowany w kontrolowany sposÃ³b.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie Offline (Offline Learning)\n",
    "\n",
    "Uczenie offline to charakterystyczna cecha uczenia wsadowego. Oznacza, Å¼e model jest **trenowany raz, poza Å›rodowiskiem produkcyjnym**, a nastÄ™pnie jest wdraÅ¼any i dziaÅ‚a, stosujÄ…c to, czego siÄ™ nauczyÅ‚, bez dalszego uczenia siÄ™ w czasie rzeczywistym.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "1.  **Trenowanie:** Model jest trenowany na kompletnym zbiorze danych.\n",
    "2.  **WdroÅ¼enie:** Wytrenowany model jest uruchamiany w Å›rodowisku produkcyjnym.\n",
    "3.  **DziaÅ‚anie:** Model dokonuje przewidywaÅ„ lub klasyfikacji, ale nie aktualizuje swoich wag ani nie uczy siÄ™ na podstawie nowych danych, ktÃ³re napÅ‚ywajÄ… po wdroÅ¼eniu.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Systemy rekomendacji produktÃ³w:** Model jest trenowany raz dziennie lub raz w tygodniu na wszystkich danych o zakupach, a nastÄ™pnie uÅ¼ywany do rekomendowania produktÃ³w.\n",
    "- **Klasyfikacja spamu:** Model jest trenowany na zbiorze znanych wiadomoÅ›ci spamowych i nie-spamowych, a nastÄ™pnie uÅ¼ywany do filtrowania nowych wiadomoÅ›ci e-mail. JeÅ›li pojawi siÄ™ nowy typ spamu, system nie nauczy siÄ™ go automatycznie.\n",
    "- **Diagnostyka medyczna:** Model trenowany na historycznych danych pacjentÃ³w do diagnozowania chorÃ³b. Nowe przypadki sÄ… klasyfikowane na podstawie tego modelu, ale model nie uczy siÄ™ z nich w locie.\n",
    "- **Ocena ryzyka kredytowego:** Model jest trenowany na historycznych danych kredytowych, a nastÄ™pnie uÅ¼ywany do oceny nowych wnioskÃ³w kredytowych.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Aktualizacja Modelu i RozkÅ‚ad Danych (Model Update and Data Drift)\n",
    "\n",
    "W systemach uczenia wsadowego, aby model mÃ³gÅ‚ uwzglÄ™dniÄ‡ nowe dane (np. nowy typ spamu, zmieniajÄ…ce siÄ™ preferencje klientÃ³w), konieczne jest **ponowne wytrenowanie nowej wersji systemu od podstaw**.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "1.  **Zebranie nowych danych:** Zbierane sÄ… nowe dane, ktÃ³re pojawiÅ‚y siÄ™ od ostatniego treningu.\n",
    "2.  **PoÅ‚Ä…czenie danych:** Nowe dane sÄ… Å‚Ä…czone ze starym, peÅ‚nym zbiorem danych.\n",
    "3.  **Ponowne trenowanie:** Nowa wersja systemu jest trenowana od zera na caÅ‚ym, zaktualizowanym zbiorze danych.\n",
    "4.  **Wymiana systemu:** Stary system w produkcji jest zatrzymywany i zastÄ™powany nowÄ…, Å›wieÅ¼o wytrenowanÄ… wersjÄ….\n",
    "\n",
    "#### RozkÅ‚ad Modelu (Data Drift):\n",
    "**Data Drift** (dryf danych) odnosi siÄ™ do zjawiska, w ktÃ³rym **statystyczne wÅ‚aÅ›ciwoÅ›ci danych wejÅ›ciowych zmieniajÄ… siÄ™ w czasie**. JeÅ›li dane, na ktÃ³rych model zostaÅ‚ wytrenowany, rÃ³Å¼niÄ… siÄ™ znaczÄ…co od danych, ktÃ³re napÅ‚ywajÄ… w produkcji, wydajnoÅ›Ä‡ modelu moÅ¼e drastycznie spaÅ›Ä‡.\n",
    "\n",
    "- **Wyzwanie dla Batch Learning:** Uczenie wsadowe jest szczegÃ³lnie wraÅ¼liwe na dryf danych, poniewaÅ¼ model nie uczy siÄ™ przyrostowo. JeÅ›li dane zmieniajÄ… siÄ™ szybko (np. ceny akcji, trendy w mediach spoÅ‚ecznoÅ›ciowych), model trenowany raz dziennie lub raz w tygodniu moÅ¼e szybko staÄ‡ siÄ™ nieaktualny i maÅ‚o skuteczny.\n",
    "- **KoniecznoÅ›Ä‡ czÄ™stych aktualizacji:** Aby przeciwdziaÅ‚aÄ‡ dryfowi danych, systemy wsadowe muszÄ… byÄ‡ regularnie aktualizowane poprzez ponowne trenowanie. Jednak ten proces jest kosztowny i czasochÅ‚onny.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Prognozowanie cen akcji:** Rynek akcji zmienia siÄ™ bardzo dynamicznie. Model trenowany wsadowo raz dziennie moÅ¼e szybko straciÄ‡ na dokÅ‚adnoÅ›ci z powodu dryfu danych.\n",
    "- **Wykrywanie trendÃ³w w mediach spoÅ‚ecznoÅ›ciowych:** JÄ™zyk i tematyka w mediach spoÅ‚ecznoÅ›ciowych ewoluujÄ… bÅ‚yskawicznie. Model do analizy sentymentu wymagaÅ‚by bardzo czÄ™stych aktualizacji.\n",
    "- **Systemy rekomendacji:** Preferencje uÅ¼ytkownikÃ³w zmieniajÄ… siÄ™. Model rekomendujÄ…cy filmy, trenowany raz na miesiÄ…c, moÅ¼e nie byÄ‡ w stanie dostosowaÄ‡ siÄ™ do nowych hitÃ³w czy zmieniajÄ…cych siÄ™ gustÃ³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Ograniczenia i Wyzwania (Limitations and Challenges)\n",
    "\n",
    "Uczenie wsadowe, choÄ‡ proste, ma szereg ograniczeÅ„, ktÃ³re sprawiajÄ…, Å¼e nie jest odpowiednie dla wszystkich scenariuszy.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Ograniczenia wynikajÄ… gÅ‚Ã³wnie z koniecznoÅ›ci trenowania na caÅ‚ym zbiorze danych i braku zdolnoÅ›ci do uczenia siÄ™ przyrostowego.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Czas i zasoby obliczeniowe:** Trenowanie na peÅ‚nym zbiorze danych moÅ¼e zajÄ…Ä‡ wiele godzin i wymagaÄ‡ duÅ¼ej mocy obliczeniowej (CPU, pamiÄ™Ä‡, przestrzeÅ„ dyskowa, I/O). Codzienne trenowanie duÅ¼ego modelu moÅ¼e byÄ‡ bardzo kosztowne.\n",
    "- **Szybko zmieniajÄ…ce siÄ™ dane:** JeÅ›li system musi szybko adaptowaÄ‡ siÄ™ do nowych danych (np. przewidywanie cen akcji, wykrywanie nowych typÃ³w oszustw), uczenie wsadowe jest zbyt wolne. Nowy system trenowany co 24 godziny lub co tydzieÅ„ moÅ¼e byÄ‡ juÅ¼ nieaktualny.\n",
    "- **Ogromne zbiory danych:** JeÅ›li iloÅ›Ä‡ danych jest zbyt duÅ¼a, trenowanie na caÅ‚ym zbiorze moÅ¼e byÄ‡ wrÄ™cz niemoÅ¼liwe ze wzglÄ™du na ograniczenia pamiÄ™ciowe i obliczeniowe.\n",
    "- **Ograniczone zasoby na urzÄ…dzeniu:** W przypadku systemÃ³w dziaÅ‚ajÄ…cych na urzÄ…dzeniach z ograniczonymi zasobami (np. aplikacje na smartfony, Å‚aziki marsjaÅ„skie), przechowywanie ogromnych zbiorÃ³w danych treningowych i zuÅ¼ywanie zasobÃ³w na codzienne, wielogodzinne trenowanie jest niewykonalne.\n",
    "- **Brak autonomii:** Systemy wsadowe nie uczÄ… siÄ™ autonomicznie w Å›rodowisku produkcyjnym; wymagajÄ… interwencji (ponownego trenowania) w celu adaptacji.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu (Batch Learning):\n",
    "1. **Zebranie peÅ‚nego zbioru danych** â€“ wszystkie dostÄ™pne dane sÄ… gromadzone.  \n",
    "2. **Trenowanie modelu** â€“ model jest trenowany na caÅ‚ym zbiorze danych.  \n",
    "3. **Ocena i walidacja** â€“ model jest testowany na zbiorze walidacyjnym/testowym.  \n",
    "4. **WdroÅ¼enie do produkcji** â€“ wytrenowany model jest uruchamiany i dokonuje przewidywaÅ„.  \n",
    "5. **Monitorowanie wydajnoÅ›ci** â€“ Å›ledzenie, jak model radzi sobie w produkcji.  \n",
    "6. **Aktualizacja (jeÅ›li potrzebna)** â€“ jeÅ›li wydajnoÅ›Ä‡ spada lub pojawiajÄ… siÄ™ nowe dane, proces wraca do kroku 1 (zbieranie danych + nowe dane) i model jest ponownie trenowany od zera.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Systemy rekomendacji offline:** Generowanie rekomendacji na podstawie historycznych danych, aktualizowanych cyklicznie.\n",
    "- **Klasyfikacja spamu:** Filtrowanie wiadomoÅ›ci e-mail na podstawie modelu trenowanego na zbiorze znanych spamu.\n",
    "- **Analiza obrazÃ³w:** Klasyfikacja obrazÃ³w w bazach danych, gdzie nowe obrazy sÄ… dodawane okresowo.\n",
    "- **Ocena ryzyka kredytowego:** Modele oceniajÄ…ce zdolnoÅ›Ä‡ kredytowÄ…, aktualizowane co kwartaÅ‚ lub co pÃ³Å‚ roku.\n",
    "- **Prognozowanie sprzedaÅ¼y:** Prognozy sprzedaÅ¼y produktÃ³w na podstawie danych historycznych, aktualizowane co miesiÄ…c.\n",
    "- **Wykrywanie oszustw (w niektÃ³rych scenariuszach):** Modele wykrywajÄ…ce oszustwa, ktÃ³re sÄ… regularnie trenowane na nowych danych, ale nie uczÄ… siÄ™ w czasie rzeczywistym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fccc0",
   "metadata": {},
   "source": [
    "## Uczenie Przyrostowe (Online Learning)\n",
    "\n",
    "Uczenie przyrostowe to paradygmat uczenia maszynowego, w ktÃ³rym system jest **trenowany przyrostowo**, poprzez dostarczanie mu instancji danych **sekwencyjnie**, pojedynczo lub w maÅ‚ych grupach zwanych **mini-partiami (mini-batches)**.  \n",
    "KaÅ¼dy krok uczenia jest szybki i tani, co pozwala systemowi **uczyÄ‡ siÄ™ na bieÅ¼Ä…co (on the fly)**, w miarÄ™ napÅ‚ywania nowych danych.\n",
    "\n",
    "#### Dlaczego Online Learning?\n",
    "- **Szybka adaptacja:** Idealne dla systemÃ³w, ktÃ³re otrzymujÄ… dane w ciÄ…gÅ‚ym strumieniu i muszÄ… szybko adaptowaÄ‡ siÄ™ do zmian (np. ceny akcji, trendy).\n",
    "- **Ograniczone zasoby:** Dobra opcja, jeÅ›li masz ograniczone zasoby obliczeniowe, poniewaÅ¼ system nie potrzebuje przechowywaÄ‡ wszystkich danych treningowych po ich przetworzeniu.\n",
    "- **Ogromne zbiory danych:** UmoÅ¼liwia trenowanie na zbiorach danych, ktÃ³re nie mieszczÄ… siÄ™ w pamiÄ™ci gÅ‚Ã³wnej jednej maszyny (out-of-core learning).\n",
    "- **Autonomia:** System moÅ¼e uczyÄ‡ siÄ™ autonomicznie w Å›rodowisku produkcyjnym.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie Przyrostowe i Strumienie Danych (Incremental Learning and Data Streams)\n",
    "\n",
    "Uczenie przyrostowe jest kluczowe dla systemÃ³w, ktÃ³re muszÄ… adaptowaÄ‡ siÄ™ do danych napÅ‚ywajÄ…cych w sposÃ³b ciÄ…gÅ‚y.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Model jest aktualizowany maÅ‚ymi krokami, przetwarzajÄ…c pojedyncze instancje danych lub maÅ‚e mini-partie. Po przetworzeniu dane te mogÄ… zostaÄ‡ odrzucone, co oszczÄ™dza pamiÄ™Ä‡.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Prognozowanie cen akcji:** System uczy siÄ™ na bieÅ¼Ä…co na podstawie napÅ‚ywajÄ…cych danych o transakcjach, szybko adaptujÄ…c siÄ™ do zmian rynkowych.\n",
    "- **Filtry spamu:** Filtr spamu moÅ¼e uczyÄ‡ siÄ™ na bieÅ¼Ä…co o nowych typach spamu, gdy tylko pojawiajÄ… siÄ™ nowe wiadomoÅ›ci.\n",
    "- **Systemy rekomendacji w czasie rzeczywistym:** Adaptacja rekomendacji w miarÄ™, jak uÅ¼ytkownik przeglÄ…da nowe produkty lub ocenia treÅ›ci.\n",
    "- **Monitorowanie sieci komputerowych:** Wykrywanie nowych typÃ³w atakÃ³w lub anomalii w ruchu sieciowym w miarÄ™ ich pojawiania siÄ™.\n",
    "- **Robotyka:** Robot moÅ¼e uczyÄ‡ siÄ™ nowych umiejÄ™tnoÅ›ci lub adaptowaÄ‡ siÄ™ do zmieniajÄ…cego siÄ™ Å›rodowiska w czasie rzeczywistym.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Uczenie Poza PamiÄ™ciÄ… (Out-of-core Learning)\n",
    "\n",
    "Uczenie poza pamiÄ™ciÄ… to zastosowanie algorytmÃ³w uczenia przyrostowego do trenowania systemÃ³w na **ogromnych zbiorach danych, ktÃ³re nie mieszczÄ… siÄ™ w pamiÄ™ci gÅ‚Ã³wnej jednej maszyny**.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Algorytm Å‚aduje czÄ™Å›Ä‡ danych (mini-partiÄ™), wykonuje krok treningowy na tych danych, a nastÄ™pnie powtarza proces, aÅ¼ przetworzy wszystkie dane. ChociaÅ¼ jest to forma uczenia przyrostowego, czÄ™sto odbywa siÄ™ offline (tj. nie na systemie dziaÅ‚ajÄ…cym na Å¼ywo), dlatego nazwa \"online learning\" moÅ¼e byÄ‡ mylÄ…ca w tym kontekÅ›cie â€“ lepiej myÅ›leÄ‡ o tym jako o uczeniu przyrostowym.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Przetwarzanie bardzo duÅ¼ych zbiorÃ³w danych tekstowych:** Trenowanie modeli jÄ™zykowych na korpusach tekstu, ktÃ³re sÄ… zbyt duÅ¼e, aby zmieÅ›ciÄ‡ siÄ™ w pamiÄ™ci RAM.\n",
    "- **Analiza danych z sensorÃ³w IoT:** Przetwarzanie terabajtÃ³w danych z czujnikÃ³w, gdzie dane sÄ… Å‚adowane i przetwarzane w maÅ‚ych fragmentach.\n",
    "- **Big Data w chmurze:** Trenowanie modeli na ogromnych zbiorach danych przechowywanych w rozproszonych systemach plikÃ³w, gdzie dane sÄ… strumieniowane do algorytmu.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ WspÃ³Å‚czynnik Uczenia (Learning Rate)\n",
    "\n",
    "WspÃ³Å‚czynnik uczenia (learning rate) to kluczowy parametr w systemach uczenia przyrostowego, ktÃ³ry okreÅ›la, **jak szybko system powinien adaptowaÄ‡ siÄ™ do zmieniajÄ…cych siÄ™ danych**.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "- **Wysoki wspÃ³Å‚czynnik uczenia:**\n",
    "    - **Zalety:** System szybko adaptuje siÄ™ do nowych danych.\n",
    "    - **Wady:** Ma tendencjÄ™ do szybkiego zapominania starych danych. MoÅ¼e byÄ‡ rÃ³wnieÅ¼ bardziej wraÅ¼liwy na szum w nowych danych lub na sekwencje niereprezentatywnych punktÃ³w danych (outlierÃ³w).\n",
    "    - **Kiedy uÅ¼ywaÄ‡:** Gdy dane zmieniajÄ… siÄ™ bardzo szybko i chcemy, aby model reagowaÅ‚ natychmiast, nawet kosztem zapominania przeszÅ‚oÅ›ci (np. bardzo dynamiczne rynki finansowe).\n",
    "- **Niski wspÃ³Å‚czynnik uczenia:**\n",
    "    - **Zalety:** System ma wiÄ™kszÄ… inercjÄ™, uczy siÄ™ wolniej, ale jest mniej wraÅ¼liwy na szum w nowych danych lub na pojedyncze odstÄ™pstwa. Lepiej zachowuje wiedzÄ™ o starych danych.\n",
    "    - **Wady:** Wolniejsza adaptacja do istotnych zmian w danych.\n",
    "    - **Kiedy uÅ¼ywaÄ‡:** Gdy dane sÄ… stosunkowo stabilne, ale chcemy, aby model stopniowo adaptowaÅ‚ siÄ™ do subtelnych zmian, jednoczeÅ›nie zachowujÄ…c wiedzÄ™ o ogÃ³lnych wzorcach (np. filtr spamu, ktÃ³ry nie powinien zapominaÄ‡ o starych typach spamu).\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Filtr spamu:** Chcemy, aby filtr spamu uczyÅ‚ siÄ™ o nowych typach spamu, ale nie zapominaÅ‚ o starych. Zbyt wysoki wspÃ³Å‚czynnik uczenia mÃ³gÅ‚by sprawiÄ‡, Å¼e filtr oznaczaÅ‚by tylko najnowsze rodzaje spamu, ignorujÄ…c te, ktÃ³re pojawiÅ‚y siÄ™ wczeÅ›niej.\n",
    "- **System rekomendacji:** JeÅ›li wspÃ³Å‚czynnik uczenia jest zbyt wysoki, system moÅ¼e zbyt szybko zmieniaÄ‡ rekomendacje na podstawie kilku ostatnich interakcji, ignorujÄ…c dÅ‚ugoterminowe preferencje uÅ¼ytkownika.\n",
    "- **Sterowanie robotem:** Zbyt wysoki wspÃ³Å‚czynnik uczenia moÅ¼e sprawiÄ‡, Å¼e robot bÄ™dzie reagowaÅ‚ zbyt gwaÅ‚townie na drobne zakÅ‚Ã³cenia, co moÅ¼e prowadziÄ‡ do niestabilnoÅ›ci.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Wyzwania i Monitorowanie (Challenges and Monitoring)\n",
    "\n",
    "Uczenie przyrostowe niesie ze sobÄ… pewne wyzwania, zwÅ‚aszcza w kontekÅ›cie jakoÅ›ci danych.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "JeÅ›li do systemu zostanÄ… dostarczone zÅ‚e dane (np. z wadliwego sensora, celowe spamowanie), wydajnoÅ›Ä‡ systemu moÅ¼e stopniowo spadaÄ‡. W systemach dziaÅ‚ajÄ…cych na Å¼ywo klienci szybko to zauwaÅ¼Ä….\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Wadliwy sensor robota:** JeÅ›li sensor robota zacznie dziaÅ‚aÄ‡ nieprawidÅ‚owo, dostarczajÄ…c bÅ‚Ä™dne dane, robot moÅ¼e nauczyÄ‡ siÄ™ zÅ‚ych zachowaÅ„, co doprowadzi do awarii.\n",
    "- **Spamowanie wyszukiwarki:** Osoby prÃ³bujÄ…ce manipulowaÄ‡ wynikami wyszukiwania mogÄ… dostarczaÄ‡ \"zÅ‚e\" dane, ktÃ³re mogÄ… sprawiÄ‡, Å¼e algorytm wyszukiwarki zacznie promowaÄ‡ nieistotne treÅ›ci.\n",
    "- **ZÅ‚oÅ›liwe ataki na systemy AI:** AtakujÄ…cy mogÄ… celowo dostarczaÄ‡ znieksztaÅ‚cone dane, aby \"otruÄ‡\" model i obniÅ¼yÄ‡ jego wydajnoÅ›Ä‡ lub zmusiÄ‡ go do bÅ‚Ä™dnych decyzji.\n",
    "\n",
    "#### RozwiÄ…zania:\n",
    "- **ÅšcisÅ‚e monitorowanie:** Konieczne jest ciÄ…gÅ‚e monitorowanie wydajnoÅ›ci systemu.\n",
    "- **WyÅ‚Ä…czanie uczenia:** W przypadku wykrycia spadku wydajnoÅ›ci, naleÅ¼y szybko wyÅ‚Ä…czyÄ‡ uczenie (i ewentualnie przywrÃ³ciÄ‡ system do poprzedniego, dziaÅ‚ajÄ…cego stanu).\n",
    "- **Monitorowanie danych wejÅ›ciowych:** Stosowanie algorytmÃ³w wykrywania anomalii (np. z uczenia nienadzorowanego) do monitorowania danych wejÅ›ciowych i reagowania na nietypowe dane.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu (Online Learning):\n",
    "1. **Inicjalizacja modelu** â€“ model jest inicjowany (czÄ™sto na maÅ‚ym zbiorze danych lub losowo).  \n",
    "2. **CiÄ…gÅ‚e dostarczanie danych** â€“ system otrzymuje instancje danych sekwencyjnie (pojedynczo lub w mini-partiach).  \n",
    "3. **Krok uczenia** â€“ dla kaÅ¼dej instancji/mini-partii, model aktualizuje swoje wagi.  \n",
    "4. **Odrzucanie danych** â€“ po przetworzeniu, dane mogÄ… zostaÄ‡ odrzucone (opcjonalnie, jeÅ›li nie ma potrzeby ich ponownego uÅ¼ycia).  \n",
    "5. **CiÄ…gÅ‚e monitorowanie** â€“ wydajnoÅ›Ä‡ systemu jest stale monitorowana, a dane wejÅ›ciowe sprawdzane pod kÄ…tem anomalii.  \n",
    "6. **Adaptacja** â€“ model nieustannie adaptuje siÄ™ do nowych danych i zmieniajÄ…cych siÄ™ warunkÃ³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Systemy rekomendacji w czasie rzeczywistym:** Adaptacja rekomendacji na platformach e-commerce, streamingowych.\n",
    "- **Filtry spamu i wykrywanie oszustw:** Szybka adaptacja do nowych wzorcÃ³w spamu lub oszustw.\n",
    "- **Prognozowanie finansowe:** Modele przewidujÄ…ce ruchy na gieÅ‚dzie, kursy walut.\n",
    "- **Personalizacja interfejsÃ³w uÅ¼ytkownika:** Dostosowywanie wyglÄ…du i funkcji aplikacji do indywidualnych preferencji uÅ¼ytkownika w czasie rzeczywistym.\n",
    "- **Robotyka i sterowanie autonomiczne:** Roboty uczÄ…ce siÄ™ nawigacji, manipulacji obiektami, adaptujÄ…ce siÄ™ do nieprzewidywalnych Å›rodowisk.\n",
    "- **Systemy monitorowania zdrowia:** Analiza danych z urzÄ…dzeÅ„ noszonych (wearables) i adaptacja do zmieniajÄ…cego siÄ™ stanu zdrowia uÅ¼ytkownika.\n",
    "- **Optymalizacja reklam:** Dynamiczne dostosowywanie wyÅ›wietlanych reklam na podstawie bieÅ¼Ä…cych interakcji uÅ¼ytkownika."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cb721",
   "metadata": {},
   "source": [
    "## Uczenie z PrzykÅ‚adu (Instance-based Learning)\n",
    "\n",
    "Uczenie z przykÅ‚adu to paradygmat uczenia maszynowego, w ktÃ³rym system **nie buduje jawnego modelu** na podstawie danych treningowych. Zamiast tego, **zapamiÄ™tuje wszystkie (lub wiÄ™kszoÅ›Ä‡) przykÅ‚ady treningowe** i uogÃ³lnia na nowe przypadki, porÃ³wnujÄ…c je z zapamiÄ™tanymi przykÅ‚adami za pomocÄ… **miary podobieÅ„stwa**.  \n",
    "MoÅ¼na to bardzo prosto opisaÄ‡ jako **\"kucie na blachÄ™\"** przez maszynÄ™ danych treningowych, a nastÄ™pnie podejmowanie decyzji na podstawie tego, co \"zapamiÄ™taÅ‚a\" i jak bardzo nowy przypadek jest podobny do tych zapamiÄ™tanych.\n",
    "\n",
    "#### Dlaczego Instance-based Learning?\n",
    "- **Prostota koncepcyjna:** Jest to jedna z najbardziej intuicyjnych form uczenia siÄ™.\n",
    "- **Brak jawnego modelu:** Nie ma potrzeby budowania zÅ‚oÅ¼onego modelu matematycznego, co moÅ¼e byÄ‡ zaletÄ… w niektÃ³rych scenariuszach.\n",
    "- **ElastycznoÅ›Ä‡:** MoÅ¼e adaptowaÄ‡ siÄ™ do zÅ‚oÅ¼onych granic decyzyjnych, poniewaÅ¼ nie narzuca sztywnej struktury modelu.\n",
    "- **ÅatwoÅ›Ä‡ aktualizacji:** Dodawanie nowych danych treningowych jest proste â€“ wystarczy je zapamiÄ™taÄ‡.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ ZapamiÄ™tywanie Danych (Learning by Heart)\n",
    "\n",
    "Najbardziej trywialnÄ… formÄ… uczenia siÄ™ z przykÅ‚adu jest po prostu **zapamiÄ™tywanie danych treningowych**.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "System przechowuje wszystkie przykÅ‚ady treningowe. Kiedy pojawia siÄ™ nowa instancja, system porÃ³wnuje jÄ… z zapamiÄ™tanymi przykÅ‚adami.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Filtr spamu (bardzo podstawowy):** System zapamiÄ™tuje wszystkie wiadomoÅ›ci e-mail, ktÃ³re zostaÅ‚y oznaczone przez uÅ¼ytkownikÃ³w jako spam. Nowa wiadomoÅ›Ä‡ jest oznaczana jako spam tylko wtedy, gdy jest **identyczna** z ktÃ³rÄ…Å› z zapamiÄ™tanych wiadomoÅ›ci spamowych. To nie jest najlepsze rozwiÄ…zanie, ale pokazuje podstawowÄ… ideÄ™.\n",
    "- **Bazy danych przypadkÃ³w:** W systemach eksperckich, gdzie system przechowuje historyczne przypadki i ich rozwiÄ…zania, a nastÄ™pnie szuka identycznego przypadku dla nowej sytuacji.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ UogÃ³lnianie przez PodobieÅ„stwo (Generalization by Similarity)\n",
    "\n",
    "Prawdziwa moc uczenia z przykÅ‚adu objawia siÄ™, gdy system uogÃ³lnia na nowe przypadki, wykorzystujÄ…c **miarÄ™ podobieÅ„stwa** do porÃ³wnywania ich z zapamiÄ™tanymi przykÅ‚adami.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Zamiast szukaÄ‡ identycznych przykÅ‚adÃ³w, system szuka przykÅ‚adÃ³w **bardzo podobnych**. Nowa instancja jest klasyfikowana lub przewidywana na podstawie etykiet (lub wartoÅ›ci) najbardziej podobnych zapamiÄ™tanych przykÅ‚adÃ³w.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Filtr spamu (ulepszony):** System nie tylko oznacza e-maile identyczne ze znanym spamem, ale takÅ¼e te, ktÃ³re sÄ… **bardzo podobne**. Miara podobieÅ„stwa moÅ¼e polegaÄ‡ na zliczaniu wspÃ³lnych sÅ‚Ã³w. JeÅ›li nowa wiadomoÅ›Ä‡ ma wiele wspÃ³lnych sÅ‚Ã³w ze znanym spamem, zostanie oznaczona jako spam.\n",
    "- **Systemy rekomendacji (najbliÅ¼si sÄ…siedzi):** JeÅ›li uÅ¼ytkownik oglÄ…da film, system szuka innych uÅ¼ytkownikÃ³w, ktÃ³rzy oglÄ…dali podobne filmy, a nastÄ™pnie rekomenduje filmy, ktÃ³re oglÄ…dali ci \"sÄ…siedzi\".\n",
    "- **Rozpoznawanie pisma rÄ™cznego:** Nowy znak jest porÃ³wnywany z zapamiÄ™tanymi przykÅ‚adami kaÅ¼dego znaku. JeÅ›li jest najbardziej podobny do zapamiÄ™tanych \"A\", zostanie sklasyfikowany jako \"A\".\n",
    "- **Diagnostyka medyczna:** Nowy pacjent jest porÃ³wnywany z historycznymi pacjentami o podobnych objawach i wynikach badaÅ„, a diagnoza jest sugerowana na podstawie diagnoz tych podobnych pacjentÃ³w.\n",
    "- **Klasyfikacja obrazÃ³w (np. k-NN):** Nowy obraz jest klasyfikowany jako naleÅ¼Ä…cy do klasy, do ktÃ³rej naleÅ¼y wiÄ™kszoÅ›Ä‡ jego \"najbliÅ¼szych sÄ…siadÃ³w\" w przestrzeni cech.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Miara PodobieÅ„stwa (Similarity Measure)\n",
    "\n",
    "Miara podobieÅ„stwa jest kluczowym elementem uczenia z przykÅ‚adu. Definiuje, jak \"blisko\" sÄ… ze sobÄ… dwie instancje danych.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Miara podobieÅ„stwa (lub jej odwrotnoÅ›Ä‡ â€“ miara odlegÅ‚oÅ›ci) jest funkcjÄ…, ktÃ³ra przypisuje wartoÅ›Ä‡ liczbowÄ… parze instancji danych, wskazujÄ…cÄ… na ich podobieÅ„stwo. Im wyÅ¼sza wartoÅ›Ä‡ (dla podobieÅ„stwa) lub niÅ¼sza (dla odlegÅ‚oÅ›ci), tym bardziej podobne sÄ… instancje.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Liczba wspÃ³lnych sÅ‚Ã³w:** Dla tekstu, prosta miara podobieÅ„stwa to liczba wspÃ³lnych sÅ‚Ã³w miÄ™dzy dwoma dokumentami.\n",
    "- **OdlegÅ‚oÅ›Ä‡ euklidesowa:** Dla danych liczbowych, odlegÅ‚oÅ›Ä‡ euklidesowa w przestrzeni cech jest czÄ™sto uÅ¼ywana jako miara niepodobieÅ„stwa (im mniejsza odlegÅ‚oÅ›Ä‡, tym wiÄ™ksze podobieÅ„stwo).\n",
    "- **PodobieÅ„stwo kosinusowe:** CzÄ™sto uÅ¼ywane dla wektorÃ³w cech (np. w NLP), mierzy kÄ…t miÄ™dzy wektorami.\n",
    "- **OdlegÅ‚oÅ›Ä‡ Hamminga:** Dla danych binarnych, zlicza liczbÄ™ pozycji, na ktÃ³rych dwa ciÄ…gi bitÃ³w siÄ™ rÃ³Å¼niÄ….\n",
    "- **Dopasowanie cech:** Dla obrazÃ³w, miara podobieÅ„stwa moÅ¼e opieraÄ‡ siÄ™ na dopasowaniu kluczowych punktÃ³w lub deskryptorÃ³w cech.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu (Instance-based Learning):\n",
    "1. **Zbieranie danych treningowych** â€“ wszystkie dostÄ™pne dane sÄ… gromadzone.  \n",
    "2. **ZapamiÄ™tywanie danych** â€“ system po prostu przechowuje wszystkie instancje danych treningowych.  \n",
    "3. **Pojawienie siÄ™ nowej instancji** â€“ system otrzymuje nowÄ… instancjÄ™, dla ktÃ³rej musi dokonaÄ‡ przewidywania.  \n",
    "4. **Obliczanie podobieÅ„stwa** â€“ system oblicza podobieÅ„stwo (lub odlegÅ‚oÅ›Ä‡) miÄ™dzy nowÄ… instancjÄ… a kaÅ¼dÄ… (lub wybranymi) zapamiÄ™tanÄ… instancjÄ… treningowÄ….  \n",
    "5. **UogÃ³lnianie** â€“ na podstawie miary podobieÅ„stwa, system identyfikuje najbardziej podobne instancje treningowe i wykorzystuje ich etykiety/wartoÅ›ci do przewidywania dla nowej instancji (np. gÅ‚osowanie wiÄ™kszoÅ›ciowe w k-NN).  \n",
    "6. **Brak jawnego etapu \"treningu\"** â€“ w tradycyjnym sensie nie ma etapu, w ktÃ³rym model uczy siÄ™ parametrÃ³w; wiedza jest po prostu przechowywana.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Systemy rekomendacji (k-Nearest Neighbors - k-NN):** Rekomendowanie produktÃ³w lub treÅ›ci na podstawie tego, co lubiÄ… \"najbliÅ¼si sÄ…siedzi\" uÅ¼ytkownika.\n",
    "- **Klasyfikacja obrazÃ³w:** Klasyfikacja obrazÃ³w poprzez porÃ³wnanie ich z bazÄ… danych oznaczonych obrazÃ³w.\n",
    "- **Diagnostyka medyczna:** Wspomaganie diagnozy poprzez wyszukiwanie podobnych przypadkÃ³w pacjentÃ³w.\n",
    "- **Wykrywanie oszustw:** Identyfikacja transakcji podobnych do znanych oszukaÅ„czych transakcji.\n",
    "- **Wyszukiwanie podobieÅ„stw:** Wyszukiwanie podobnych dokumentÃ³w, obrazÃ³w, produktÃ³w w duÅ¼ych bazach danych.\n",
    "- **Systemy eksperckie oparte na przypadkach (Case-Based Reasoning - CBR):** RozwiÄ…zywanie nowych problemÃ³w poprzez adaptacjÄ™ rozwiÄ…zaÅ„ z podobnych, historycznych problemÃ³w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f785f",
   "metadata": {},
   "source": [
    "## Uczenie z Modelu (Model-based Learning)\n",
    "\n",
    "Uczenie z modelu to paradygmat uczenia maszynowego, w ktÃ³rym system **buduje model matematyczny** na podstawie danych treningowych, a nastÄ™pnie wykorzystuje ten model do **przewidywania** dla nowych przypadkÃ³w.  \n",
    "W przeciwieÅ„stwie do uczenia z przykÅ‚adu, gdzie system zapamiÄ™tuje konkretne przypadki, tutaj system **uogÃ³lnia** poprzez stworzenie abstrakcyjnego modelu, ktÃ³ry opisuje zaleÅ¼noÅ›ci w danych.\n",
    "\n",
    "#### Dlaczego Model-based Learning?\n",
    "- **EfektywnoÅ›Ä‡:** Model moÅ¼e dokonywaÄ‡ przewidywaÅ„ bez koniecznoÅ›ci przechowywania wszystkich danych treningowych.\n",
    "- **UogÃ³lnianie:** Model moÅ¼e przewidywaÄ‡ dla przypadkÃ³w, ktÃ³re nie sÄ… identyczne z Å¼adnym przypadkiem treningowym.\n",
    "- **InterpretowalnoÅ›Ä‡:** Modele matematyczne czÄ™sto pozwalajÄ… na zrozumienie zaleÅ¼noÅ›ci miÄ™dzy zmiennymi.\n",
    "- **SkalowalnoÅ›Ä‡:** MoÅ¼e dziaÅ‚aÄ‡ na duÅ¼ych zbiorach danych bez problemÃ³w z pamiÄ™ciÄ….\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Budowanie Modelu (Model Building)\n",
    "\n",
    "Proces budowania modelu polega na znalezieniu **matematycznej funkcji**, ktÃ³ra najlepiej opisuje zaleÅ¼noÅ›Ä‡ miÄ™dzy cechami wejÅ›ciowymi a wartoÅ›ciÄ… docelowÄ….\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "1. **WybÃ³r typu modelu** â€“ decyzja o strukturze matematycznej (np. funkcja liniowa, wielomianowa).\n",
    "2. **Trenowanie modelu** â€“ znalezienie parametrÃ³w modelu, ktÃ³re najlepiej dopasowujÄ… siÄ™ do danych treningowych.\n",
    "3. **Walidacja** â€“ sprawdzenie, jak dobrze model radzi sobie z nowymi danymi.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Regresja liniowa:** Model opisuje zaleÅ¼noÅ›Ä‡ miÄ™dzy cenÄ… domu a jego powierzchniÄ… za pomocÄ… prostej linii: `cena = Î¸â‚€ + Î¸â‚ Ã— powierzchnia`\n",
    "- **Regresja wielomianowa:** Model opisuje bardziej zÅ‚oÅ¼one zaleÅ¼noÅ›ci za pomocÄ… krzywej wielomianowej.\n",
    "- **Drzewa decyzyjne:** Model opisuje zaleÅ¼noÅ›ci za pomocÄ… hierarchii reguÅ‚ if-then.\n",
    "- **Sieci neuronowe:** Model opisuje zÅ‚oÅ¼one, nieliniowe zaleÅ¼noÅ›ci za pomocÄ… poÅ‚Ä…czonych wÄ™zÅ‚Ã³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ WybÃ³r Modelu (Model Selection)\n",
    "\n",
    "WybÃ³r modelu to proces **decydowania o strukturze matematycznej**, ktÃ³ra bÄ™dzie najlepiej opisywaÄ‡ dane.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Na podstawie analizy danych (np. wykresÃ³w rozrzutu, korelacji) wybieramy typ funkcji, ktÃ³ra prawdopodobnie najlepiej opisze zaleÅ¼noÅ›Ä‡ w danych.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Dane liniowe:** JeÅ›li wykres rozrzutu pokazuje liniowÄ… zaleÅ¼noÅ›Ä‡, wybieramy model liniowy.\n",
    "- **Dane wykÅ‚adnicze:** JeÅ›li zaleÅ¼noÅ›Ä‡ jest wykÅ‚adnicza, wybieramy model wykÅ‚adniczy.\n",
    "- **Dane cykliczne:** JeÅ›li dane majÄ… charakter cykliczny (np. sezonowoÅ›Ä‡), wybieramy model sinusoidalny.\n",
    "- **ZÅ‚oÅ¼one dane:** JeÅ›li zaleÅ¼noÅ›Ä‡ jest bardzo zÅ‚oÅ¼ona, wybieramy model nieliniowy (np. sieÄ‡ neuronowÄ…).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Parametry Modelu (Model Parameters)\n",
    "\n",
    "Parametry modelu to **wartoÅ›ci liczbowe**, ktÃ³re definiujÄ… konkretnÄ… instancjÄ™ wybranego typu modelu.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "KaÅ¼dy typ modelu ma swoje charakterystyczne parametry. Algorytm treningowy znajduje wartoÅ›ci tych parametrÃ³w, ktÃ³re najlepiej dopasowujÄ… model do danych treningowych.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Model liniowy:** `y = Î¸â‚€ + Î¸â‚x` ma parametry Î¸â‚€ (przeciÄ™cie z osiÄ… Y) i Î¸â‚ (nachylenie linii).\n",
    "- **Model kwadratowy:** `y = Î¸â‚€ + Î¸â‚x + Î¸â‚‚xÂ²` ma parametry Î¸â‚€, Î¸â‚, Î¸â‚‚.\n",
    "- **SieÄ‡ neuronowa:** Ma tysiÄ…ce parametrÃ³w (wagi i bias) w rÃ³Å¼nych warstwach.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Funkcja Kosztu (Cost Function)\n",
    "\n",
    "Funkcja kosztu to **miara jakoÅ›ci** modelu, ktÃ³ra okreÅ›la, jak bardzo przewidywania modelu odbiegajÄ… od rzeczywistych wartoÅ›ci w danych treningowych.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Funkcja kosztu oblicza rÃ³Å¼nicÄ™ miÄ™dzy przewidywaniami modelu a rzeczywistymi wartoÅ›ciami. Celem treningu jest **minimalizacja** tej funkcji kosztu.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Mean Squared Error (MSE):** Åšrednia kwadratÃ³w rÃ³Å¼nic miÄ™dzy przewidywaniami a rzeczywistymi wartoÅ›ciami.\n",
    "- **Mean Absolute Error (MAE):** Åšrednia wartoÅ›ci bezwzglÄ™dnych rÃ³Å¼nic.\n",
    "- **Cross-entropy:** UÅ¼ywana w klasyfikacji, mierzy rÃ³Å¼nicÄ™ miÄ™dzy rozkÅ‚adami prawdopodobieÅ„stwa.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Trenowanie Modelu (Model Training)\n",
    "\n",
    "Trenowanie modelu to proces **znajdowania optymalnych parametrÃ³w** poprzez minimalizacjÄ™ funkcji kosztu.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Algorytm treningowy (np. Gradient Descent) iteracyjnie dostosowuje parametry modelu, aby zmniejszyÄ‡ rÃ³Å¼nicÄ™ miÄ™dzy przewidywaniami a rzeczywistymi wartoÅ›ciami.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Regresja liniowa:** Algorytm znajduje Î¸â‚€ i Î¸â‚, ktÃ³re minimalizujÄ… MSE.\n",
    "- **Sieci neuronowe:** Algorytm backpropagation dostosowuje wagi w sieci.\n",
    "- **Drzewa decyzyjne:** Algorytm znajduje optymalne podziaÅ‚y wÄ™zÅ‚Ã³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Przewidywanie (Prediction/Inference)\n",
    "\n",
    "Po wytrenowaniu modelu moÅ¼na go uÅ¼ywaÄ‡ do **przewidywania wartoÅ›ci** dla nowych przypadkÃ³w.\n",
    "\n",
    "#### Jak to dziaÅ‚a:\n",
    "Nowe dane wejÅ›ciowe sÄ… podawane do wytrenowanego modelu, ktÃ³ry oblicza przewidywanÄ… wartoÅ›Ä‡ na podstawie wyuczonych parametrÃ³w.\n",
    "\n",
    "#### PrzykÅ‚ady praktyczne:\n",
    "- **Prognozowanie cen:** Podanie powierzchni nowego domu do modelu, ktÃ³ry zwraca przewidywanÄ… cenÄ™.\n",
    "- **Klasyfikacja obrazÃ³w:** Podanie nowego obrazu do modelu, ktÃ³ry zwraca prawdopodobieÅ„stwo przynaleÅ¼noÅ›ci do kaÅ¼dej klasy.\n",
    "- **Rekomendacje:** Podanie preferencji uÅ¼ytkownika do modelu, ktÃ³ry zwraca ocenÄ™ dla rÃ³Å¼nych produktÃ³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ PrzykÅ‚ad: Czy pieniÄ…dze czyniÄ… ludzi szczÄ™Å›liwymi?\n",
    "\n",
    "RozwaÅ¼my przykÅ‚ad z ksiÄ…Å¼ki, gdzie chcemy zbadaÄ‡ zaleÅ¼noÅ›Ä‡ miÄ™dzy PKB per capita a poziomem zadowolenia z Å¼ycia.\n",
    "\n",
    "#### Dane:\n",
    "| Kraj | PKB per capita (USD) | Zadowolenie z Å¼ycia |\n",
    "|------|---------------------|-------------------|\n",
    "| WÄ™gry | 12,240 | 4.9 |\n",
    "| Korea | 27,195 | 5.8 |\n",
    "| Francja | 37,675 | 6.5 |\n",
    "| Australia | 50,962 | 7.3 |\n",
    "| USA | 55,805 | 7.2 |\n",
    "\n",
    "#### Analiza:\n",
    "Po wykreÅ›leniu danych widzimy **liniowÄ… tendencjÄ™** - zadowolenie z Å¼ycia roÅ›nie wraz ze wzrostem PKB per capita.\n",
    "\n",
    "#### Model:\n",
    "Wybieramy **model liniowy**: `zadowolenie_z_Å¼ycia = Î¸â‚€ + Î¸â‚ Ã— PKB_per_capita`\n",
    "\n",
    "#### Trenowanie:\n",
    "Algorytm regresji liniowej znajduje optymalne parametry:\n",
    "- Î¸â‚€ = 4.85\n",
    "- Î¸â‚ = 4.91 Ã— 10â»âµ\n",
    "\n",
    "#### Przewidywanie:\n",
    "Dla Cypru z PKB per capita = $22,587:\n",
    "`zadowolenie_z_Å¼ycia = 4.85 + 22,587 Ã— 4.91 Ã— 10â»âµ = 5.96`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ PorÃ³wnanie z Uczeniem z PrzykÅ‚adu:\n",
    "\n",
    "| Cecha | Uczenie z PrzykÅ‚adu | Uczenie z Modelu |\n",
    "|-------|-------------------|------------------|\n",
    "| **Przechowywanie danych** | Wszystkie przykÅ‚ady treningowe | Tylko parametry modelu |\n",
    "| **Przewidywanie** | PorÃ³wnanie z zapamiÄ™tanymi przykÅ‚adami | Obliczenie na podstawie modelu |\n",
    "| **PamiÄ™Ä‡** | Wymaga duÅ¼o pamiÄ™ci | Wymaga maÅ‚o pamiÄ™ci |\n",
    "| **SzybkoÅ›Ä‡ przewidywania** | Wolne (porÃ³wnanie z wszystkimi przykÅ‚adami) | Szybkie (obliczenie matematyczne) |\n",
    "| **UogÃ³lnianie** | Ograniczone do podobnych przypadkÃ³w | MoÅ¼e przewidywaÄ‡ dla nowych przypadkÃ³w |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Proces uczenia modelu (Model-based Learning):\n",
    "1. **Analiza danych** â€“ zbadanie struktury i zaleÅ¼noÅ›ci w danych treningowych.  \n",
    "2. **WybÃ³r modelu** â€“ decyzja o typie funkcji matematycznej (liniowa, wielomianowa, itp.).  \n",
    "3. **Definicja funkcji kosztu** â€“ okreÅ›lenie miary jakoÅ›ci modelu.  \n",
    "4. **Trenowanie modelu** â€“ znalezienie optymalnych parametrÃ³w poprzez minimalizacjÄ™ funkcji kosztu.  \n",
    "5. **Walidacja modelu** â€“ sprawdzenie jakoÅ›ci modelu na danych testowych.  \n",
    "6. **Przewidywanie** â€“ uÅ¼ycie wytrenowanego modelu do przewidywania dla nowych przypadkÃ³w.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Zastosowania w realnym Å›wiecie:\n",
    "- **Prognozowanie cen nieruchomoÅ›ci** na podstawie powierzchni, lokalizacji i innych cech.\n",
    "- **Klasyfikacja obrazÃ³w** â€“ rozpoznawanie obiektÃ³w na zdjÄ™ciach.\n",
    "- **Systemy rekomendacji** â€“ przewidywanie ocen uÅ¼ytkownikÃ³w dla produktÃ³w.\n",
    "- **Prognozowanie sprzedaÅ¼y** â€“ przewidywanie popytu na produkty.\n",
    "- **Diagnostyka medyczna** â€“ przewidywanie prawdopodobieÅ„stwa chorÃ³b na podstawie objawÃ³w.\n",
    "- **Analiza sentymentu** â€“ klasyfikacja emocji w tekÅ›cie.\n",
    "- **Optymalizacja procesÃ³w** â€“ znajdowanie optymalnych parametrÃ³w procesÃ³w przemysÅ‚owych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrzykÅ‚ad implementacji uczenia z modelu - Regresja liniowa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Tworzenie przykÅ‚adowych danych (PKB per capita vs zadowolenie z Å¼ycia)\n",
    "data = {\n",
    "    'Country': ['Hungary', 'Korea', 'France', 'Australia', 'USA'],\n",
    "    'GDP_per_capita': [12240, 27195, 37675, 50962, 55805],\n",
    "    'Life_satisfaction': [4.9, 5.8, 6.5, 7.3, 7.2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dane treningowe:\")\n",
    "print(df)\n",
    "\n",
    "# Przygotowanie danych\n",
    "X = df[['GDP_per_capita']].values  # Features (cechy)\n",
    "y = df['Life_satisfaction'].values  # Target (cel)\n",
    "\n",
    "print(f\"\\nX (PKB per capita): {X.flatten()}\")\n",
    "print(f\"y (zadowolenie z Å¼ycia): {y}\")\n",
    "\n",
    "# Wizualizacja danych\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue')\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('ZaleÅ¼noÅ›Ä‡ miÄ™dzy PKB per capita a zadowoleniem z Å¼ycia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie nazw krajÃ³w do punktÃ³w\n",
    "for i, country in enumerate(df['Country']):\n",
    "    plt.annotate(country, (X[i][0], y[i]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenowanie modelu regresji liniowej\n",
    "print(\"=== TRENOWANIE MODELU REGRESJI LINIOWEJ ===\")\n",
    "\n",
    "# WybÃ³r modelu\n",
    "model = LinearRegression()\n",
    "\n",
    "# Trenowanie modelu\n",
    "model.fit(X, y)\n",
    "\n",
    "# WyÅ›wietlenie parametrÃ³w modelu\n",
    "print(f\"Parametry modelu:\")\n",
    "print(f\"Î¸â‚€ (intercept): {model.intercept_:.2f}\")\n",
    "print(f\"Î¸â‚ (slope): {model.coef_[0]:.6f}\")\n",
    "\n",
    "# RÃ³wnanie modelu\n",
    "print(f\"\\nRÃ³wnanie modelu:\")\n",
    "print(f\"zadowolenie_z_Å¼ycia = {model.intercept_:.2f} + {model.coef_[0]:.6f} Ã— PKB_per_capita\")\n",
    "\n",
    "# Przewidywanie dla Cypru (PKB per capita = $22,587)\n",
    "cyprus_gdp = [[22587]]\n",
    "prediction = model.predict(cyprus_gdp)\n",
    "print(f\"\\nPrzewidywanie dla Cypru (PKB per capita = $22,587):\")\n",
    "print(f\"Przewidywane zadowolenie z Å¼ycia: {prediction[0]:.2f}\")\n",
    "\n",
    "# Wizualizacja modelu\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Wykres rozrzutu danych\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('Dane treningowe')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie nazw krajÃ³w\n",
    "for i, country in enumerate(df['Country']):\n",
    "    plt.annotate(country, (X[i][0], y[i]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Wykres z modelem\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "\n",
    "# Linia regresji\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(X_line)\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=2, label='Model liniowy')\n",
    "\n",
    "# Przewidywanie dla Cypru\n",
    "plt.scatter(cyprus_gdp, prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr: {prediction[0]:.2f}')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('Model regresji liniowej')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ocena jakoÅ›ci modelu\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Przewidywania na danych treningowych\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Metryki\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"\\n=== OCENA JAKOÅšCI MODELU ===\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.4f}\")\n",
    "\n",
    "# PorÃ³wnanie rzeczywistych i przewidywanych wartoÅ›ci\n",
    "print(f\"\\nPorÃ³wnanie rzeczywistych i przewidywanych wartoÅ›ci:\")\n",
    "comparison_df = df.copy()\n",
    "comparison_df['Predicted'] = y_pred\n",
    "comparison_df['Error'] = comparison_df['Life_satisfaction'] - comparison_df['Predicted']\n",
    "print(comparison_df[['Country', 'Life_satisfaction', 'Predicted', 'Error']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PorÃ³wnanie z uczeniem z przykÅ‚adu (k-NN)\n",
    "print(\"=== PORÃ“WNANIE Z UCZENIEM Z PRZYKÅADU (k-NN) ===\")\n",
    "\n",
    "# Model k-NN (uczenie z przykÅ‚adu)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_model.fit(X, y)\n",
    "\n",
    "# Przewidywanie dla Cypru\n",
    "knn_prediction = knn_model.predict(cyprus_gdp)\n",
    "print(f\"Przewidywanie k-NN dla Cypru: {knn_prediction[0]:.2f}\")\n",
    "\n",
    "# PorÃ³wnanie wynikÃ³w\n",
    "print(f\"\\n=== PORÃ“WNANIE WYNIKÃ“W ===\")\n",
    "print(f\"Regresja liniowa (model-based): {prediction[0]:.2f}\")\n",
    "print(f\"k-NN (instance-based): {knn_prediction[0]:.2f}\")\n",
    "print(f\"RÃ³Å¼nica: {abs(prediction[0] - knn_prediction[0]):.2f}\")\n",
    "\n",
    "# Wizualizacja porÃ³wnania\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Wykres 1: Dane i model liniowy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(X_line)\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=2, label='Model liniowy')\n",
    "plt.scatter(cyprus_gdp, prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr: {prediction[0]:.2f}')\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('Model-based Learning\\n(Regresja liniowa)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 2: Dane i k-NN\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "\n",
    "# Znalezienie 3 najbliÅ¼szych sÄ…siadÃ³w dla Cypru\n",
    "distances, indices = knn_model.kneighbors(cyprus_gdp)\n",
    "nearest_neighbors = X[indices[0]]\n",
    "nearest_values = y[indices[0]]\n",
    "\n",
    "# PodÅ›wietlenie najbliÅ¼szych sÄ…siadÃ³w\n",
    "plt.scatter(nearest_neighbors, nearest_values, s=150, color='green', \n",
    "           marker='s', label='NajbliÅ¼si sÄ…siedzi', alpha=0.8)\n",
    "\n",
    "plt.scatter(cyprus_gdp, knn_prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr: {knn_prediction[0]:.2f}')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('Instance-based Learning\\n(k-NN, k=3)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 3: PorÃ³wnanie obu metod\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=2, label='Model liniowy')\n",
    "plt.scatter(nearest_neighbors, nearest_values, s=150, color='green', \n",
    "           marker='s', label='NajbliÅ¼si sÄ…siedzi', alpha=0.8)\n",
    "plt.scatter(cyprus_gdp, prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr (lin.): {prediction[0]:.2f}')\n",
    "plt.scatter(cyprus_gdp, knn_prediction, s=150, color='orange', marker='^', \n",
    "           label=f'Cypr (k-NN): {knn_prediction[0]:.2f}')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('PorÃ³wnanie metod')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analiza najbliÅ¼szych sÄ…siadÃ³w\n",
    "print(f\"\\n=== ANALIZA NAJBLIÅ»SZYCH SÄ„SIADÃ“W (k-NN) ===\")\n",
    "print(\"NajbliÅ¼si sÄ…siedzi Cypru:\")\n",
    "for i, (gdp, satisfaction, country) in enumerate(zip(nearest_neighbors.flatten(), \n",
    "                                                    nearest_values, \n",
    "                                                    df.iloc[indices[0]]['Country'])):\n",
    "    print(f\"{i+1}. {country}: PKB = ${gdp:,.0f}, Zadowolenie = {satisfaction}\")\n",
    "\n",
    "print(f\"\\nÅšrednia zadowolenia z Å¼ycia najbliÅ¼szych sÄ…siadÃ³w: {nearest_values.mean():.2f}\")\n",
    "print(f\"Przewidywanie k-NN: {knn_prediction[0]:.2f}\")\n",
    "\n",
    "# PorÃ³wnanie charakterystyk metod\n",
    "print(f\"\\n=== CHARAKTERYSTYKI METOD ===\")\n",
    "print(\"Model-based Learning (Regresja liniowa):\")\n",
    "print(\"- Buduje matematyczny model zaleÅ¼noÅ›ci\")\n",
    "print(\"- Szybkie przewidywania (obliczenie matematyczne)\")\n",
    "print(\"- MoÅ¼e przewidywaÄ‡ dla wartoÅ›ci poza zakresem danych treningowych\")\n",
    "print(\"- Interpretowalny (moÅ¼na zrozumieÄ‡ zaleÅ¼noÅ›Ä‡)\")\n",
    "\n",
    "print(\"\\nInstance-based Learning (k-NN):\")\n",
    "print(\"- PorÃ³wnuje z zapamiÄ™tanymi przykÅ‚adami\")\n",
    "print(\"- Wolniejsze przewidywania (obliczanie odlegÅ‚oÅ›ci)\")\n",
    "print(\"- Ograniczony do zakresu danych treningowych\")\n",
    "print(\"- Mniej interpretowalny\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodatkowe przykÅ‚ady rÃ³Å¼nych typÃ³w modeli\n",
    "print(\"=== RÃ“Å»NE TYPY MODELI W MODEL-BASED LEARNING ===\")\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Generowanie wiÄ™kszego zbioru danych dla lepszej demonstracji\n",
    "np.random.seed(42)\n",
    "X_extended = np.linspace(10000, 60000, 50).reshape(-1, 1)\n",
    "y_extended = 4.5 + 0.00005 * X_extended.flatten() + np.random.normal(0, 0.2, 50)\n",
    "\n",
    "# Przygotowanie danych\n",
    "X_train = X_extended[:40]\n",
    "y_train = y_extended[:40]\n",
    "X_test = X_extended[40:]\n",
    "y_test = y_extended[40:]\n",
    "\n",
    "print(f\"Dane treningowe: {len(X_train)} prÃ³bek\")\n",
    "print(f\"Dane testowe: {len(X_test)} prÃ³bek\")\n",
    "\n",
    "# 1. Regresja liniowa\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "linear_pred = linear_model.predict(X_test)\n",
    "\n",
    "# 2. Regresja wielomianowa (stopieÅ„ 2)\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "poly_pred = poly_model.predict(X_test_poly)\n",
    "\n",
    "# 3. Drzewo decyzyjne\n",
    "tree_model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# 4. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Wizualizacja wszystkich modeli\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Wykres 1: Dane i modele\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(X_train, y_train, alpha=0.6, color='blue', label='Dane treningowe')\n",
    "plt.scatter(X_test, y_test, alpha=0.6, color='red', label='Dane testowe')\n",
    "\n",
    "# Linie dla rÃ³Å¼nych modeli\n",
    "X_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "plt.plot(X_line, linear_model.predict(X_line), 'g-', linewidth=2, label='Regresja liniowa')\n",
    "\n",
    "X_line_poly = poly_features.transform(X_line)\n",
    "plt.plot(X_line, poly_model.predict(X_line_poly), 'm-', linewidth=2, label='Regresja wielomianowa')\n",
    "\n",
    "plt.plot(X_line, tree_model.predict(X_line), 'c-', linewidth=2, label='Drzewo decyzyjne')\n",
    "plt.plot(X_line, rf_model.predict(X_line), 'y-', linewidth=2, label='Random Forest')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z Å¼ycia')\n",
    "plt.title('PorÃ³wnanie rÃ³Å¼nych modeli')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 2: PorÃ³wnanie bÅ‚Ä™dÃ³w\n",
    "models = ['Regresja liniowa', 'Regresja wielomianowa', 'Drzewo decyzyjne', 'Random Forest']\n",
    "predictions = [linear_pred, poly_pred, tree_pred, rf_pred]\n",
    "mse_scores = [mean_squared_error(y_test, pred) for pred in predictions]\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "bars = plt.bar(models, mse_scores, color=['green', 'magenta', 'cyan', 'yellow'])\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('PorÃ³wnanie bÅ‚Ä™dÃ³w (MSE)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, score in zip(bars, mse_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 3: Rzeczywiste vs przewidywane wartoÅ›ci\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(y_test, linear_pred, alpha=0.6, label='Regresja liniowa')\n",
    "plt.scatter(y_test, poly_pred, alpha=0.6, label='Regresja wielomianowa')\n",
    "plt.scatter(y_test, tree_pred, alpha=0.6, label='Drzewo decyzyjne')\n",
    "plt.scatter(y_test, rf_pred, alpha=0.6, label='Random Forest')\n",
    "\n",
    "# Linia idealna (rzeczywiste = przewidywane)\n",
    "min_val = min(y_test.min(), min(pred.min() for pred in predictions))\n",
    "max_val = max(y_test.max(), max(pred.max() for pred in predictions))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, label='Idealna linia')\n",
    "\n",
    "plt.xlabel('Rzeczywiste wartoÅ›ci')\n",
    "plt.ylabel('Przewidywane wartoÅ›ci')\n",
    "plt.title('Rzeczywiste vs Przewidywane')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 4: Reszty (bÅ‚Ä™dy)\n",
    "plt.subplot(2, 2, 4)\n",
    "residuals = [y_test - pred for pred in predictions]\n",
    "for i, (residual, model) in enumerate(zip(residuals, models)):\n",
    "    plt.scatter(X_test, residual, alpha=0.6, label=model)\n",
    "\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Reszty (bÅ‚Ä™dy)')\n",
    "plt.title('Analiza reszt')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Podsumowanie wynikÃ³w\n",
    "print(f\"\\n=== PODSUMOWANIE WYNIKÃ“W ===\")\n",
    "for model, pred, mse in zip(models, predictions, mse_scores):\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  RÂ²: {r2:.4f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(mse):.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== WNIOSKI ===\")\n",
    "print(\"1. RÃ³Å¼ne modele majÄ… rÃ³Å¼ne charakterystyki:\")\n",
    "print(\"   - Regresja liniowa: prosta, interpretowalna\")\n",
    "print(\"   - Regresja wielomianowa: moÅ¼e modelowaÄ‡ krzywe\")\n",
    "print(\"   - Drzewo decyzyjne: moÅ¼e modelowaÄ‡ zÅ‚oÅ¼one granice\")\n",
    "print(\"   - Random Forest: Å‚Ä…czy wiele drzew, czÄ™sto lepsza wydajnoÅ›Ä‡\")\n",
    "print()\n",
    "print(\"2. WybÃ³r modelu zaleÅ¼y od:\")\n",
    "print(\"   - Charakteru danych (liniowe vs nieliniowe)\")\n",
    "print(\"   - InterpretowalnoÅ›ci vs wydajnoÅ›ci\")\n",
    "print(\"   - WielkoÅ›ci zbioru danych\")\n",
    "print(\"   - ZÅ‚oÅ¼onoÅ›ci problemu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00130c5",
   "metadata": {},
   "source": [
    "# Regresja k-NajbliÅ¼szych SÄ…siadÃ³w (k-NN) ze Wzorami Matematycznymi\n",
    "\n",
    "### Wprowadzenie do Regresji k-NajbliÅ¼szych SÄ…siadÃ³w\n",
    "\n",
    "Regresja k-najbliÅ¼szych sÄ…siadÃ³w (k-NN) to prosty i intuicyjny algorytm uczenia maszynowego z nadzorem, ktÃ³ry moÅ¼na stosowaÄ‡ zarÃ³wno do zadaÅ„ klasyfikacyjnych, jak i regresyjnych. W kontekÅ›cie regresji, celem jest przewidywanie ciÄ…gÅ‚ej wartoÅ›ci wyjÅ›ciowej (np. ceny domu, temperatury). Jest to metoda **nieparametryczna**, co oznacza, Å¼e nie zakÅ‚ada Å¼adnej konkretnej formy funkcyjnej dla danych, jak na przykÅ‚ad liniowa zaleÅ¼noÅ›Ä‡ w regresji liniowej. K-NN jest rÃ³wnieÅ¼ algorytmem \"uczenia siÄ™ na podstawie instancji\" (instance-based learning), poniewaÅ¼ nie buduje modelu w fazie trenowania, a zamiast tego przechowuje caÅ‚y zbiÃ³r treningowy i wykonuje obliczenia dopiero w momencie predykcji.\n",
    "\n",
    "GÅ‚Ã³wna idea opiera siÄ™ na zaÅ‚oÅ¼eniu, Å¼e podobne punkty danych istniejÄ… w bliskiej odlegÅ‚oÅ›ci od siebie. Przewidywana wartoÅ›Ä‡ dla nowego, nieznanego punktu danych jest obliczana na podstawie wartoÅ›ci jego \"k\" najbliÅ¼szych sÄ…siadÃ³w ze zbioru treningowego.\n",
    "\n",
    "---\n",
    "\n",
    "### Jak DziaÅ‚a Algorytm Regresji k-NN?\n",
    "\n",
    "Proces predykcji przy uÅ¼yciu regresji k-NN moÅ¼na podzieliÄ‡ na kilka kluczowych krokÃ³w:\n",
    "\n",
    "#### Krok 1: WybÃ³r liczby sÄ…siadÃ³w (k)\n",
    "\n",
    "Pierwszym krokiem jest wybÃ³r hiperparametru `k`, ktÃ³ry okreÅ›la, ilu najbliÅ¼szych sÄ…siadÃ³w zostanie uwzglÄ™dnionych podczas dokonywania predykcji. WybÃ³r `k` ma kluczowe znaczenie dla dziaÅ‚ania modelu:\n",
    "*   **MaÅ‚e `k`** (np. `k=1`): Model jest bardzo elastyczny i podatny na szum w danych, co moÅ¼e prowadziÄ‡ do niestabilnych predykcji.\n",
    "*   **DuÅ¼e `k`**: Predykcje stajÄ… siÄ™ bardziej stabilne i wygÅ‚adzone, ale model moÅ¼e traciÄ‡ zdolnoÅ›Ä‡ do wychwytywania lokalnych struktur w danych.\n",
    "\n",
    "OptymalnÄ… wartoÅ›Ä‡ `k` czÄ™sto wybiera siÄ™ za pomocÄ… walidacji krzyÅ¼owej. PowszechnÄ… heurystykÄ… jest wybÃ³r `k` w przybliÅ¼eniu rÃ³wnego pierwiastkowi kwadratowemu z liczby punktÃ³w danych w zbiorze (`k â‰ˆ âˆšn`).\n",
    "\n",
    "#### Krok 2: Obliczenie odlegÅ‚oÅ›ci\n",
    "\n",
    "Aby znaleÅºÄ‡ najbliÅ¼szych sÄ…siadÃ³w dla nowego punktu danych, musimy obliczyÄ‡ odlegÅ‚oÅ›Ä‡ miÄ™dzy nim a wszystkimi punktami w zbiorze treningowym. NajczÄ™Å›ciej uÅ¼ywanÄ… metrykÄ… odlegÅ‚oÅ›ci dla zmiennych ciÄ…gÅ‚ych jest **odlegÅ‚oÅ›Ä‡ Euklidesowa**.\n",
    "\n",
    "**WzÃ³r na odlegÅ‚oÅ›Ä‡ EuklidesowÄ…:**\n",
    "\n",
    "Dla dwÃ³ch punktÃ³w, **p** i **q**, w *n*-wymiarowej przestrzeni cech, gdzie **p** = $(p_1, p_2, ..., p_n)$ i **q** = $(q_1, q_2, ..., q_n)$, odlegÅ‚oÅ›Ä‡ Euklidesowa $d(p, q)$ jest definiowana jako:\n",
    "\n",
    "$$\n",
    "d(p, q) = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + ... + (q_n - p_n)^2} = \\sqrt{\\sum_{i=1}^{n} (q_i - p_i)^2}\n",
    "$$\n",
    "\n",
    "Inne popularne metryki odlegÅ‚oÅ›ci to:\n",
    "*   **OdlegÅ‚oÅ›Ä‡ Manhattan:** suma bezwzglÄ™dnych rÃ³Å¼nic wspÃ³Å‚rzÄ™dnych.\n",
    "*   **OdlegÅ‚oÅ›Ä‡ Minkowskiego:** uogÃ³lnienie odlegÅ‚oÅ›ci Euklidesowej i Manhattan.\n",
    "\n",
    "> **WaÅ¼na uwaga:** Algorytm k-NN jest wraÅ¼liwy na skalÄ™ cech. JeÅ›li cechy majÄ… rÃ³Å¼ne zakresy wartoÅ›ci (np. wiek w latach i dochÃ³d w tysiÄ…cach), cecha o wiÄ™kszym zakresie bÄ™dzie dominowaÄ‡ w obliczeniach odlegÅ‚oÅ›ci. Dlatego kluczowe jest przeskalowanie danych (np. przez normalizacjÄ™ lub standaryzacjÄ™) przed zastosowaniem algorytmu.\n",
    "\n",
    "#### Krok 3: Znalezienie k-najbliÅ¼szych sÄ…siadÃ³w\n",
    "\n",
    "Po obliczeniu odlegÅ‚oÅ›ci do wszystkich punktÃ³w treningowych, sÄ… one sortowane w porzÄ…dku rosnÄ…cym. NastÄ™pnie wybierane jest `k` punktÃ³w o najmniejszych odlegÅ‚oÅ›ciach od nowego punktu.\n",
    "\n",
    "#### Krok 4: Dokonanie predykcji\n",
    "\n",
    "W standardowej wersji regresji k-NN, przewidywana wartoÅ›Ä‡ dla nowego punktu jest prostÄ… **Å›redniÄ… arytmetycznÄ…** wartoÅ›ci docelowych jego `k` najbliÅ¼szych sÄ…siadÃ³w.\n",
    "\n",
    "**WzÃ³r na predykcjÄ™ w standardowej regresji k-NN:**\n",
    "\n",
    "JeÅ›li $y_1, y_2, ..., y_k$ to wartoÅ›ci docelowe `k` najbliÅ¼szych sÄ…siadÃ³w, to przewidywana wartoÅ›Ä‡ $\\hat{y}$ dla nowego punktu jest obliczana jako:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{k} \\sum_{i=1}^{k} y_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Wariant: WaÅ¼ona Regresja k-NN\n",
    "\n",
    "Standardowe podejÅ›cie traktuje wszystkich `k` sÄ…siadÃ³w jednakowo. Intuicyjnym ulepszeniem jest przypisanie wiÄ™kszej wagi sÄ…siadom, ktÃ³rzy sÄ… bliÅ¼ej nowego punktu, a mniejszej tym, ktÃ³rzy sÄ… dalej. Nazywa siÄ™ to waÅ¼onÄ… regresjÄ… k-NN.\n",
    "\n",
    "W tym wariancie, predykcja jest **Å›redniÄ… waÅ¼onÄ…**, gdzie wagi sÄ… zazwyczaj odwrotnoÅ›ciÄ… odlegÅ‚oÅ›ci do sÄ…siada.\n",
    "\n",
    "**WzÃ³r na wagÄ™:**\n",
    "\n",
    "Waga $w_i$ dla *i*-tego sÄ…siada moÅ¼e byÄ‡ zdefiniowana jako:\n",
    "\n",
    "$$\n",
    "w_i = \\frac{1}{d_i}\n",
    "$$\n",
    "\n",
    "gdzie $d_i$ to odlegÅ‚oÅ›Ä‡ do *i*-tego sÄ…siada. NaleÅ¼y uwaÅ¼aÄ‡ na przypadek, gdy odlegÅ‚oÅ›Ä‡ wynosi zero; aby uniknÄ…Ä‡ dzielenia przez zero, moÅ¼na dodaÄ‡ maÅ‚Ä… staÅ‚Ä… $\\epsilon$ do mianownika.\n",
    "\n",
    "**WzÃ³r na predykcjÄ™ w waÅ¼onej regresji k-NN:**\n",
    "\n",
    "Przewidywana wartoÅ›Ä‡ $\\hat{y}$ jest obliczana jako:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{\\sum_{i=1}^{k} (w_i \\cdot y_i)}{\\sum_{i=1}^{k} w_i}\n",
    "$$\n",
    "\n",
    "DziÄ™ki temu podejÅ›ciu, wpÅ‚yw bliÅ¼szych sÄ…siadÃ³w na ostateczny wynik jest silniejszy, co czÄ™sto prowadzi do dokÅ‚adniejszych predykcji.\n",
    "\n",
    "---\n",
    "\n",
    "### Podsumowanie\n",
    "\n",
    "| Aspekt | Opis |\n",
    "| :--- | :--- |\n",
    "| **Typ algorytmu** | Uczenie maszynowe z nadzorem, nieparametryczne, oparte na instancjach. |\n",
    "| **Zadanie** | Regresja (przewidywanie wartoÅ›ci ciÄ…gÅ‚ych). |\n",
    "| **Krok 1: WybÃ³r k** | OkreÅ›lenie liczby sÄ…siadÃ³w do uwzglÄ™dnienia. |\n",
    "| **Krok 2: Metryka odlegÅ‚oÅ›ci** | NajczÄ™Å›ciej odlegÅ‚oÅ›Ä‡ Euklidesowa do mierzenia podobieÅ„stwa. |\n",
    "| **Krok 3: Znalezienie sÄ…siadÃ³w** | Identyfikacja `k` punktÃ³w treningowych o najmniejszej odlegÅ‚oÅ›ci. |\n",
    "| **Krok 4: Predykcja (standardowa)** | Åšrednia arytmetyczna wartoÅ›ci docelowych `k` sÄ…siadÃ³w. |\n",
    "| **Krok 4: Predykcja (waÅ¼ona)** | Åšrednia waÅ¼ona wartoÅ›ci docelowych, gdzie wagi zaleÅ¼Ä… od odlegÅ‚oÅ›ci. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913009e6",
   "metadata": {},
   "source": [
    "# GÅ‚Ã³wne Wyzwania w Uczeniu Maszynowym: ZÅ‚e Dane i ZÅ‚e Algorytmy\n",
    "\n",
    "PoniÅ¼sza notatka podsumowuje kluczowe problemy, na jakie moÅ¼na natrafiÄ‡ podczas budowania systemÃ³w uczenia maszynowego, dzielÄ…c je na dwie gÅ‚Ã³wne kategorie: problemy z danymi i problemy z algorytmami.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ZÅ‚e Dane (Bad Data)\n",
    "\n",
    "JakoÅ›Ä‡ i reprezentatywnoÅ›Ä‡ danych treningowych jest absolutnie kluczowa. Zasada \"Å›mieci na wejÅ›ciu, Å›mieci na wyjÅ›ciu\" (garbage in, garbage out) jest tu fundamentalna.\n",
    "\n",
    "### A. BÅ‚Ä…d PrÃ³bkowania (Sampling Bias)\n",
    "\n",
    "> **W skrÃ³cie:** Dane treningowe nie sÄ… reprezentatywne dla przypadkÃ³w, ktÃ³re model napotka w rzeczywistoÅ›ci.\n",
    "\n",
    "Model uczy siÄ™ na podstawie danych, ktÃ³re nie odzwierciedlajÄ… prawdziwego rozkÅ‚adu populacji.\n",
    "\n",
    "*   **Klasyczny przykÅ‚ad: Wybory w USA w 1936 r.**\n",
    "    *   **Problem:** SondaÅ¼ownia *Literary Digest* przewidziaÅ‚a wygranÄ… Landona, podczas gdy z duÅ¼Ä… przewagÄ… wygraÅ‚ Roosevelt.\n",
    "    *   **Przyczyny bÅ‚Ä™du:**\n",
    "        1.  **Niereprezentatywne ÅºrÃ³dÅ‚a danych:** Adresy do wysyÅ‚ki ankiet pochodziÅ‚y z ksiÄ…Å¼ek telefonicznych i list subskrybentÃ³w magazynÃ³w. W tamtych czasach posiadanie telefonu czy prenumeraty byÅ‚o domenÄ… ludzi zamoÅ¼niejszych, ktÃ³rzy czÄ™Å›ciej gÅ‚osowali na RepublikanÃ³w (Landon).\n",
    "        2.  **BÅ‚Ä…d braku odpowiedzi (Nonresponse bias):** Mniej niÅ¼ 25% osÃ³b odesÅ‚aÅ‚o ankietÄ™. OdpowiedziaÅ‚y gÅ‚Ã³wnie osoby silnie zaangaÅ¼owane politycznie, co rÃ³wnieÅ¼ zaburzyÅ‚o reprezentatywnoÅ›Ä‡ prÃ³by.\n",
    "\n",
    "*   **WspÃ³Å‚czesny przykÅ‚ad: Wideo z muzykÄ… funk**\n",
    "    *   JeÅ›li zbiÃ³r treningowy zbudujesz, pobierajÄ…c wyniki wyszukiwania \"funk music\" z YouTube, wyniki bÄ™dÄ… przechylone w stronÄ™ najpopularniejszych artystÃ³w i mogÄ… nie reprezentowaÄ‡ caÅ‚ego gatunku.\n",
    "\n",
    "### B. Dane Niskiej JakoÅ›ci (Poor-Quality Data)\n",
    "\n",
    "> **W skrÃ³cie:** Dane sÄ… peÅ‚ne bÅ‚Ä™dÃ³w, wartoÅ›ci odstajÄ…cych (outlierÃ³w) i szumu.\n",
    "\n",
    "Nawet najlepszy algorytm bÄ™dzie miaÅ‚ problemy, jeÅ›li dane bÄ™dÄ… \"brudne\". DuÅ¼a czÄ™Å›Ä‡ pracy Data Scientista to wÅ‚aÅ›nie czyszczenie danych.\n",
    "\n",
    "*   **Co robiÄ‡?**\n",
    "    *   **WartoÅ›ci odstajÄ…ce (outliers):** JeÅ›li niektÃ³re instancje sÄ… oczywistymi anomaliami, moÅ¼na je usunÄ…Ä‡ lub sprÃ³bowaÄ‡ naprawiÄ‡ rÄ™cznie.\n",
    "    *   **BrakujÄ…ce wartoÅ›ci:** JeÅ›li w niektÃ³rych prÃ³bkach brakuje cech (np. 5% klientÃ³w nie podaÅ‚o wieku), moÅ¼na:\n",
    "        *   ZignorowaÄ‡ caÅ‚Ä… cechÄ™ (atrybut).\n",
    "        *   ZignorowaÄ‡ instancje z brakami.\n",
    "        *   UzupeÅ‚niÄ‡ braki (np. medianÄ… lub Å›redniÄ…).\n",
    "        *   WytrenowaÄ‡ jeden model z tÄ… cechÄ… (na danych, ktÃ³re jÄ… majÄ…) i jeden bez niej.\n",
    "\n",
    "### C. Nieistotne Cechy (Irrelevant Features)\n",
    "\n",
    "> **W skrÃ³cie:** ZbiÃ³r danych zawiera zbyt wiele cech, ktÃ³re nie majÄ… znaczenia dla problemu, a za maÅ‚o tych, ktÃ³re majÄ….\n",
    "\n",
    "System bÄ™dzie w stanie siÄ™ uczyÄ‡ tylko, jeÅ›li dane treningowe zawierajÄ… wystarczajÄ…co duÅ¼o **istotnych** cech.\n",
    "\n",
    "*   **RozwiÄ…zanie: InÅ¼ynieria Cech (Feature Engineering)**\n",
    "    Jest to proces tworzenia dobrego zestawu cech do trenowania. SkÅ‚ada siÄ™ z:\n",
    "    1.  **Selekcji cech (Feature Selection):** WybÃ³r najbardziej uÅ¼ytecznych cech spoÅ›rÃ³d juÅ¼ istniejÄ…cych.\n",
    "    2.  **Ekstrakcji cech (Feature Extraction):** ÅÄ…czenie istniejÄ…cych cech w celu stworzenia nowej, bardziej uÅ¼ytecznej (np. za pomocÄ… algorytmÃ³w redukcji wymiarowoÅ›ci).\n",
    "    3.  **Tworzenia nowych cech:** Poprzez zbieranie nowych danych.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ZÅ‚e Algorytmy (Bad Algorithms)\n",
    "\n",
    "Nawet przy idealnych danych, niewÅ‚aÅ›ciwy dobÃ³r lub konfiguracja modelu moÅ¼e prowadziÄ‡ do sÅ‚abych wynikÃ³w.\n",
    "\n",
    "### A. Przeuczenie (Overfitting)\n",
    "\n",
    "> **W skrÃ³cie:** Model dziaÅ‚a Å›wietnie na danych treningowych, ale sÅ‚abo generalizuje i nie radzi sobie z nowymi, nieznanymi danymi.\n",
    "\n",
    "Model jest zbyt skomplikowany w stosunku do iloÅ›ci i zaszumienia danych. Uczy siÄ™ \"na pamiÄ™Ä‡\" danych treningowych, wÅ‚Ä…czajÄ…c w to przypadkowy szum, zamiast uczyÄ‡ siÄ™ ogÃ³lnych wzorcÃ³w.\n",
    "\n",
    "*   **Intuicyjny przykÅ‚ad:** TaksÃ³wkarz oszukaÅ‚ CiÄ™ w obcym kraju. Dochodzisz do wniosku, Å¼e *wszyscy* taksÃ³wkarze w tym kraju to zÅ‚odzieje. To jest wÅ‚aÅ›nie nadmierna generalizacja na podstawie maÅ‚ej prÃ³bki.\n",
    "\n",
    "*   **PrzykÅ‚ad techniczny:** Model uczy siÄ™, Å¼e kraje z literÄ… \"w\" w nazwie majÄ… wskaÅºnik satysfakcji z Å¼ycia > 7 (na podstawie danych treningowych). Ten wzorzec jest przypadkowy i nie sprawdzi siÄ™ dla innych krajÃ³w.\n",
    "\n",
    "*   **RozwiÄ…zania:**\n",
    "    1.  **UproÅ›Ä‡ model:**\n",
    "        *   Wybierz model z mniejszÄ… liczbÄ… parametrÃ³w (np. model liniowy zamiast wielomianu wysokiego stopnia).\n",
    "        *   Zredukuj liczbÄ™ atrybutÃ³w w danych.\n",
    "        *   NaÅ‚Ã³Å¼ ograniczenia na model (patrz: Regularyzacja).\n",
    "    2.  **Zbierz wiÄ™cej danych treningowych.**\n",
    "    3.  **Zredukuj szum w danych** (napraw bÅ‚Ä™dy, usuÅ„ outliery).\n",
    "\n",
    "*   **Regularyzacja (Regularization):**\n",
    "    *   To technika **nakÅ‚adania ograniczeÅ„ na model, aby go uproÅ›ciÄ‡** i zmniejszyÄ‡ ryzyko przeuczenia.\n",
    "    *   Steruje siÄ™ niÄ… za pomocÄ… **hiperparametru**.\n",
    "    *   PrzykÅ‚ad: W modelu liniowym moÅ¼na \"zmusiÄ‡\" algorytm, by utrzymywaÅ‚ nachylenie prostej bliskie zeru. Model nie dopasuje siÄ™ idealnie do danych treningowych, ale bÄ™dzie lepiej generalizowaÅ‚.\n",
    "\n",
    "### B. Niedouczenie (Underfitting)\n",
    "\n",
    "> **W skrÃ³cie:** Model jest zbyt prosty, aby nauczyÄ‡ siÄ™ podstawowej struktury danych. DziaÅ‚a sÅ‚abo nawet na danych treningowych.\n",
    "\n",
    "Jest to przeciwieÅ„stwo przeuczenia. RzeczywistoÅ›Ä‡ jest bardziej zÅ‚oÅ¼ona niÅ¼ moÅ¼liwoÅ›ci modelu.\n",
    "\n",
    "*   **PrzykÅ‚ad:** PrÃ³ba opisania skomplikowanego, nieliniowego zjawiska za pomocÄ… prostej regresji liniowej.\n",
    "\n",
    "*   **RozwiÄ…zania:**\n",
    "    1.  **Wybierz potÄ™Å¼niejszy model** (z wiÄ™kszÄ… liczbÄ… parametrÃ³w).\n",
    "    2.  **Dostarcz lepsze cechy** (inÅ¼ynieria cech).\n",
    "    3.  **Zmniejsz ograniczenia naÅ‚oÅ¼one na model** (np. zredukuj hiperparametr regularyzacji)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c1675",
   "metadata": {},
   "source": [
    "## ZbiÃ³r uczÄ…co rozwojowy \"train-dev\"\n",
    "\n",
    "ZbiÃ³r \"train-dev\" jest uÅ¼ywany, gdy istnieje ryzyko niedopasowania miÄ™dzy danymi treningowymi a danymi uÅ¼ywanymi w zbiorach walidacyjnym i testowym (ktÃ³re zawsze powinny byÄ‡ jak najbardziej zbliÅ¼one do danych uÅ¼ywanych po wdroÅ¼eniu modelu do produkcji). ZbiÃ³r \"train-dev\" to czÄ™Å›Ä‡ zbioru treningowego, ktÃ³ra jest odÅ‚oÅ¼ona (model nie jest na niej trenowany). Model jest trenowany na pozostaÅ‚ej czÄ™Å›ci zbioru treningowego i oceniany zarÃ³wno na zbiorze \"train-dev\", jak i na zbiorze walidacyjnym. JeÅ›li model dobrze radzi sobie na zbiorze treningowym, ale nie na zbiorze \"train-dev\", to model prawdopodobnie nadmiernie dopasowuje siÄ™ do zbioru treningowego. JeÅ›li dobrze radzi sobie zarÃ³wno na zbiorze treningowym, jak i na zbiorze \"train-dev\", ale nie na zbiorze walidacyjnym, to prawdopodobnie istnieje znaczne niedopasowanie danych miÄ™dzy danymi treningowymi a danymi walidacyjnymi i testowymi, i naleÅ¼y sprÃ³bowaÄ‡ ulepszyÄ‡ dane treningowe, aby bardziej przypominaÅ‚y dane walidacyjne i testowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdb2d3",
   "metadata": {},
   "source": [
    "## Parametry a hiperparametry\n",
    "\n",
    "ğŸ”¹ Parametry\n",
    "Uczy siÄ™ ich sam model podczas treningu.\n",
    "SÄ… wewnÄ™trzne â€” model dopasowuje je do danych.\n",
    "PrzykÅ‚ady:\n",
    "w regresji liniowej â†’ wspÃ³Å‚czynniki w i b,\n",
    "w sieci neuronowej â†’ wagi i biasy neuronÃ³w.\n",
    "ğŸ“˜ My nie ustawiamy parametrÃ³w â€” model sam je â€uczyâ€.\n",
    "ğŸ”¹ Hiperparametry\n",
    "Ustawiamy je my (czÅ‚owiek lub algorytm optymalizacji) przed treningiem.\n",
    "SterujÄ… tym, jak model siÄ™ uczy.\n",
    "PrzykÅ‚ady:\n",
    "szybkoÅ›Ä‡ uczenia (learning rate),\n",
    "liczba warstw lub neuronÃ³w,\n",
    "liczba epok,\n",
    "rozmiar batcha,\n",
    "k w k-NN,\n",
    "C w SVM.\n",
    "ğŸ“˜ Hiperparametry â†’ wpÅ‚ywajÄ… na proces uczenia, ale nie sÄ… przez model uczone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f36d4",
   "metadata": {},
   "source": [
    "## ğŸ“˜ Zbiory danych w uczeniu maszynowym\n",
    "\n",
    "#### ğŸ”¹ ZbiÃ³r uczÄ…cy (treningowy)\n",
    "- UÅ¼ywany do **nauki modelu** â€” model dopasowuje do niego swoje **parametry**.  \n",
    "- NajwiÄ™ksza czÄ™Å›Ä‡ danych (zwykle ok. 70â€“80%).  \n",
    "\n",
    "#### ğŸ”¹ ZbiÃ³r walidacyjny\n",
    "- UÅ¼ywany do **dobierania hiperparametrÃ³w** i **oceny jakoÅ›ci** modelu podczas treningu.  \n",
    "- Pomaga wykryÄ‡ **przeuczenie (overfitting)**.  \n",
    "- Dane z walidacji **nie sÄ… uÅ¼ywane do uczenia**.  \n",
    "\n",
    "#### ğŸ”¹ ZbiÃ³r testowy\n",
    "- UÅ¼ywany **na koÅ„cu** do **sprawdzenia**, jak dobrze model generalizuje na **nowych danych**.  \n",
    "- Dane testowe **nie mogÄ… byÄ‡ widziane przez model wczeÅ›niej**.  \n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ BÅ‚Ä…d generalizacji\n",
    "- To **rÃ³Å¼nica miÄ™dzy bÅ‚Ä™dem na danych uczÄ…cych a bÅ‚Ä™dem na danych testowych**.  \n",
    "- Pokazuje, **jak dobrze model radzi sobie z nowymi, nieznanymi danymi**.  \n",
    "- MaÅ‚y bÅ‚Ä…d generalizacji â†’ model dobrze **uogÃ³lnia**.  \n",
    "- DuÅ¼y bÅ‚Ä…d generalizacji â†’ model **przeuczony (overfitting)** lub **niedouczenie (underfitting)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70d23c",
   "metadata": {},
   "source": [
    "## odp. na pytania z 1 rozdzialu\n",
    "\n",
    "Jasne, oto tekst z dodanÄ… numeracjÄ… do kaÅ¼dego akapitu:\n",
    "\n",
    "1.  Uczenie maszynowe polega na budowaniu systemÃ³w, ktÃ³re potrafiÄ… uczyÄ‡ siÄ™ na podstawie danych. Uczenie siÄ™ oznacza stawanie siÄ™ lepszym w wykonywaniu jakiegoÅ› zadania, przy uwzglÄ™dnieniu okreÅ›lonej miary wydajnoÅ›ci.\n",
    "\n",
    "2.  Uczenie maszynowe jest doskonaÅ‚e do rozwiÄ…zywania zÅ‚oÅ¼onych problemÃ³w, dla ktÃ³rych nie mamy rozwiÄ…zania algorytmicznego, do zastÄ™powania dÅ‚ugich list rÄ™cznie dostrajanych reguÅ‚, do budowania systemÃ³w, ktÃ³re dostosowujÄ… siÄ™ do zmieniajÄ…cego siÄ™ otoczenia, a wreszcie do pomagania ludziom w uczeniu siÄ™ (np. eksploracja danych).\n",
    "\n",
    "3.  Oznaczony zbiÃ³r treningowy to zbiÃ³r treningowy, ktÃ³ry zawiera poÅ¼Ä…dane rozwiÄ…zanie (czyli etykietÄ™) dla kaÅ¼dego przypadku.\n",
    "\n",
    "4.  Dwa najczÄ™stsze zadania nadzorowane to regresja i klasyfikacja.\n",
    "\n",
    "5.  Typowe zadania nienadzorowane obejmujÄ… klasteryzacjÄ™, wizualizacjÄ™, redukcjÄ™ wymiarowoÅ›ci i uczenie siÄ™ reguÅ‚ asocjacyjnych.\n",
    "\n",
    "6.  Uczenie przez wzmacnianie (Reinforcement Learning) prawdopodobnie sprawdzi siÄ™ najlepiej, jeÅ›li chcemy, aby robot nauczyÅ‚ siÄ™ chodziÄ‡ po rÃ³Å¼nych nieznanych terenach, poniewaÅ¼ jest to typowy rodzaj problemu, ktÃ³rym zajmuje siÄ™ uczenie przez wzmacnianie. MoÅ¼liwe byÅ‚oby wyraÅ¼enie tego problemu jako problemu uczenia nadzorowanego lub czÄ™Å›ciowo nadzorowanego, ale byÅ‚oby to mniej naturalne.\n",
    "\n",
    "7.  JeÅ›li nie wiesz, jak zdefiniowaÄ‡ grupy, moÅ¼esz uÅ¼yÄ‡ algorytmu klastrowania (uczenie nienadzorowane) do posegmentowania klientÃ³w na klastry podobnych klientÃ³w. JeÅ›li jednak wiesz, jakie grupy chciaÅ‚byÅ› mieÄ‡, moÅ¼esz dostarczyÄ‡ wiele przykÅ‚adÃ³w kaÅ¼dej grupy do algorytmu klasyfikacyjnego (uczenie nadzorowane), a on sklasyfikuje wszystkich twoich klientÃ³w do tych grup.\n",
    "\n",
    "8.  Wykrywanie spamu to typowy problem uczenia nadzorowanego: algorytm otrzymuje wiele e-maili wraz z ich etykietami (spam lub nie spam).\n",
    "\n",
    "9.  System uczÄ…cy siÄ™ online moÅ¼e uczyÄ‡ siÄ™ w sposÃ³b przyrostowy, w przeciwieÅ„stwie do systemu uczÄ…cego siÄ™ wsadowo. DziÄ™ki temu jest w stanie szybko dostosowywaÄ‡ siÄ™ zarÃ³wno do zmieniajÄ…cych siÄ™ danych, jak i systemÃ³w autonomicznych, oraz trenowaÄ‡ na bardzo duÅ¼ych iloÅ›ciach danych.\n",
    "\n",
    "10. Algorytmy \"out-of-core\" potrafiÄ… obsÅ‚ugiwaÄ‡ ogromne iloÅ›ci danych, ktÃ³re nie mieszczÄ… siÄ™ w pamiÄ™ci gÅ‚Ã³wnej komputera. Algorytm uczÄ…cy siÄ™ \"out-of-core\" dzieli dane na mini-partie i wykorzystuje techniki uczenia online do nauki na podstawie tych mini-partii.\n",
    "\n",
    "11. System uczÄ…cy siÄ™ oparty na instancjach (instance-based learning) uczy siÄ™ danych treningowych na pamiÄ™Ä‡; nastÄ™pnie, gdy otrzyma nowÄ… instancjÄ™, uÅ¼ywa miary podobieÅ„stwa, aby znaleÅºÄ‡ najbardziej podobne nauczone instancje i wykorzystuje je do tworzenia prognoz.\n",
    "\n",
    "12. \n",
    "ğŸ”¹ Parametry\n",
    "Uczy siÄ™ ich sam model podczas treningu.\n",
    "SÄ… wewnÄ™trzne â€” model dopasowuje je do danych.\n",
    "PrzykÅ‚ady:\n",
    "w regresji liniowej â†’ wspÃ³Å‚czynniki w i b,\n",
    "w sieci neuronowej â†’ wagi i biasy neuronÃ³w.\n",
    "ğŸ“˜ My nie ustawiamy parametrÃ³w â€” model sam je â€uczyâ€.\n",
    "ğŸ”¹ Hiperparametry\n",
    "Ustawiamy je my (czÅ‚owiek lub algorytm optymalizacji) przed treningiem.\n",
    "SterujÄ… tym, jak model siÄ™ uczy.\n",
    "PrzykÅ‚ady:\n",
    "szybkoÅ›Ä‡ uczenia (learning rate),\n",
    "liczba warstw lub neuronÃ³w,\n",
    "liczba epok,\n",
    "rozmiar batcha,\n",
    "k w k-NN,\n",
    "C w SVM.\n",
    "ğŸ“˜ Hiperparametry â†’ wpÅ‚ywajÄ… na proces uczenia, ale nie sÄ… przez model uczone.\n",
    "\n",
    "13. Algorytmy uczenia oparte na modelu (model-based learning) poszukujÄ… optymalnej wartoÅ›ci dla parametrÃ³w modelu, tak aby model dobrze generalizowaÅ‚ na nowe instancje. Zazwyczaj trenujemy takie systemy poprzez minimalizacjÄ™ funkcji kosztu, ktÃ³ra mierzy, jak sÅ‚abo system radzi sobie z przewidywaniami na danych treningowych, plus kara za zÅ‚oÅ¼onoÅ›Ä‡ modelu, jeÅ›li model jest regularyzowany. Aby dokonaÄ‡ predykcji, podajemy cechy nowej instancji do funkcji predykcyjnej modelu, uÅ¼ywajÄ…c wartoÅ›ci parametrÃ³w znalezionych przez algorytm uczÄ…cy.\n",
    "\n",
    "14. NiektÃ³re z gÅ‚Ã³wnych wyzwaÅ„ w uczeniu maszynowym to brak danych, niska jakoÅ›Ä‡ danych, niereprezentatywne dane, nieinformacyjne cechy, nadmiernie proste modele, ktÃ³re niedostatecznie dopasowujÄ… siÄ™ do danych treningowych (underfitting), oraz nadmiernie zÅ‚oÅ¼one modele, ktÃ³re nadmiernie dopasowujÄ… siÄ™ do danych (overfitting).\n",
    "\n",
    "15. JeÅ›li model doskonale radzi sobie na danych treningowych, ale sÅ‚abo generalizuje na nowe instancje, model prawdopodobnie nadmiernie dopasowuje siÄ™ do danych treningowych (lub mieliÅ›my wyjÄ…tkowe szczÄ™Å›cie na danych treningowych). MoÅ¼liwe rozwiÄ…zania problemu nadmiernego dopasowania to pozyskanie wiÄ™kszej iloÅ›ci danych, uproszczenie modelu (wybÃ³r prostszego algorytmu, zmniejszenie liczby parametrÃ³w lub uÅ¼ywanych cech, lub regularyzacja modelu) lub zmniejszenie szumu w danych treningowych.\n",
    "\n",
    "16. ZbiÃ³r testowy jest uÅ¼ywany do oszacowania bÅ‚Ä™du generalizacji, jaki model popeÅ‚ni na nowych instancjach, zanim model zostanie wdroÅ¼ony do produkcji.\n",
    "\n",
    "17. ZbiÃ³r walidacyjny jest uÅ¼ywany do porÃ³wnywania modeli. UmoÅ¼liwia on wybÃ³r najlepszego modelu i dostrojenie hiperparametrÃ³w.\n",
    "\n",
    "18. ZbiÃ³r \"train-dev\" jest uÅ¼ywany, gdy istnieje ryzyko niedopasowania miÄ™dzy danymi treningowymi a danymi uÅ¼ywanymi w zbiorach walidacyjnym i testowym (ktÃ³re zawsze powinny byÄ‡ jak najbardziej zbliÅ¼one do danych uÅ¼ywanych po wdroÅ¼eniu modelu do produkcji). ZbiÃ³r \"train-dev\" to czÄ™Å›Ä‡ zbioru treningowego, ktÃ³ra jest odÅ‚oÅ¼ona (model nie jest na niej trenowany). Model jest trenowany na pozostaÅ‚ej czÄ™Å›ci zbioru treningowego i oceniany zarÃ³wno na zbiorze \"train-dev\", jak i na zbiorze walidacyjnym. JeÅ›li model dobrze radzi sobie na zbiorze treningowym, ale nie na zbiorze \"train-dev\", to model prawdopodobnie nadmiernie dopasowuje siÄ™ do zbioru treningowego. JeÅ›li dobrze radzi sobie zarÃ³wno na zbiorze treningowym, jak i na zbiorze \"train-dev\", ale nie na zbiorze walidacyjnym, to prawdopodobnie istnieje znaczne niedopasowanie danych miÄ™dzy danymi treningowymi a danymi walidacyjnymi i testowymi, i naleÅ¼y sprÃ³bowaÄ‡ ulepszyÄ‡ dane treningowe, aby bardziej przypominaÅ‚y dane walidacyjne i testowe.\n",
    "\n",
    "19. JeÅ›li dostrajasz hiperparametry przy uÅ¼yciu zbioru testowego, ryzykujesz nadmierne dopasowanie do zbioru testowego, a mierzony bÅ‚Ä…d generalizacji bÄ™dzie optymistyczny (moÅ¼esz wdroÅ¼yÄ‡ model, ktÃ³ry dziaÅ‚a gorzej niÅ¼ siÄ™ spodziewasz)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5964b7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
