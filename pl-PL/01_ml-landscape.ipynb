{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a86b868",
   "metadata": {},
   "source": [
    "# Kluczowe pojęcia i krótkie opisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1efa3c",
   "metadata": {},
   "source": [
    "- **Machine Learning** – dziedzina nauki dająca komputerom możliwość uczenia się bez konieczności ich jawnego programowania.  \n",
    "\n",
    "- **Training Set (dane uczące)** – przykładowe dane używane do trenowania modelu, składające się z próbek (sample).  \n",
    "\n",
    "- **Accuracy** – konkretna miara wydajności modelu, często stosowana w zadaniach klasyfikacyjnych.  \n",
    "\n",
    "- **Data Mining** – analizowanie zbioru danych w celu poszukiwania ukrytych wzorców.  \n",
    "\n",
    "- **NLP (Natural Language Processing)** – przetwarzanie języka naturalnego; dziedzina AI zajmująca się analizą, rozumieniem i generowaniem ludzkiego języka przez komputery.  \n",
    "\n",
    "- **RNN (Recurrent Neural Network)** – rekurencyjna sieć neuronowa; sieć przetwarzająca dane sekwencyjne (np. tekst, dźwięk) poprzez zapamiętywanie wcześniejszych stanów.  \n",
    "\n",
    "- **CNN (Convolutional Neural Network)** – konwolucyjna sieć neuronowa; model szczególnie skuteczny w rozpoznawaniu obrazów dzięki operacjom splotu.  \n",
    "\n",
    "- **NLU (Natural Language Understanding)** – rozumienie języka naturalnego; poddziedzina NLP skupiająca się na interpretacji znaczenia wypowiedzi.  \n",
    "\n",
    "- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** – algorytm grupowania na podstawie gęstości punktów; wykrywa skupiska danych i odrzuca szum.  \n",
    "\n",
    "- **MNIST (Modified National Institute of Standards and Technology dataset)** – popularny zbiór danych zawierający ręcznie pisane cyfry, używany do trenowania i testowania modeli ML.  \n",
    "\n",
    "- **Transformator (Transformer)** – architektura sieci neuronowych oparta na mechanizmie uwagi (attention); podstawa modeli językowych, takich jak GPT czy BERT.  \n",
    "\n",
    "- **Redukcja wymiarowości (Dimensionality Reduction)** – proces upraszczania danych przez zmniejszenie liczby cech przy zachowaniu najważniejszych informacji.  \n",
    "\n",
    "- **Splot (Convolution)** – operacja matematyczna w CNN, która wyłapuje lokalne wzorce w danych (np. krawędzie na obrazie).  \n",
    "\n",
    "- **Regresja liniowa (Linear Regression)** – metoda przewidywania wartości ciągłych poprzez dopasowanie prostej linii do danych.  \n",
    "\n",
    "- **Regresja wielomianowa (Polynomial Regression)** – rozszerzenie regresji liniowej, w której zależność między zmiennymi jest opisana wielomianem.  \n",
    "\n",
    "- **Random Forest Regression (Regresja lasu losowego)** – metoda oparta na wielu drzewach decyzyjnych, uśredniająca ich wyniki w celu zwiększenia dokładności.  \n",
    "\n",
    "- **Decision Tree** to model uczenia maszynowego używany zarówno w **klasyfikacji**, jak i **regresji**.  Działa podobnie do procesu podejmowania decyzji przez człowieka — zadaje kolejne pytania, aż dojdzie do odpowiedzi.\n",
    "\n",
    "- **SVM (Support Vector Machine)** – maszyna wektorów nośnych; algorytm klasyfikacji i regresji, który znajduje granicę maksymalnie oddzielającą klasy.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251c5f",
   "metadata": {},
   "source": [
    "# Wykorzystanie ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd1ff0",
   "metadata": {},
   "source": [
    "- Problemy, ktore wymagaja czestego dostrajania algorytmu lub korzystanie z dlugich list regul.\n",
    "\n",
    "- Zlozonoe problemy, ktorych nie da sie rozwiazac tradycyjnymi metodami\n",
    "\n",
    "- Zmiennych srodowisk ( `model ml` moze sie dostosowac szybko do nowych danych i byc aktualizowany z latwoscia w dowolnym momencie )\n",
    "\n",
    "- Do analizy ogromnej ilosci danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1b538",
   "metadata": {},
   "source": [
    "# Rodzaje systemów ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bb40a",
   "metadata": {},
   "source": [
    "- **Nadzorowanie w fazie uczenia** - (uczenie nadzorowane, nienadzorowane, półnadzorowane, samonadzorowane, wzmocnienie itd.)\n",
    "\n",
    "- **Uczenie się w czasie rzeczywistym** - (u. przyrostowe, wsadowe)\n",
    "\n",
    "- **Sposób pracy** - proste porównanie nowych punktów danychze znanymi punktami, lub wykrywanie wzorców w `training set` i tworzenie modelu predykcyjnego \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2a8ec",
   "metadata": {},
   "source": [
    "## Uczenie nadzorowane (Supervised Learning)\n",
    "\n",
    "#### Etykieta (Label) i Cel (Target)\n",
    "\n",
    "- **Etykieta (Label)** – to **prawidłowa odpowiedź** w danych uczących, której model używa do nauki.  \n",
    "- **Cel (Target)** – to **wartość, którą model ma przewidzieć** podczas działania na nowych danych.  \n",
    "W praktyce oba pojęcia często oznaczają to samo – wynik, do którego model dąży.\n",
    "\n",
    "#### 🔹 Przykład:\n",
    "\n",
    "| Powierzchnia (m²) | Liczba pokoi | Lokalizacja | **Cena (etykieta / target)** |\n",
    "|--------------------|--------------|--------------|------------------------------|\n",
    "| 60                 | 3            | Centrum      | 520 000 zł                   |\n",
    "\n",
    "➡️ **Cechy (features):** powierzchnia, liczba pokoi, lokalizacja  \n",
    "➡️ **Etykieta / Cel:** czy email jest spamem czy nie -> SPAM / NOT SPAM\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Uczenie nadzorowane to rodzaj uczenia maszynowego, w którym model uczy się na podstawie **danych oznaczonych (z etykietami)**.  \n",
    "Każdy przykład w danych zawiera:\n",
    "- **wejście/cechy (features)** – czyli dane wejściowe, np. liczba pokoi, lokalizacja, temperatura, słowa w zdaniu,  \n",
    "- **wyjście (label lub target value)** – czyli oczekiwany wynik, np. cena domu, gatunek kwiatu, klasa obrazu.  \n",
    "\n",
    "Celem jest nauczenie modelu zależności między wejściem a wyjściem, tak aby mógł **przewidywać etykiety (lub wartości)** dla nowych, nieznanych danych.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Regresja (Regression)\n",
    "\n",
    "Regresja to typ uczenia nadzorowanego, w którym celem jest **przewidywanie wartości liczbowych (ciągłych)** — tzw. **wartości docelowej (target value)**.  \n",
    "Model stara się znaleźć zależność matematyczną między cechami (features) a wartością, którą chcemy przewidzieć.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model analizuje dane wejściowe i dopasowuje funkcję (np. prostą lub krzywą), która najlepiej opisuje zależność między zmiennymi.  \n",
    "Podczas treningu minimalizuje różnicę między przewidywaną a rzeczywistą wartością (np. za pomocą błędu MSE – Mean Squared Error).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Prognozowanie cen nieruchomości** na podstawie powierzchni, lokalizacji i liczby pokoi.  \n",
    "- **Przewidywanie zużycia energii** lub wody w budynkach.  \n",
    "- **Szacowanie przyszłej sprzedaży** produktów lub przychodów firmy.  \n",
    "- **Prognozowanie pogody** – np. temperatury lub opadów.  \n",
    "- **Przewidywanie kursów akcji lub kryptowalut** w czasie.  \n",
    "- **Modelowanie wzrostu populacji** lub trendów gospodarczych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Regresja liniowa (Linear Regression)  \n",
    "- Regresja wielomianowa (Polynomial Regression)  \n",
    "- Random Forest Regression  \n",
    "- Support Vector Regression (SVR)  \n",
    "- Sieci neuronowe (Neural Networks)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Klasyfikacja (Classification)\n",
    "\n",
    "Klasyfikacja to rodzaj uczenia nadzorowanego, w którym celem jest **przypisanie danych do jednej lub wielu kategorii (klas)**.  \n",
    "Model nie przewiduje liczby, lecz **etykietę** — np. „kot” / „pies”, „spam” / „nie spam”.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model uczy się rozróżniać wzorce w danych, tak aby dla nowych przykładów mógł zdecydować, do której klasy należą.  \n",
    "Podczas uczenia minimalizuje liczbę błędnych przypisań (np. za pomocą funkcji strat cross-entropy).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Filtracja spamu** – rozpoznawanie, czy e-mail to spam czy wiadomość prawidłowa.  \n",
    "- **Rozpoznawanie obrazów** – np. identyfikacja obiektów (samochód, człowiek, drzewo).  \n",
    "- **Diagnostyka medyczna** – klasyfikacja, czy pacjent ma daną chorobę na podstawie wyników badań.  \n",
    "- **Analiza nastrojów (sentiment analysis)** – określenie, czy opinia jest pozytywna, neutralna, czy negatywna.  \n",
    "- **Wykrywanie oszustw finansowych** – klasyfikacja transakcji jako prawdziwe lub podejrzane.  \n",
    "- **Rozpoznawanie mowy lub tekstu** – np. komendy głosowe lub analiza języka naturalnego.  \n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Logistic Regression  \n",
    "- Decision Tree  \n",
    "- Random Forest  \n",
    "- k-NN (k-Nearest Neighbors)  \n",
    "- SVM (Support Vector Machine)  \n",
    "- Naive Bayes  \n",
    "- Sieci neuronowe (CNN, RNN)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu:\n",
    "1. **Przygotowanie danych** – zebranie i oznaczenie danych (features + labels).  \n",
    "2. **Podział danych** – na zbiór uczący (*training set*) i testowy (*test set*).  \n",
    "3. **Trenowanie modelu** – model uczy się zależności między wejściami a wyjściami.  \n",
    "4. **Walidacja i testowanie** – sprawdzenie, jak dobrze model działa na nowych danych.  \n",
    "5. **Ewaluacja wyników** – np. przy użyciu metryk: *accuracy, precision, recall, MSE, R²*.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- Systemy rekomendacji (Netflix, Amazon, Spotify).  \n",
    "- Asystenci głosowi (rozumienie mowy i komend).  \n",
    "- Systemy wykrywania oszustw bankowych.  \n",
    "- Ocena ryzyka kredytowego i scoring klientów.  \n",
    "- Wykrywanie defektów w produkcji przemysłowej.  \n",
    "- Automatyczne rozpoznawanie obrazu w kamerach bezpieczeństwa.  \n",
    "- Prognozowanie cen, popytu, trendów i sprzedaży.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55efe9",
   "metadata": {},
   "source": [
    "## Uczenie nienadzorowane (Unsupervised Learning)\n",
    "\n",
    "Uczenie nienadzorowane to rodzaj uczenia maszynowego, w którym model uczy się na podstawie **danych nieoznaczonych (bez etykiet)**.  \n",
    "Celem jest odkrywanie ukrytych wzorców, struktur i zależności w danych wejściowych, bez wcześniejszego informowania modelu, jakie są „prawidłowe” odpowiedzi. Model samodzielnie grupuje, redukuje lub identyfikuje anomalie.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Klastrowanie / Analiza Skupień (Clustering)\n",
    "\n",
    "Klastrowanie, często nazywane **Analizą Skupień**, to typ uczenia nienadzorowanego, w którym celem jest **grupowanie podobnych punktów danych w klastry (grupy)**.  \n",
    "Model samodzielnie identyfikuje wewnętrzne struktury w danych, tak aby punkty w tym samym klastrze były do siebie podobne (wysoka spójność wewnątrzklastrowa), a punkty z różnych klastrów – jak najbardziej różne (niska spójność międzyklastrowa).\n",
    "\n",
    "#### Jak to działa:\n",
    "Algorytmy klastrowania analizują cechy danych i na podstawie ich podobieństwa (często mierzonego odległością w przestrzeni cech, np. odległością euklidesową) przypisują je do grup. Nie potrzebują z góry określonych kategorii czy etykiet. Liczba klastrów może być z góry narzucona (np. K-Means) lub odkryta przez algorytm (np. DBSCAN).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Segmentacja klientów** – grupowanie klientów na podstawie zachowań zakupowych, danych demograficznych, historii przeglądania. Pozwala to firmom na tworzenie spersonalizowanych kampanii marketingowych i strategii produktowych.\n",
    "- **Analiza danych genetycznych i medycznych** – grupowanie genów, próbek DNA, komórek lub pacjentów, aby odkryć podobieństwa i różnice, które mogą wskazywać na wspólne cechy, podtypy chorób lub reakcje na leczenie.\n",
    "- **Organizacja i eksploracja dokumentów lub artykułów** – automatyczne grupowanie tekstów o podobnej tematyce bez ich wcześniejszego tagowania. Ułatwia to wyszukiwanie, przeglądanie i odkrywanie nowych tematów w dużych zbiorach danych tekstowych.\n",
    "- **Detekcja miast w danych geograficznych** – grupowanie punktów danych lokalizacji (np. z GPS), aby zidentyfikować obszary o wysokim zagęszczeniu, co może odpowiadać miastom lub obszarom miejskim.\n",
    "- **Kompresja i segmentacja obrazów** – grupowanie podobnych pikseli lub obszarów obrazu na podstawie koloru, tekstury czy jasności, co może być wykorzystane do kompresji, analizy obiektów lub edycji obrazu.\n",
    "- **Wstępna analiza danych** – odkrywanie naturalnych grup w zbiorze danych, co może dostarczyć cennych insightów przed zastosowaniem algorytmów nadzorowanych lub w celu lepszego zrozumienia danych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- K-Means\n",
    "- Hierarchical Clustering (klastrowanie hierarchiczne)\n",
    "- DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- Gaussian Mixture Models (GMM)\n",
    "- Agglomerative Clustering\n",
    "- Mean-Shift\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Redukcja Wymiarowości (Dimensionality Reduction)\n",
    "\n",
    "Redukcja wymiarowości to typ uczenia nienadzorowanego, który ma na celu **zmniejszenie liczby cech (zmiennych) w zbiorze danych**, jednocześnie zachowując jak najwięcej istotnych informacji.  \n",
    "Pomaga to w wizualizacji danych, usuwaniu szumu, kompresji danych i przyspieszaniu pracy innych algorytmów.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model znajduje sposoby na reprezentowanie danych w przestrzeni o niższej liczbie wymiarów, tworząc nowe, syntetyczne cechy (tzw. komponenty lub embeddingi), które są kombinacją oryginalnych cech. Metody te mogą być liniowe (np. PCA) lub nieliniowe (np. t-SNE, UMAP), zdolne do wykrywania bardziej złożonych struktur.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wizualizacja danych wielowymiarowych** – przekształcenie danych z setek czy tysięcy wymiarów do 2 lub 3 wymiarów, aby móc je wykreślić i zrozumieć strukturę, dostrzec klastry lub anomalie. Jest to kluczowy krok w eksploracyjnej analizie danych.\n",
    "- **Kompresja obrazów i dźwięku** – redukcja liczby pikseli, kanałów kolorów lub próbek sygnału przy zachowaniu akceptowalnej jakości wizualnej/słuchowej, co zmniejsza wymagania dotyczące przechowywania i przesyłania danych.\n",
    "- **Przygotowanie danych do uczenia nadzorowanego** – zmniejszenie liczby cech wejściowych dla klasyfikatorów lub regresorów, aby zapobiec nadmiernemu dopasowaniu (overfitting), zmniejszyć złożoność obliczeniową i poprawić generalizację modelu.\n",
    "- **Redukcja szumu (denoising)** – usunięcie zbędnych, redundantnych lub mało istotnych cech, które mogą wprowadzać szum do modelu i pogarszać jego wydajność.\n",
    "- **Uczenie embeddingów** – tworzenie niskowymiarowych, gęstych reprezentacji (wektorów) dla złożonych obiektów, takich jak słowa (word embeddings), obrazy czy użytkownicy, które zachowują semantyczne lub strukturalne relacje.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- PCA (Principal Component Analysis – Analiza Składowych Głównych)\n",
    "- t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "- UMAP (Uniform Manifold Approximation and Projection)\n",
    "- Autoenkodery (Autoencoders – w sieciach neuronowych)\n",
    "- NMF (Non-negative Matrix Factorization)\n",
    "- LLE (Locally Linear Embedding)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Wizualizacja (Visualization)\n",
    "\n",
    "Wizualizacja danych w kontekście uczenia nienadzorowanego to proces **graficznego przedstawiania złożonych danych**, aby ułatwić zrozumienie ich struktury, wzorców, klastrów, anomalii i relacji między cechami, często po przeprowadzeniu redukcji wymiarowości. Choć nie jest to algorytm uczenia maszynowego per se, jest to nieodzowne narzędzie do interpretacji wyników nienadzorowanych modeli.\n",
    "\n",
    "#### Jak to działa:\n",
    "Wykorzystuje się różne techniki graficzne (wykresy punktowe, mapy cieplne, dendrogramy, wykresy 3D) do przedstawienia danych w sposób, który jest łatwy do odbioru przez człowieka. Często wizualizacja jest efektem zastosowania metod redukcji wymiarowości, które transformują dane do 2 lub 3 wymiarów, umożliwiając ich wykreślenie.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wizualizacja klastrów** – przedstawienie punktów danych w 2D/3D, gdzie punkty należące do tego samego klastra są oznaczone tym samym kolorem lub kształtem. Pozwala to na ocenę jakości klastrowania i zrozumienie, jakie cechy charakteryzują poszczególne grupy.\n",
    "- **Odkrywanie anomalii** – punkty danych, które są wizualnie odseparowane od głównych skupisk, mogą wskazywać na anomalie.\n",
    "- **Eksploracja danych** – szybkie dostrzeżenie relacji między zmiennymi, wykrycie brakujących danych, obserwacja rozkładów cech czy identyfikacja korelacji.\n",
    "- **Ocena jakości redukcji wymiarowości** – sprawdzenie, czy metoda redukcji wymiarowości skutecznie zachowała strukturę danych, np. czy klastry są nadal dobrze rozdzielone po projekcji na niższe wymiary.\n",
    "- **Komunikacja wyników** – prezentowanie złożonych analiz szerszej publiczności w przystępny i intuicyjny sposób.\n",
    "\n",
    "#### Popularne techniki i narzędzia:\n",
    "- Wykresy punktowe (Scatter Plots)\n",
    "- Macierze wykresów punktowych (Scatter Plot Matrices)\n",
    "- Wykresy 3D\n",
    "- Mapy cieplne (Heatmaps)\n",
    "- Dendrogramy (dla klastrowania hierarchicznego)\n",
    "- Wykresy radarowe\n",
    "- Biblioteki Python: Matplotlib, Seaborn, Plotly, Altair\n",
    "- Narzędzia: Tableau, Power BI, Qlik Sense\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Wykrywanie Anomalii (Anomaly Detection)\n",
    "\n",
    "Wykrywanie anomalii to typ uczenia nienadzorowanego, który ma na celu **identyfikację punktów danych, które znacznie odbiegają od większości danych** (tzw. odstępstw lub outlierów).  \n",
    "Anomalie często wskazują na nietypowe, interesujące lub problematyczne zdarzenia.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model uczy się \"normalnego\" wzorca danych, a następnie identyfikuje punkty, które są na tyle różne od tego wzorca, że można je uznać za anomalie. Nie potrzebuje wcześniejszych etykiet anomalii (choć może być wspierane przez nadzór). Podejścia obejmują metody statystyczne, oparte na gęstości, odległości czy modelach uczenia maszynowego.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wykrywanie oszustw finansowych** – identyfikacja nietypowych transakcji kartą kredytową, które mogą wskazywać na oszustwo, lub podejrzanych roszczeń ubezpieczeniowych.\n",
    "- **Monitorowanie sieci komputerowych** – wykrywanie nietypowego ruchu sieciowego, który może sygnalizować atak hakerski, złośliwe oprogramowanie lub naruszenie bezpieczeństwa.\n",
    "- **Diagnostyka usterek maszyn i konserwacja predykcyjna** – monitorowanie danych z sensorów maszyn (np. wibracje, temperatura, zużycie energii) w celu wykrycia nietypowych wzorców wskazujących na zbliżającą się awarię lub potrzebę serwisu.\n",
    "- **Kontrola jakości w produkcji przemysłowej** – automatyczna identyfikacja produktów z wadami, które odbiegają od normy, na podstawie danych z kamer lub sensorów.\n",
    "- **Monitorowanie zdrowia pacjentów** – wykrywanie nietypowych odczytów z urządzeń medycznych (np. EKG, glukometr, smartwatche), które mogą wskazywać na nagły problem zdrowotny lub pogorszenie stanu.\n",
    "- **Analiza danych z sensorów IoT** – wykrywanie nieprawidłowości w odczytach z czujników w inteligentnych domach, miastach czy rolnictwie, np. awarii sprzętu czy nietypowych warunków środowiskowych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Isolation Forest\n",
    "- One-Class SVM (Support Vector Machine dla jednej klasy)\n",
    "- Local Outlier Factor (LOF)\n",
    "- DBSCAN (może być używany do wykrywania punktów nieprzypisanych do klastrów)\n",
    "- Autoenkodery (wersje do wykrywania anomalii, gdzie duży błąd rekonstrukcji wskazuje na anomalię)\n",
    "- K-Nearest Neighbors (k-NN) na podstawie odległości do sąsiadów\n",
    "- Statystyczne metody: 3-Sigma Rule, Box Plots\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie Reguł Asocjacyjnych (Association Rule Learning)\n",
    "\n",
    "Uczenie reguł asocjacyjnych to typ uczenia nienadzorowanego, który ma na celu **odkrywanie interesujących relacji i zależności między zmiennymi w dużych zbiorach danych**, często w kontekście danych transakcyjnych.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model szuka często występujących razem zestawów elementów (np. produktów w koszyku zakupowym) i na ich podstawie generuje reguły typu \"Jeśli kupiono X, to prawdopodobnie kupiono też Y\". Mierzy się wsparcie (support), ufność (confidence) i lift, aby ocenić istotność tych reguł.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Analiza koszyka zakupowego (Market Basket Analysis)** – identyfikacja produktów, które często są kupowane razem (np. \"Klienci, którzy kupują pieluchy, często kupują też piwo\", \"Jeśli klient kupi kawę i cukier, prawdopodobnie kupi też mleko\"). Pomaga to w układaniu towarów w sklepach, ofertach promocyjnych, cross-sellingu czy rekomendacjach online.\n",
    "- **Optymalizacja układu sklepu internetowego lub fizycznego** – umieszczanie często kupowanych razem produktów w pobliżu siebie w celu zwiększenia sprzedaży.\n",
    "- **Systemy rekomendacji** – sugerowanie produktów na podstawie tego, co inni klienci z podobnymi preferencjami kupili (np. \"Często kupowane razem z tym produktem\").\n",
    "- **Analiza danych medycznych** – odkrywanie powiązań między objawami, diagnozami, wynikami badań i lekami, które mogą wspierać badania medyczne i decyzje kliniczne.\n",
    "- **Zarządzanie zapasami** – przewidywanie popytu na produkty komplementarne, aby zoptymalizować stany magazynowe.\n",
    "- **Wykrywanie wzorców w danych sekwencyjnych** – znajdowanie często występujących sekwencji zdarzeń lub czynności (np. w logach systemowych).\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Apriori\n",
    "- FP-Growth (Frequent Pattern Growth)\n",
    "- ECLAT\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu nienadzorowanego:\n",
    "1. **Przygotowanie danych** – zebranie, wstępne oczyszczenie i ewentualne przekształcenie danych (bez etykiet).  \n",
    "2. **Wybór algorytmu** – w zależności od celu (klastrowanie, redukcja, anomalia, reguły asocjacyjne).  \n",
    "3. **Trenowanie modelu** – model samodzielnie odkrywa struktury i wzorce w danych.  \n",
    "4. **Ocena, interpretacja i wizualizacja wyników** – analiza odkrytych wzorców (np. wizualizacja klastrów, analiza komponentów, identyfikacja anomalii, interpretacja reguł).  \n",
    "5. **Dostosowanie parametrów** – iteracyjne poprawianie modelu i algorytmu w celu uzyskania optymalnych i sensownych wyników.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- Segmentacja rynku i personalizacja ofert marketingowych.\n",
    "- Wizualizacja i eksploracja złożonych zbiorów danych dla lepszego zrozumienia.\n",
    "- Kompresja danych, optymalizacja przechowywania i przesyłania.\n",
    "- Wykrywanie oszustw, błędów, usterek i zagrożeń bezpieczeństwa.\n",
    "- Ulepszanie systemów rekomendacyjnych poprzez odkrywanie ukrytych powiązań.\n",
    "- Uczenie się cech (feature learning) dla innych modeli nadzorowanych (jako pre-processing).\n",
    "- Wstępne badanie danych i generowanie hipotez przed zastosowaniem bardziej zaawansowanych technik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57260d4",
   "metadata": {},
   "source": [
    "## Uczenie Pół-nadzorowane (Semi-supervised Learning)\n",
    "\n",
    "Uczenie pół-nadzorowane to rodzaj uczenia maszynowego, który łączy w sobie elementy **uczenia nadzorowanego** i **nienadzorowanego**. Model uczy się na podstawie **niewielkiej ilości danych oznaczonych (z etykietami)** oraz **dużej ilości danych nieoznaczonych (bez etykiet)**.  \n",
    "Jest to szczególnie przydatne w sytuacjach, gdy etykietowanie danych jest kosztowne, czasochłonne lub wymaga specjalistycznej wiedzy.\n",
    "\n",
    "#### Dlaczego Semi-supervised Learning?\n",
    "- **Ograniczone etykiety:** Wiele realnych problemów ma dostęp do dużej ilości danych, ale tylko niewielka ich część jest etykietowana.\n",
    "- **Wykorzystanie nieoznaczonych danych:** Dane nieoznaczone zawierają cenne informacje o strukturze rozkładu danych, które mogą pomóc modelowi lepiej uogólniać.\n",
    "- **Zmniejszenie kosztów:** Redukuje potrzebę ręcznego etykietowania ogromnych zbiorów danych.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na spójności (Consistency Regularization / Self-training)\n",
    "\n",
    "Uczenie oparte na spójności to podejście, w którym model jest trenowany tak, aby jego przewidywania dla danych nieoznaczonych były **spójne** nawet po niewielkich perturbacjach danych wejściowych lub samego modelu. Self-training jest pokrewną techniką, gdzie model \"etykietuje\" dane nieoznaczone.\n",
    "\n",
    "#### Jak to działa:\n",
    "1.  **Self-training:** Model jest początkowo trenowany na małym zbiorze danych oznaczonych. Następnie używa się go do przewidywania etykiet dla danych nieoznaczonych. Te \"pseudo-etykiety\" są dodawane do zbioru treningowego (często z wysoką pewnością), a model jest ponownie trenowany. Proces może być iteracyjny.\n",
    "2.  **Consistency Regularization:** Model jest trenowany tak, aby jego wyjścia dla nieoznaczonych danych były podobne, nawet jeśli te dane zostaną lekko zmienione (np. dodanie szumu, drobne transformacje obrazu). Dodaje się człon regularyzacyjny do funkcji straty, który karze za niespójne przewidywania.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Klasyfikacja obrazów z ograniczonymi etykietami** – np. rozpoznawanie gatunków zwierząt, gdzie mamy tylko kilka zdjęć z etykietami, ale tysiące nieoznaczonych. Model uczy się na etykietowanych, a następnie generuje pseudo-etykiety dla reszty.\n",
    "- **Analiza tekstu (NLP)** – klasyfikacja sentymentu, wykrywanie spamu, gdzie dostępnych jest wiele nieoznaczonych tekstów, ale etykietowanie jest kosztowne.\n",
    "- **Rozpoznawanie mowy** – poprawa dokładności modeli rozpoznawania mowy poprzez wykorzystanie dużych zbiorów nieoznaczonych nagrań audio.\n",
    "- **Diagnostyka medyczna** – wspomaganie klasyfikacji chorób na podstawie obrazów medycznych (np. MRI, RTG), gdzie etykietowanie wymaga ekspertów.\n",
    "- **Systemy rekomendacji** – wykorzystanie nieoznaczonych danych o interakcjach użytkowników do poprawy rekomendacji.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Pseudo-Labeling\n",
    "- Mean Teacher\n",
    "- Pi-Model\n",
    "- Temporal Ensembling\n",
    "- MixMatch, FixMatch (zaawansowane techniki consistency regularization)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na grafach (Graph-based Semi-supervised Learning)\n",
    "\n",
    "Uczenie oparte na grafach wykorzystuje strukturę grafu, gdzie punkty danych są wierzchołkami, a krawędzie reprezentują podobieństwo między nimi. Informacje z etykietowanych wierzchołków są \"rozprzestrzeniane\" na nieoznaczone wierzchołki wzdłuż krawędzi grafu.\n",
    "\n",
    "#### Jak to działa:\n",
    "Tworzy się graf, w którym każdy punkt danych jest węzłem. Krawędzie łączą podobne punkty danych, a ich wagi odzwierciedlają stopień podobieństwa. Etykiety z nielicznych oznaczonych węzłów są propagowane przez graf do nieoznaczonych węzłów, zakładając, że podobne węzły powinny mieć podobne etykiety.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Klasyfikacja dokumentów** – tworzenie grafu, gdzie dokumenty są węzłami, a krawędzie łączą podobne dokumenty. Etykiety z kilku oznaczonych dokumentów są propagowane na resztę.\n",
    "- **Analiza sieci społecznościowych** – klasyfikacja użytkowników (np. identyfikacja botów, segmentacja grup interesu) na podstawie ich połączeń i aktywności, gdzie tylko niewielka część użytkowników jest etykietowana.\n",
    "- **Bioinformatyka** – klasyfikacja białek lub genów na podstawie ich interakcji i podobieństwa sekwencji.\n",
    "- **Wykrywanie oszustw** – budowanie grafu transakcji lub użytkowników i propagowanie informacji o znanych oszustwach na powiązane, nieoznaczone węzły.\n",
    "- **Segmentacja obrazów** – tworzenie grafu z pikseli lub superpikseli obrazu i propagowanie etykiet z kilku oznaczonych regionów na resztę.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Label Propagation (Propagacja etykiet)\n",
    "- Label Spreading\n",
    "- Graph Convolutional Networks (GCNs) – w kontekście głębokiego uczenia na grafach\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na modelach generatywnych (Generative Models for Semi-supervised Learning)\n",
    "\n",
    "Uczenie oparte na modelach generatywnych zakłada, że dane pochodzą z pewnego rozkładu, który można modelować. Modele te próbują nauczyć się tego rozkładu, co pozwala im wykorzystać zarówno dane oznaczone, jak i nieoznaczone.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model generatywny (np. GMM, VAE, GAN) uczy się wspólnego rozkładu prawdopodobieństwa dla danych wejściowych i etykiet. Dane nieoznaczone pomagają modelowi lepiej zrozumieć strukturę danych wejściowych, co z kolei poprawia jego zdolność do klasyfikacji danych oznaczonych.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Klasyfikacja obrazów** – wykorzystanie VAE lub GAN do nauczenia się reprezentacji obrazów, co pomaga w klasyfikacji nawet z ograniczonymi etykietami.\n",
    "- **Rozpoznawanie wzorców** – budowanie modelu, który potrafi generować nowe przykłady danych, co świadczy o zrozumieniu ich struktury.\n",
    "- **Segmentacja obrazów** – modele generatywne mogą pomóc w nauczeniu się, jak wyglądają różne regiony obrazu, nawet jeśli tylko niewielka ich część jest etykietowana.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Gaussian Mixture Models (GMM)\n",
    "- Variational Autoencoders (VAEs)\n",
    "- Generative Adversarial Networks (GANs) w trybie pół-nadzorowanym (SGAN)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na redukcji wymiarowości (Dimensionality Reduction for Semi-supervised Learning)\n",
    "\n",
    "Chociaż redukcja wymiarowości jest techniką nienadzorowaną, może być wykorzystana w kontekście pół-nadzorowanym, aby znaleźć reprezentację danych, która jest optymalna zarówno dla struktury danych (nienadzorowane), jak i dla zadania klasyfikacji (nadzorowane).\n",
    "\n",
    "#### Jak to działa:\n",
    "Niektóre algorytmy redukcji wymiarowości mogą uwzględniać dostępne etykiety, aby znaleźć projekcję, która nie tylko zmniejsza wymiarowość, ale także maksymalizuje separację klas. Inne metody nienadzorowane (np. PCA) mogą być użyte jako pre-processing, a następnie na zredukowanych danych stosuje się techniki pół-nadzorowane.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wizualizacja danych z etykietami i bez** – użycie t-SNE lub UMAP do wizualizacji danych, gdzie punkty z etykietami są wyróżnione, co pomaga w ocenie, czy struktura danych wspiera separację klas.\n",
    "- **Poprawa wydajności klasyfikatorów** – redukcja wymiarowości danych wejściowych przed zastosowaniem algorytmu pół-nadzorowanego lub nadzorowanego, co może zmniejszyć szum i poprawić generalizację.\n",
    "- **Uczenie reprezentacji** – tworzenie niskowymiarowych embeddingów, które są użyteczne zarówno dla zadań nienadzorowanych (np. klastrowanie), jak i nadzorowanych (np. klasyfikacja).\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Semi-supervised PCA (SSPCA)\n",
    "- Linear Discriminant Analysis (LDA) – choć głównie nadzorowane, może być adaptowane\n",
    "- Manifold Learning (np. Isomap, LLE) w połączeniu z etykietami\n",
    "- Autoenkodery z dodatkową funkcją straty dla etykiet\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu pół-nadzorowanego:\n",
    "1. **Przygotowanie danych** – zebranie danych, podział na mały zbiór oznaczony i duży zbiór nieoznaczony.  \n",
    "2. **Wybór algorytmu** – w zależności od dostępnych danych i problemu (np. self-training, graph-based).  \n",
    "3. **Trenowanie modelu** – model uczy się, wykorzystując zarówno etykiety, jak i strukturę danych nieoznaczonych.  \n",
    "4. **Walidacja i testowanie** – ocena modelu na zbiorze testowym (z etykietami).  \n",
    "5. **Ewaluacja wyników** – przy użyciu metryk klasyfikacji (accuracy, precision, recall, F1-score).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Rozpoznawanie obrazów i wideo** – klasyfikacja obiektów, segmentacja, detekcja twarzy, gdzie etykietowanie każdego piksela jest niemożliwe.\n",
    "- **Przetwarzanie języka naturalnego (NLP)** – klasyfikacja tekstu, analiza sentymentu, rozpoznawanie encji, gdzie dostępnych jest wiele nieoznaczonych tekstów.\n",
    "- **Bioinformatyka** – klasyfikacja danych genetycznych, analiza ekspresji genów, gdzie etykietowanie próbek jest kosztowne.\n",
    "- **Diagnostyka medyczna** – wspomaganie klasyfikacji chorób na podstawie obrazów medycznych lub danych pacjentów.\n",
    "- **Wykrywanie oszustw i anomalii** – wykorzystanie nieoznaczonych danych do lepszego zrozumienia \"normalnego\" zachowania i skuteczniejszego wykrywania odstępstw.\n",
    "- **Personalizacja i systemy rekomendacji** – wykorzystanie nieoznaczonych danych o zachowaniach użytkowników do poprawy rekomendacji.\n",
    "- **Uczenie robotów** – roboty mogą uczyć się na podstawie niewielkiej liczby demonstracji (etykiet) i dużej liczby nieoznaczonych interakcji ze środowiskiem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3948247",
   "metadata": {},
   "source": [
    "## Uczenie Samonadzorowane (Self-supervised Learning - SSL)\n",
    "\n",
    "Uczenie samonadzorowane to rodzaj uczenia maszynowego, w którym model uczy się na podstawie **danych nieoznaczonych**, ale generuje **własne \"pseudo-etykiety\"** z tych danych, aby rozwiązać tzw. **zadanie pretekstowe (pretext task)**.  \n",
    "Celem nie jest rozwiązanie samego zadania pretekstowego, lecz nauczenie modelu **ogólnych, użytecznych reprezentacji (embeddingów)** danych, które mogą być następnie wykorzystane do rozwiązywania innych, bardziej złożonych zadań (tzw. **zadań downstream**), często z użyciem uczenia nadzorowanego.\n",
    "\n",
    "#### Dlaczego Self-supervised Learning?\n",
    "- **Brak etykiet:** Podobnie jak w uczeniu nienadzorowanym, SSL nie wymaga ręcznie etykietowanych danych.\n",
    "- **Bogatsze reprezentacje:** W przeciwieństwie do tradycyjnego uczenia nienadzorowanego (np. klastrowania), SSL często prowadzi do nauki bardziej semantycznie bogatych i ogólnych reprezentacji, które są bardzo skuteczne w transfer learningu.\n",
    "- **Skalowalność:** Możliwość wykorzystania ogromnych, nieoznaczonych zbiorów danych (np. miliardów obrazów, terabajtów tekstu) do wstępnego trenowania.\n",
    "- **Most między unsupervised a supervised:** Umożliwia wykorzystanie nienadzorowanych danych do \"rozgrzania\" modelu, który następnie jest dostrajany (fine-tuned) na małym zbiorze danych oznaczonych.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zadania Pretekstowe (Pretext Tasks)\n",
    "\n",
    "Zadania pretekstowe to specjalnie zaprojektowane zadania, które model rozwiązuje na danych nieoznaczonych, aby nauczyć się użytecznych reprezentacji. Model generuje własne etykiety dla tych zadań.\n",
    "\n",
    "#### Jak to działa:\n",
    "Dane wejściowe są modyfikowane w kontrolowany sposób (np. maskowanie części obrazu, tasowanie zdań), a model jest trenowany, aby przewidzieć oryginalny stan lub brakującą część. Rozwiązując te \"sztuczne\" problemy, model uczy się rozumieć strukturę, kontekst i semantykę danych.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Przewidywanie brakujących fragmentów obrazu (Image Inpainting/Context Prediction):** Model otrzymuje obraz z zamaskowanym fragmentem i musi przewidzieć, co się tam znajdowało. Uczy się relacji przestrzennych i semantycznych obiektów.\n",
    "- **Przewidywanie względnej pozycji fragmentów obrazu (Relative Patch Prediction):** Model otrzymuje centralny fragment obrazu i kilka innych fragmentów, a jego zadaniem jest przewidzenie, gdzie te inne fragmenty znajdowały się względem centralnego. Uczy się relacji przestrzennych.\n",
    "- **Kolorowanie obrazów czarno-białych (Colorization):** Model otrzymuje obraz czarno-biały i musi przewidzieć jego kolory. Uczy się rozpoznawać obiekty i ich typowe barwy.\n",
    "- **Generowanie następnego słowa/maskowanie słów (Next Word Prediction/Masked Language Modeling):** W NLP, model otrzymuje sekwencję słów i musi przewidzieć następne słowo (np. GPT) lub zamaskowane słowa w zdaniu (np. BERT). Uczy się gramatyki, składni i semantyki języka.\n",
    "- **Przewidywanie rotacji obrazu (Rotation Prediction):** Model otrzymuje obraz obrócony o losowy kąt i musi przewidzieć ten kąt. Uczy się rozpoznawania obiektów niezależnie od ich orientacji.\n",
    "- **Kontrastowe uczenie się (Contrastive Learning):** Model uczy się, aby podobne przykłady (np. różne augmentacje tego samego obrazu) miały podobne reprezentacje, a niepodobne przykłady – różne. Jest to obecnie jedna z najskuteczniejszych metod SSL.\n",
    "\n",
    "#### Popularne algorytmy/techniki (przykłady zadań pretekstowych):\n",
    "- **Dla obrazów:** Jigsaw Puzzles, Rotation Prediction, Context Prediction, Colorization, SimCLR, MoCo, BYOL (ostatnie trzy to metody kontrastowe).\n",
    "- **Dla tekstu:** Masked Language Modeling (BERT), Next Sentence Prediction (BERT), Next Token Prediction (GPT), ELECTRA.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Transfer Learning (Przenoszenie Wiedzy)\n",
    "\n",
    "Transfer Learning to kluczowy element i główna zaleta uczenia samonadzorowanego. Polega na **przenoszeniu wiedzy (nauczenia się reprezentacji) z jednego zadania (zadania pretekstowego SSL) do innego, często bardziej złożonego zadania (zadania downstream)**.\n",
    "\n",
    "#### Jak to działa:\n",
    "1.  **Pre-training (Wstępne trenowanie):** Model (np. duża sieć neuronowa) jest trenowany na ogromnym zbiorze danych nieoznaczonych, rozwiązując zadanie pretekstowe SSL. W tym etapie model uczy się ogólnych, niskopoziomowych i wysokopoziomowych cech danych (np. krawędzie, tekstury, kształty dla obrazów; gramatyka, semantyka dla tekstu).\n",
    "2.  **Fine-tuning (Dostrajanie):** Nauczenie reprezentacje (wagi i bias sieci) są następnie wykorzystywane jako punkt wyjścia dla nowego zadania (np. klasyfikacji obrazów, analizy sentymentu), które ma dostęp do małego zbioru danych oznaczonych. Zazwyczaj dodaje się nową, małą warstwę wyjściową, która jest trenowana na danych oznaczonych, a reszta modelu jest albo zamrożona, albo trenowana z bardzo małym współczynnikiem uczenia.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Rozpoznawanie obiektów na obrazach medycznych:** Wstępne trenowanie modelu na miliardach ogólnych obrazów (np. ImageNet, ale bez etykiet, używając SSL), a następnie dostrajanie go na małym zbiorze obrazów medycznych (np. RTG klatki piersiowej) z etykietami.\n",
    "- **Klasyfikacja tekstu w rzadkich językach:** Wstępne trenowanie modelu językowego (np. BERT) na ogromnym korpusie tekstu w języku angielskim (lub innym bogatym w dane), a następnie dostrajanie go na małym zbiorze danych w rzadkim języku do zadania klasyfikacji.\n",
    "- **Personalizacja asystentów głosowych:** Wstępne trenowanie modelu na ogólnych danych audio, a następnie dostrajanie go do rozpoznawania mowy konkretnego użytkownika.\n",
    "- **Wykrywanie oszustw:** Wstępne trenowanie modelu na dużej ilości nieoznaczonych danych transakcyjnych, aby nauczyć się \"normalnych\" wzorców, a następnie dostrajanie go do wykrywania oszustw na małym zbiorze etykietowanych transakcji.\n",
    "\n",
    "#### Korzyści z Transfer Learningu w SSL:\n",
    "- **Lepsza wydajność:** Modele osiągają znacznie lepsze wyniki, nawet z małą ilością danych oznaczonych.\n",
    "- **Szybszy trening:** Wstępnie wytrenowany model szybciej konwerguje podczas dostrajania.\n",
    "- **Mniejsze zapotrzebowanie na dane:** Zmniejsza potrzebę posiadania ogromnych, etykietowanych zbiorów danych dla każdego nowego zadania.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Porównanie Self-supervised Learning (SSL) z Unsupervised Learning (UL)\n",
    "\n",
    "Chociaż SSL jest formą uczenia nienadzorowanego, istnieje kluczowa różnica w ich celach i metodologii:\n",
    "\n",
    "| Cecha                  | Uczenie Nienadzorowane (Unsupervised Learning - UL)                               | Uczenie Samonadzorowane (Self-supervised Learning - SSL)                               |\n",
    "| :--------------------- | :-------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |\n",
    "| **Cel główny**         | Odkrywanie ukrytych struktur w danych (np. klastry, redukcja wymiarowości).       | Uczenie się ogólnych, użytecznych reprezentacji danych do **transferu wiedzy**.        |\n",
    "| **Etykiety**           | Brak etykiet.                                                                     | Brak ręcznych etykiet. Model **generuje własne \"pseudo-etykiety\"** z danych.            |\n",
    "| **Zadanie**            | Bezpośrednie rozwiązanie problemu (np. klastrowanie klientów).                    | Rozwiązanie **zadania pretekstowego**, które jest środkiem do celu (nauki reprezentacji). |\n",
    "| **Wyjście**            | Klastry, zredukowane wymiary, wykryte anomalie.                                   | **Reprezentacje (embeddingi)** danych, które są wejściem dla kolejnych zadań.          |\n",
    "| **Zastosowanie**       | Segmentacja, wizualizacja, detekcja anomalii, analiza koszyka.                    | **Pre-training** dla zadań nadzorowanych (klasyfikacja, detekcja obiektów, NLP).       |\n",
    "| **Typowe algorytmy**   | K-Means, PCA, DBSCAN, Isolation Forest, Apriori.                                  | BERT, GPT, SimCLR, MoCo, BYOL (często oparte na głębokich sieciach neuronowych).       |\n",
    "| **Złożoność modelu**   | Często prostsze modele, choć mogą być też głębokie autoenkodery.                   | Zazwyczaj **głębokie sieci neuronowe** (transformery, konwolucyjne).                   |\n",
    "\n",
    "**Kluczowa różnica:**\n",
    "UL skupia się na **bezpośrednim odkrywaniu wzorców** w danych. SSL natomiast skupia się na **uczeniu się reprezentacji**, które są tak dobre, że mogą być **przeniesione** do innych zadań, często nadzorowanych, znacząco poprawiając ich wydajność, nawet przy małej ilości etykiet. SSL jest często postrzegane jako sposób na \"rozgrzanie\" dużych modeli głębokiego uczenia, aby były bardziej efektywne w późniejszym dostrajaniu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu samonadzorowanego:\n",
    "1. **Przygotowanie danych** – zebranie dużego zbioru danych nieoznaczonych.  \n",
    "2. **Definicja zadania pretekstowego** – zaprojektowanie zadania, które pozwoli modelowi nauczyć się użytecznych reprezentacji.  \n",
    "3. **Trenowanie modelu (Pre-training)** – model uczy się rozwiązywać zadanie pretekstowe, generując własne pseudo-etykiety.  \n",
    "4. **Ekstrakcja reprezentacji** – po pre-treningu, warstwy modelu (z wyjątkiem warstwy wyjściowej zadania pretekstowego) są wykorzystywane do ekstrakcji embeddingów.  \n",
    "5. **Dostrajanie (Fine-tuning)** – na małym zbiorze danych oznaczonych, model jest dostrajany do właściwego zadania (downstream task).  \n",
    "6. **Ewaluacja wyników** – ocena modelu na zbiorze testowym dla zadania downstream.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Przetwarzanie języka naturalnego (NLP):** Modele takie jak BERT, GPT-3/4, T5 są trenowane samonadzorowanie na ogromnych korpusach tekstu, a następnie dostrajane do tłumaczenia maszynowego, generowania tekstu, analizy sentymentu, odpowiadania na pytania.\n",
    "- **Wizja komputerowa:** Modele trenowane samonadzorowanie (np. SimCLR, MoCo) na miliardach obrazów, a następnie dostrajane do klasyfikacji obrazów, detekcji obiektów, segmentacji, rozpoznawania twarzy, nawet z bardzo małą ilością etykiet.\n",
    "- **Rozpoznawanie mowy:** Wstępne trenowanie na dużych zbiorach audio, a następnie dostrajanie do transkrypcji mowy, identyfikacji mówcy.\n",
    "- **Bioinformatyka:** Uczenie reprezentacji sekwencji DNA/RNA/białek, które mogą być następnie użyte do przewidywania funkcji białek, wykrywania mutacji.\n",
    "- **Robotyka:** Uczenie się reprezentacji środowiska i interakcji na podstawie nieoznaczonych danych z sensorów, co pomaga robotom w nawigacji i manipulacji.\n",
    "- **Medycyna:** Wstępne trenowanie na dużych zbiorach nieoznaczonych obrazów medycznych, a następnie dostrajanie do diagnozy chorób."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72935d52",
   "metadata": {},
   "source": [
    "## Uczenie ze Wzmocnieniem (Reinforcement Learning - RL)\n",
    "\n",
    "Uczenie ze wzmocnieniem to zupełnie inny paradygmat uczenia maszynowego, w którym system uczący, zwany w tym kontekście **agentem**, może **obserwować środowisko**, **wybierać i wykonywać akcje**, a w zamian otrzymuje **nagrody** (lub kary w postaci negatywnych nagród).  \n",
    "Agent musi samodzielnie nauczyć się, jaka jest najlepsza strategia, zwana **polityką (policy)**, aby z czasem uzyskać jak najwięcej nagród. Polityka definiuje, jaką akcję agent powinien wybrać w danej sytuacji.\n",
    "\n",
    "#### Dlaczego Reinforcement Learning?\n",
    "- **Interakcja ze środowiskiem:** RL jest idealne do problemów, gdzie system musi podejmować sekwencję decyzji w dynamicznym środowisku.\n",
    "- **Brak etykiet:** Nie wymaga ręcznie etykietowanych danych wejścia-wyjścia; uczy się na podstawie prób i błędów oraz otrzymywanych nagród.\n",
    "- **Optymalizacja długoterminowa:** Skupia się na maksymalizacji skumulowanej nagrody w czasie, a nie tylko na natychmiastowych korzyściach.\n",
    "- **Autonomiczne systemy:** Umożliwia tworzenie systemów, które uczą się adaptować i optymalizować swoje zachowanie w złożonych scenariuszach.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Agent i Środowisko (Agent and Environment)\n",
    "\n",
    "W uczeniu ze wzmocnieniem, interakcja odbywa się między **agentem** a **środowiskiem**.\n",
    "\n",
    "#### Jak to działa:\n",
    "- **Agent:** To system uczący się, który podejmuje decyzje. Obserwuje stan środowiska, wybiera akcję do wykonania i otrzymuje nagrodę (lub karę) oraz nowy stan środowiska.\n",
    "- **Środowisko:** To świat, w którym działa agent. Reaguje na akcje agenta, zmieniając swój stan i dostarczając nagrody.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Robot kroczący:** Robot (agent) obserwuje swoje położenie i równowagę (stan środowiska), wykonuje ruchy nogami (akcje), a otrzymuje nagrody za utrzymanie równowagi i poruszanie się do przodu, a kary za upadek.\n",
    "- **Gra w Go (AlphaGo):** Program AlphaGo (agent) obserwuje planszę (stan środowiska), wykonuje ruch (akcję), a otrzymuje nagrody za wygrane partie i kary za przegrane.\n",
    "- **Autonomiczny samochód:** Samochód (agent) obserwuje drogę, inne pojazdy, znaki (stan środowiska), wykonuje akcje (przyspieszanie, hamowanie, skręcanie), a otrzymuje nagrody za bezpieczną jazdę i dotarcie do celu, a kary za kolizje czy naruszenia przepisów.\n",
    "- **System zarządzania energią:** System (agent) obserwuje zużycie energii, ceny, prognozy pogody (stan środowiska), podejmuje decyzje o włączeniu/wyłączeniu urządzeń (akcje), a otrzymuje nagrody za oszczędności i kary za przekroczenie limitów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Akcje, Stany i Nagrody (Actions, States, and Rewards)\n",
    "\n",
    "To podstawowe elementy, które definiują interakcję agenta ze środowiskiem.\n",
    "\n",
    "#### Jak to działa:\n",
    "- **Akcje (Actions):** Decyzje, które agent może podjąć w danym stanie środowiska. Mogą być dyskretne (np. \"idź w lewo\", \"kup\") lub ciągłe (np. \"przyspiesz o 0.5 m/s²\").\n",
    "- **Stany (States):** Reprezentacja aktualnej sytuacji środowiska, którą agent może obserwować. Stan zawiera wszystkie istotne informacje potrzebne agentowi do podjęcia decyzji.\n",
    "- **Nagrody (Rewards):** Sygnał zwrotny od środowiska, który informuje agenta o jakości jego ostatniej akcji. Nagrody są kluczowe dla uczenia się polityki. Celem agenta jest maksymalizacja skumulowanej nagrody w czasie.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Gra w szachy:**\n",
    "    - **Akcje:** Wykonanie ruchu figurą.\n",
    "    - **Stany:** Układ figur na szachownicy.\n",
    "    - **Nagrody:** +1 za wygraną, -1 za przegraną, 0 za remis lub ruchy pośrednie.\n",
    "- **Zarządzanie magazynem:**\n",
    "    - **Akcje:** Zamówienie towaru, wysyłka towaru.\n",
    "    - **Stany:** Poziom zapasów, prognozy popytu.\n",
    "    - **Nagrody:** + za zysk ze sprzedaży, - za koszty magazynowania, - za brak towaru.\n",
    "- **Sterowanie robotem przemysłowym:**\n",
    "    - **Akcje:** Ruch ramienia robota w określonym kierunku.\n",
    "    - **Stany:** Pozycja ramienia, położenie obiektu.\n",
    "    - **Nagrody:** + za prawidłowe chwycenie obiektu, - za upuszczenie obiektu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Polityka (Policy)\n",
    "\n",
    "Polityka to **strategia** agenta, która definiuje, jaką akcję powinien wybrać w danej sytuacji (stanie środowiska). Jest to \"mózg\" agenta, który kieruje jego zachowaniem.\n",
    "\n",
    "#### Jak to działa:\n",
    "Polityka może być deterministyczna (dla danego stanu zawsze wybiera tę samą akcję) lub stochastyczna (dla danego stanu wybiera akcję z pewnym prawdopodobieństwem). Celem uczenia ze wzmocnieniem jest znalezienie optymalnej polityki, która maksymalizuje oczekiwaną skumulowaną nagrodę.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Polityka AlphaGo:** AlphaGo nauczyło się swojej zwycięskiej polityki poprzez analizę milionów gier i rozgrywanie wielu gier przeciwko sobie. Polityka ta definiowała, jaki ruch wykonać w każdej możliwej konfiguracji planszy Go.\n",
    "- **Polityka robota kroczącego:** Polityka robota może definiować, jak poruszać nogami w zależności od aktualnego stanu równowagi i prędkości, aby utrzymać się na nogach i iść do przodu.\n",
    "- **Polityka systemu rekomendacji:** Polityka może decydować, jaki produkt zarekomendować użytkownikowi w zależności od jego historii przeglądania i zakupów, aby zmaksymalizować prawdopodobieństwo zakupu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu (Reinforcement Learning):\n",
    "1. **Definicja środowiska i nagród** – określenie, jak agent będzie wchodził w interakcje ze światem i jakie nagrody będzie otrzymywał.  \n",
    "2. **Inicjalizacja polityki** – początkowa, często losowa, strategia agenta.  \n",
    "3. **Interakcja ze środowiskiem** – agent obserwuje stan, wybiera akcję zgodnie z polityką, wykonuje ją, otrzymuje nagrodę i nowy stan.  \n",
    "4. **Aktualizacja polityki** – na podstawie otrzymanych nagród, agent modyfikuje swoją politykę, aby w przyszłości podejmować lepsze decyzje.  \n",
    "5. **Iteracja** – proces interakcji i aktualizacji powtarza się wielokrotnie, aż agent nauczy się optymalnej polityki.  \n",
    "6. **Zastosowanie polityki** – po nauczeniu, agent stosuje wyuczoną politykę do rozwiązywania problemu (np. AlphaGo stosujące wyuczoną politykę w grze przeciwko mistrzowi).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Robotyka:** Uczenie robotów chodzenia, manipulacji obiektami, nawigacji w złożonych środowiskach.\n",
    "- **Gry:** Tworzenie agentów AI, którzy potrafią grać w gry (szachy, Go, gry wideo) na poziomie mistrzowskim lub ponadludzkim (np. AlphaGo, AlphaStar, OpenAI Five).\n",
    "- **Autonomiczne pojazdy:** Uczenie samochodów, jak bezpiecznie i efektywnie jeździć, unikać przeszkód, parkować.\n",
    "- **Systemy rekomendacji:** Optymalizacja rekomendacji produktów, filmów czy muzyki w celu maksymalizacji zaangażowania użytkownika.\n",
    "- **Zarządzanie zasobami:** Optymalizacja zużycia energii w centrach danych, zarządzanie ruchem w sieciach telekomunikacyjnych.\n",
    "- **Finanse:** Optymalizacja strategii handlowych, zarządzanie portfelem inwestycyjnym.\n",
    "- **Medycyna:** Optymalizacja planów leczenia, dawkowania leków w czasie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c575e99",
   "metadata": {},
   "source": [
    "## Uczenie Wsadowe (Batch Learning)\n",
    "\n",
    "Uczenie wsadowe to paradygmat uczenia maszynowego, w którym system **nie jest zdolny do uczenia się przyrostowego**. Oznacza to, że model musi być **trenowany przy użyciu wszystkich dostępnych danych jednocześnie**.  \n",
    "Proces ten zazwyczaj wymaga znacznych zasobów obliczeniowych i czasu, dlatego jest typowo przeprowadzany **offline**. Po wytrenowaniu system jest uruchamiany w środowisku produkcyjnym i działa, stosując wyuczoną wiedzę, bez dalszego uczenia się.\n",
    "\n",
    "#### Dlaczego Batch Learning?\n",
    "- **Prostota implementacji:** Jest to często najprostszy sposób na trenowanie modeli, szczególnie dla problemów, gdzie dane są stabilne.\n",
    "- **Stabilność modelu:** Model jest trenowany na całym zbiorze danych, co często prowadzi do stabilniejszych i bardziej uogólniających wyników, jeśli dane nie zmieniają się szybko.\n",
    "- **Kontrolowane środowisko:** Idealne dla środowisk, gdzie model jest regularnie aktualizowany w kontrolowany sposób.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie Offline (Offline Learning)\n",
    "\n",
    "Uczenie offline to charakterystyczna cecha uczenia wsadowego. Oznacza, że model jest **trenowany raz, poza środowiskiem produkcyjnym**, a następnie jest wdrażany i działa, stosując to, czego się nauczył, bez dalszego uczenia się w czasie rzeczywistym.\n",
    "\n",
    "#### Jak to działa:\n",
    "1.  **Trenowanie:** Model jest trenowany na kompletnym zbiorze danych.\n",
    "2.  **Wdrożenie:** Wytrenowany model jest uruchamiany w środowisku produkcyjnym.\n",
    "3.  **Działanie:** Model dokonuje przewidywań lub klasyfikacji, ale nie aktualizuje swoich wag ani nie uczy się na podstawie nowych danych, które napływają po wdrożeniu.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Systemy rekomendacji produktów:** Model jest trenowany raz dziennie lub raz w tygodniu na wszystkich danych o zakupach, a następnie używany do rekomendowania produktów.\n",
    "- **Klasyfikacja spamu:** Model jest trenowany na zbiorze znanych wiadomości spamowych i nie-spamowych, a następnie używany do filtrowania nowych wiadomości e-mail. Jeśli pojawi się nowy typ spamu, system nie nauczy się go automatycznie.\n",
    "- **Diagnostyka medyczna:** Model trenowany na historycznych danych pacjentów do diagnozowania chorób. Nowe przypadki są klasyfikowane na podstawie tego modelu, ale model nie uczy się z nich w locie.\n",
    "- **Ocena ryzyka kredytowego:** Model jest trenowany na historycznych danych kredytowych, a następnie używany do oceny nowych wniosków kredytowych.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Aktualizacja Modelu i Rozkład Danych (Model Update and Data Drift)\n",
    "\n",
    "W systemach uczenia wsadowego, aby model mógł uwzględnić nowe dane (np. nowy typ spamu, zmieniające się preferencje klientów), konieczne jest **ponowne wytrenowanie nowej wersji systemu od podstaw**.\n",
    "\n",
    "#### Jak to działa:\n",
    "1.  **Zebranie nowych danych:** Zbierane są nowe dane, które pojawiły się od ostatniego treningu.\n",
    "2.  **Połączenie danych:** Nowe dane są łączone ze starym, pełnym zbiorem danych.\n",
    "3.  **Ponowne trenowanie:** Nowa wersja systemu jest trenowana od zera na całym, zaktualizowanym zbiorze danych.\n",
    "4.  **Wymiana systemu:** Stary system w produkcji jest zatrzymywany i zastępowany nową, świeżo wytrenowaną wersją.\n",
    "\n",
    "#### Rozkład Modelu (Data Drift):\n",
    "**Data Drift** (dryf danych) odnosi się do zjawiska, w którym **statystyczne właściwości danych wejściowych zmieniają się w czasie**. Jeśli dane, na których model został wytrenowany, różnią się znacząco od danych, które napływają w produkcji, wydajność modelu może drastycznie spaść.\n",
    "\n",
    "- **Wyzwanie dla Batch Learning:** Uczenie wsadowe jest szczególnie wrażliwe na dryf danych, ponieważ model nie uczy się przyrostowo. Jeśli dane zmieniają się szybko (np. ceny akcji, trendy w mediach społecznościowych), model trenowany raz dziennie lub raz w tygodniu może szybko stać się nieaktualny i mało skuteczny.\n",
    "- **Konieczność częstych aktualizacji:** Aby przeciwdziałać dryfowi danych, systemy wsadowe muszą być regularnie aktualizowane poprzez ponowne trenowanie. Jednak ten proces jest kosztowny i czasochłonny.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Prognozowanie cen akcji:** Rynek akcji zmienia się bardzo dynamicznie. Model trenowany wsadowo raz dziennie może szybko stracić na dokładności z powodu dryfu danych.\n",
    "- **Wykrywanie trendów w mediach społecznościowych:** Język i tematyka w mediach społecznościowych ewoluują błyskawicznie. Model do analizy sentymentu wymagałby bardzo częstych aktualizacji.\n",
    "- **Systemy rekomendacji:** Preferencje użytkowników zmieniają się. Model rekomendujący filmy, trenowany raz na miesiąc, może nie być w stanie dostosować się do nowych hitów czy zmieniających się gustów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Ograniczenia i Wyzwania (Limitations and Challenges)\n",
    "\n",
    "Uczenie wsadowe, choć proste, ma szereg ograniczeń, które sprawiają, że nie jest odpowiednie dla wszystkich scenariuszy.\n",
    "\n",
    "#### Jak to działa:\n",
    "Ograniczenia wynikają głównie z konieczności trenowania na całym zbiorze danych i braku zdolności do uczenia się przyrostowego.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Czas i zasoby obliczeniowe:** Trenowanie na pełnym zbiorze danych może zająć wiele godzin i wymagać dużej mocy obliczeniowej (CPU, pamięć, przestrzeń dyskowa, I/O). Codzienne trenowanie dużego modelu może być bardzo kosztowne.\n",
    "- **Szybko zmieniające się dane:** Jeśli system musi szybko adaptować się do nowych danych (np. przewidywanie cen akcji, wykrywanie nowych typów oszustw), uczenie wsadowe jest zbyt wolne. Nowy system trenowany co 24 godziny lub co tydzień może być już nieaktualny.\n",
    "- **Ogromne zbiory danych:** Jeśli ilość danych jest zbyt duża, trenowanie na całym zbiorze może być wręcz niemożliwe ze względu na ograniczenia pamięciowe i obliczeniowe.\n",
    "- **Ograniczone zasoby na urządzeniu:** W przypadku systemów działających na urządzeniach z ograniczonymi zasobami (np. aplikacje na smartfony, łaziki marsjańskie), przechowywanie ogromnych zbiorów danych treningowych i zużywanie zasobów na codzienne, wielogodzinne trenowanie jest niewykonalne.\n",
    "- **Brak autonomii:** Systemy wsadowe nie uczą się autonomicznie w środowisku produkcyjnym; wymagają interwencji (ponownego trenowania) w celu adaptacji.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu (Batch Learning):\n",
    "1. **Zebranie pełnego zbioru danych** – wszystkie dostępne dane są gromadzone.  \n",
    "2. **Trenowanie modelu** – model jest trenowany na całym zbiorze danych.  \n",
    "3. **Ocena i walidacja** – model jest testowany na zbiorze walidacyjnym/testowym.  \n",
    "4. **Wdrożenie do produkcji** – wytrenowany model jest uruchamiany i dokonuje przewidywań.  \n",
    "5. **Monitorowanie wydajności** – śledzenie, jak model radzi sobie w produkcji.  \n",
    "6. **Aktualizacja (jeśli potrzebna)** – jeśli wydajność spada lub pojawiają się nowe dane, proces wraca do kroku 1 (zbieranie danych + nowe dane) i model jest ponownie trenowany od zera.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Systemy rekomendacji offline:** Generowanie rekomendacji na podstawie historycznych danych, aktualizowanych cyklicznie.\n",
    "- **Klasyfikacja spamu:** Filtrowanie wiadomości e-mail na podstawie modelu trenowanego na zbiorze znanych spamu.\n",
    "- **Analiza obrazów:** Klasyfikacja obrazów w bazach danych, gdzie nowe obrazy są dodawane okresowo.\n",
    "- **Ocena ryzyka kredytowego:** Modele oceniające zdolność kredytową, aktualizowane co kwartał lub co pół roku.\n",
    "- **Prognozowanie sprzedaży:** Prognozy sprzedaży produktów na podstawie danych historycznych, aktualizowane co miesiąc.\n",
    "- **Wykrywanie oszustw (w niektórych scenariuszach):** Modele wykrywające oszustwa, które są regularnie trenowane na nowych danych, ale nie uczą się w czasie rzeczywistym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fccc0",
   "metadata": {},
   "source": [
    "## Uczenie Przyrostowe (Online Learning)\n",
    "\n",
    "Uczenie przyrostowe to paradygmat uczenia maszynowego, w którym system jest **trenowany przyrostowo**, poprzez dostarczanie mu instancji danych **sekwencyjnie**, pojedynczo lub w małych grupach zwanych **mini-partiami (mini-batches)**.  \n",
    "Każdy krok uczenia jest szybki i tani, co pozwala systemowi **uczyć się na bieżąco (on the fly)**, w miarę napływania nowych danych.\n",
    "\n",
    "#### Dlaczego Online Learning?\n",
    "- **Szybka adaptacja:** Idealne dla systemów, które otrzymują dane w ciągłym strumieniu i muszą szybko adaptować się do zmian (np. ceny akcji, trendy).\n",
    "- **Ograniczone zasoby:** Dobra opcja, jeśli masz ograniczone zasoby obliczeniowe, ponieważ system nie potrzebuje przechowywać wszystkich danych treningowych po ich przetworzeniu.\n",
    "- **Ogromne zbiory danych:** Umożliwia trenowanie na zbiorach danych, które nie mieszczą się w pamięci głównej jednej maszyny (out-of-core learning).\n",
    "- **Autonomia:** System może uczyć się autonomicznie w środowisku produkcyjnym.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie Przyrostowe i Strumienie Danych (Incremental Learning and Data Streams)\n",
    "\n",
    "Uczenie przyrostowe jest kluczowe dla systemów, które muszą adaptować się do danych napływających w sposób ciągły.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model jest aktualizowany małymi krokami, przetwarzając pojedyncze instancje danych lub małe mini-partie. Po przetworzeniu dane te mogą zostać odrzucone, co oszczędza pamięć.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Prognozowanie cen akcji:** System uczy się na bieżąco na podstawie napływających danych o transakcjach, szybko adaptując się do zmian rynkowych.\n",
    "- **Filtry spamu:** Filtr spamu może uczyć się na bieżąco o nowych typach spamu, gdy tylko pojawiają się nowe wiadomości.\n",
    "- **Systemy rekomendacji w czasie rzeczywistym:** Adaptacja rekomendacji w miarę, jak użytkownik przegląda nowe produkty lub ocenia treści.\n",
    "- **Monitorowanie sieci komputerowych:** Wykrywanie nowych typów ataków lub anomalii w ruchu sieciowym w miarę ich pojawiania się.\n",
    "- **Robotyka:** Robot może uczyć się nowych umiejętności lub adaptować się do zmieniającego się środowiska w czasie rzeczywistym.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie Poza Pamięcią (Out-of-core Learning)\n",
    "\n",
    "Uczenie poza pamięcią to zastosowanie algorytmów uczenia przyrostowego do trenowania systemów na **ogromnych zbiorach danych, które nie mieszczą się w pamięci głównej jednej maszyny**.\n",
    "\n",
    "#### Jak to działa:\n",
    "Algorytm ładuje część danych (mini-partię), wykonuje krok treningowy na tych danych, a następnie powtarza proces, aż przetworzy wszystkie dane. Chociaż jest to forma uczenia przyrostowego, często odbywa się offline (tj. nie na systemie działającym na żywo), dlatego nazwa \"online learning\" może być myląca w tym kontekście – lepiej myśleć o tym jako o uczeniu przyrostowym.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Przetwarzanie bardzo dużych zbiorów danych tekstowych:** Trenowanie modeli językowych na korpusach tekstu, które są zbyt duże, aby zmieścić się w pamięci RAM.\n",
    "- **Analiza danych z sensorów IoT:** Przetwarzanie terabajtów danych z czujników, gdzie dane są ładowane i przetwarzane w małych fragmentach.\n",
    "- **Big Data w chmurze:** Trenowanie modeli na ogromnych zbiorach danych przechowywanych w rozproszonych systemach plików, gdzie dane są strumieniowane do algorytmu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Współczynnik Uczenia (Learning Rate)\n",
    "\n",
    "Współczynnik uczenia (learning rate) to kluczowy parametr w systemach uczenia przyrostowego, który określa, **jak szybko system powinien adaptować się do zmieniających się danych**.\n",
    "\n",
    "#### Jak to działa:\n",
    "- **Wysoki współczynnik uczenia:**\n",
    "    - **Zalety:** System szybko adaptuje się do nowych danych.\n",
    "    - **Wady:** Ma tendencję do szybkiego zapominania starych danych. Może być również bardziej wrażliwy na szum w nowych danych lub na sekwencje niereprezentatywnych punktów danych (outlierów).\n",
    "    - **Kiedy używać:** Gdy dane zmieniają się bardzo szybko i chcemy, aby model reagował natychmiast, nawet kosztem zapominania przeszłości (np. bardzo dynamiczne rynki finansowe).\n",
    "- **Niski współczynnik uczenia:**\n",
    "    - **Zalety:** System ma większą inercję, uczy się wolniej, ale jest mniej wrażliwy na szum w nowych danych lub na pojedyncze odstępstwa. Lepiej zachowuje wiedzę o starych danych.\n",
    "    - **Wady:** Wolniejsza adaptacja do istotnych zmian w danych.\n",
    "    - **Kiedy używać:** Gdy dane są stosunkowo stabilne, ale chcemy, aby model stopniowo adaptował się do subtelnych zmian, jednocześnie zachowując wiedzę o ogólnych wzorcach (np. filtr spamu, który nie powinien zapominać o starych typach spamu).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Filtr spamu:** Chcemy, aby filtr spamu uczył się o nowych typach spamu, ale nie zapominał o starych. Zbyt wysoki współczynnik uczenia mógłby sprawić, że filtr oznaczałby tylko najnowsze rodzaje spamu, ignorując te, które pojawiły się wcześniej.\n",
    "- **System rekomendacji:** Jeśli współczynnik uczenia jest zbyt wysoki, system może zbyt szybko zmieniać rekomendacje na podstawie kilku ostatnich interakcji, ignorując długoterminowe preferencje użytkownika.\n",
    "- **Sterowanie robotem:** Zbyt wysoki współczynnik uczenia może sprawić, że robot będzie reagował zbyt gwałtownie na drobne zakłócenia, co może prowadzić do niestabilności.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Wyzwania i Monitorowanie (Challenges and Monitoring)\n",
    "\n",
    "Uczenie przyrostowe niesie ze sobą pewne wyzwania, zwłaszcza w kontekście jakości danych.\n",
    "\n",
    "#### Jak to działa:\n",
    "Jeśli do systemu zostaną dostarczone złe dane (np. z wadliwego sensora, celowe spamowanie), wydajność systemu może stopniowo spadać. W systemach działających na żywo klienci szybko to zauważą.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wadliwy sensor robota:** Jeśli sensor robota zacznie działać nieprawidłowo, dostarczając błędne dane, robot może nauczyć się złych zachowań, co doprowadzi do awarii.\n",
    "- **Spamowanie wyszukiwarki:** Osoby próbujące manipulować wynikami wyszukiwania mogą dostarczać \"złe\" dane, które mogą sprawić, że algorytm wyszukiwarki zacznie promować nieistotne treści.\n",
    "- **Złośliwe ataki na systemy AI:** Atakujący mogą celowo dostarczać zniekształcone dane, aby \"otruć\" model i obniżyć jego wydajność lub zmusić go do błędnych decyzji.\n",
    "\n",
    "#### Rozwiązania:\n",
    "- **Ścisłe monitorowanie:** Konieczne jest ciągłe monitorowanie wydajności systemu.\n",
    "- **Wyłączanie uczenia:** W przypadku wykrycia spadku wydajności, należy szybko wyłączyć uczenie (i ewentualnie przywrócić system do poprzedniego, działającego stanu).\n",
    "- **Monitorowanie danych wejściowych:** Stosowanie algorytmów wykrywania anomalii (np. z uczenia nienadzorowanego) do monitorowania danych wejściowych i reagowania na nietypowe dane.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu (Online Learning):\n",
    "1. **Inicjalizacja modelu** – model jest inicjowany (często na małym zbiorze danych lub losowo).  \n",
    "2. **Ciągłe dostarczanie danych** – system otrzymuje instancje danych sekwencyjnie (pojedynczo lub w mini-partiach).  \n",
    "3. **Krok uczenia** – dla każdej instancji/mini-partii, model aktualizuje swoje wagi.  \n",
    "4. **Odrzucanie danych** – po przetworzeniu, dane mogą zostać odrzucone (opcjonalnie, jeśli nie ma potrzeby ich ponownego użycia).  \n",
    "5. **Ciągłe monitorowanie** – wydajność systemu jest stale monitorowana, a dane wejściowe sprawdzane pod kątem anomalii.  \n",
    "6. **Adaptacja** – model nieustannie adaptuje się do nowych danych i zmieniających się warunków.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Systemy rekomendacji w czasie rzeczywistym:** Adaptacja rekomendacji na platformach e-commerce, streamingowych.\n",
    "- **Filtry spamu i wykrywanie oszustw:** Szybka adaptacja do nowych wzorców spamu lub oszustw.\n",
    "- **Prognozowanie finansowe:** Modele przewidujące ruchy na giełdzie, kursy walut.\n",
    "- **Personalizacja interfejsów użytkownika:** Dostosowywanie wyglądu i funkcji aplikacji do indywidualnych preferencji użytkownika w czasie rzeczywistym.\n",
    "- **Robotyka i sterowanie autonomiczne:** Roboty uczące się nawigacji, manipulacji obiektami, adaptujące się do nieprzewidywalnych środowisk.\n",
    "- **Systemy monitorowania zdrowia:** Analiza danych z urządzeń noszonych (wearables) i adaptacja do zmieniającego się stanu zdrowia użytkownika.\n",
    "- **Optymalizacja reklam:** Dynamiczne dostosowywanie wyświetlanych reklam na podstawie bieżących interakcji użytkownika."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cb721",
   "metadata": {},
   "source": [
    "## Uczenie z Przykładu (Instance-based Learning)\n",
    "\n",
    "Uczenie z przykładu to paradygmat uczenia maszynowego, w którym system **nie buduje jawnego modelu** na podstawie danych treningowych. Zamiast tego, **zapamiętuje wszystkie (lub większość) przykłady treningowe** i uogólnia na nowe przypadki, porównując je z zapamiętanymi przykładami za pomocą **miary podobieństwa**.  \n",
    "Można to bardzo prosto opisać jako **\"kucie na blachę\"** przez maszynę danych treningowych, a następnie podejmowanie decyzji na podstawie tego, co \"zapamiętała\" i jak bardzo nowy przypadek jest podobny do tych zapamiętanych.\n",
    "\n",
    "#### Dlaczego Instance-based Learning?\n",
    "- **Prostota koncepcyjna:** Jest to jedna z najbardziej intuicyjnych form uczenia się.\n",
    "- **Brak jawnego modelu:** Nie ma potrzeby budowania złożonego modelu matematycznego, co może być zaletą w niektórych scenariuszach.\n",
    "- **Elastyczność:** Może adaptować się do złożonych granic decyzyjnych, ponieważ nie narzuca sztywnej struktury modelu.\n",
    "- **Łatwość aktualizacji:** Dodawanie nowych danych treningowych jest proste – wystarczy je zapamiętać.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zapamiętywanie Danych (Learning by Heart)\n",
    "\n",
    "Najbardziej trywialną formą uczenia się z przykładu jest po prostu **zapamiętywanie danych treningowych**.\n",
    "\n",
    "#### Jak to działa:\n",
    "System przechowuje wszystkie przykłady treningowe. Kiedy pojawia się nowa instancja, system porównuje ją z zapamiętanymi przykładami.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Filtr spamu (bardzo podstawowy):** System zapamiętuje wszystkie wiadomości e-mail, które zostały oznaczone przez użytkowników jako spam. Nowa wiadomość jest oznaczana jako spam tylko wtedy, gdy jest **identyczna** z którąś z zapamiętanych wiadomości spamowych. To nie jest najlepsze rozwiązanie, ale pokazuje podstawową ideę.\n",
    "- **Bazy danych przypadków:** W systemach eksperckich, gdzie system przechowuje historyczne przypadki i ich rozwiązania, a następnie szuka identycznego przypadku dla nowej sytuacji.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uogólnianie przez Podobieństwo (Generalization by Similarity)\n",
    "\n",
    "Prawdziwa moc uczenia z przykładu objawia się, gdy system uogólnia na nowe przypadki, wykorzystując **miarę podobieństwa** do porównywania ich z zapamiętanymi przykładami.\n",
    "\n",
    "#### Jak to działa:\n",
    "Zamiast szukać identycznych przykładów, system szuka przykładów **bardzo podobnych**. Nowa instancja jest klasyfikowana lub przewidywana na podstawie etykiet (lub wartości) najbardziej podobnych zapamiętanych przykładów.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Filtr spamu (ulepszony):** System nie tylko oznacza e-maile identyczne ze znanym spamem, ale także te, które są **bardzo podobne**. Miara podobieństwa może polegać na zliczaniu wspólnych słów. Jeśli nowa wiadomość ma wiele wspólnych słów ze znanym spamem, zostanie oznaczona jako spam.\n",
    "- **Systemy rekomendacji (najbliżsi sąsiedzi):** Jeśli użytkownik ogląda film, system szuka innych użytkowników, którzy oglądali podobne filmy, a następnie rekomenduje filmy, które oglądali ci \"sąsiedzi\".\n",
    "- **Rozpoznawanie pisma ręcznego:** Nowy znak jest porównywany z zapamiętanymi przykładami każdego znaku. Jeśli jest najbardziej podobny do zapamiętanych \"A\", zostanie sklasyfikowany jako \"A\".\n",
    "- **Diagnostyka medyczna:** Nowy pacjent jest porównywany z historycznymi pacjentami o podobnych objawach i wynikach badań, a diagnoza jest sugerowana na podstawie diagnoz tych podobnych pacjentów.\n",
    "- **Klasyfikacja obrazów (np. k-NN):** Nowy obraz jest klasyfikowany jako należący do klasy, do której należy większość jego \"najbliższych sąsiadów\" w przestrzeni cech.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Miara Podobieństwa (Similarity Measure)\n",
    "\n",
    "Miara podobieństwa jest kluczowym elementem uczenia z przykładu. Definiuje, jak \"blisko\" są ze sobą dwie instancje danych.\n",
    "\n",
    "#### Jak to działa:\n",
    "Miara podobieństwa (lub jej odwrotność – miara odległości) jest funkcją, która przypisuje wartość liczbową parze instancji danych, wskazującą na ich podobieństwo. Im wyższa wartość (dla podobieństwa) lub niższa (dla odległości), tym bardziej podobne są instancje.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Liczba wspólnych słów:** Dla tekstu, prosta miara podobieństwa to liczba wspólnych słów między dwoma dokumentami.\n",
    "- **Odległość euklidesowa:** Dla danych liczbowych, odległość euklidesowa w przestrzeni cech jest często używana jako miara niepodobieństwa (im mniejsza odległość, tym większe podobieństwo).\n",
    "- **Podobieństwo kosinusowe:** Często używane dla wektorów cech (np. w NLP), mierzy kąt między wektorami.\n",
    "- **Odległość Hamminga:** Dla danych binarnych, zlicza liczbę pozycji, na których dwa ciągi bitów się różnią.\n",
    "- **Dopasowanie cech:** Dla obrazów, miara podobieństwa może opierać się na dopasowaniu kluczowych punktów lub deskryptorów cech.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu (Instance-based Learning):\n",
    "1. **Zbieranie danych treningowych** – wszystkie dostępne dane są gromadzone.  \n",
    "2. **Zapamiętywanie danych** – system po prostu przechowuje wszystkie instancje danych treningowych.  \n",
    "3. **Pojawienie się nowej instancji** – system otrzymuje nową instancję, dla której musi dokonać przewidywania.  \n",
    "4. **Obliczanie podobieństwa** – system oblicza podobieństwo (lub odległość) między nową instancją a każdą (lub wybranymi) zapamiętaną instancją treningową.  \n",
    "5. **Uogólnianie** – na podstawie miary podobieństwa, system identyfikuje najbardziej podobne instancje treningowe i wykorzystuje ich etykiety/wartości do przewidywania dla nowej instancji (np. głosowanie większościowe w k-NN).  \n",
    "6. **Brak jawnego etapu \"treningu\"** – w tradycyjnym sensie nie ma etapu, w którym model uczy się parametrów; wiedza jest po prostu przechowywana.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Systemy rekomendacji (k-Nearest Neighbors - k-NN):** Rekomendowanie produktów lub treści na podstawie tego, co lubią \"najbliżsi sąsiedzi\" użytkownika.\n",
    "- **Klasyfikacja obrazów:** Klasyfikacja obrazów poprzez porównanie ich z bazą danych oznaczonych obrazów.\n",
    "- **Diagnostyka medyczna:** Wspomaganie diagnozy poprzez wyszukiwanie podobnych przypadków pacjentów.\n",
    "- **Wykrywanie oszustw:** Identyfikacja transakcji podobnych do znanych oszukańczych transakcji.\n",
    "- **Wyszukiwanie podobieństw:** Wyszukiwanie podobnych dokumentów, obrazów, produktów w dużych bazach danych.\n",
    "- **Systemy eksperckie oparte na przypadkach (Case-Based Reasoning - CBR):** Rozwiązywanie nowych problemów poprzez adaptację rozwiązań z podobnych, historycznych problemów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f785f",
   "metadata": {},
   "source": [
    "## Uczenie z Modelu (Model-based Learning)\n",
    "\n",
    "Uczenie z modelu to paradygmat uczenia maszynowego, w którym system **buduje model matematyczny** na podstawie danych treningowych, a następnie wykorzystuje ten model do **przewidywania** dla nowych przypadków.  \n",
    "W przeciwieństwie do uczenia z przykładu, gdzie system zapamiętuje konkretne przypadki, tutaj system **uogólnia** poprzez stworzenie abstrakcyjnego modelu, który opisuje zależności w danych.\n",
    "\n",
    "#### Dlaczego Model-based Learning?\n",
    "- **Efektywność:** Model może dokonywać przewidywań bez konieczności przechowywania wszystkich danych treningowych.\n",
    "- **Uogólnianie:** Model może przewidywać dla przypadków, które nie są identyczne z żadnym przypadkiem treningowym.\n",
    "- **Interpretowalność:** Modele matematyczne często pozwalają na zrozumienie zależności między zmiennymi.\n",
    "- **Skalowalność:** Może działać na dużych zbiorach danych bez problemów z pamięcią.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Budowanie Modelu (Model Building)\n",
    "\n",
    "Proces budowania modelu polega na znalezieniu **matematycznej funkcji**, która najlepiej opisuje zależność między cechami wejściowymi a wartością docelową.\n",
    "\n",
    "#### Jak to działa:\n",
    "1. **Wybór typu modelu** – decyzja o strukturze matematycznej (np. funkcja liniowa, wielomianowa).\n",
    "2. **Trenowanie modelu** – znalezienie parametrów modelu, które najlepiej dopasowują się do danych treningowych.\n",
    "3. **Walidacja** – sprawdzenie, jak dobrze model radzi sobie z nowymi danymi.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Regresja liniowa:** Model opisuje zależność między ceną domu a jego powierzchnią za pomocą prostej linii: `cena = θ₀ + θ₁ × powierzchnia`\n",
    "- **Regresja wielomianowa:** Model opisuje bardziej złożone zależności za pomocą krzywej wielomianowej.\n",
    "- **Drzewa decyzyjne:** Model opisuje zależności za pomocą hierarchii reguł if-then.\n",
    "- **Sieci neuronowe:** Model opisuje złożone, nieliniowe zależności za pomocą połączonych węzłów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Wybór Modelu (Model Selection)\n",
    "\n",
    "Wybór modelu to proces **decydowania o strukturze matematycznej**, która będzie najlepiej opisywać dane.\n",
    "\n",
    "#### Jak to działa:\n",
    "Na podstawie analizy danych (np. wykresów rozrzutu, korelacji) wybieramy typ funkcji, która prawdopodobnie najlepiej opisze zależność w danych.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Dane liniowe:** Jeśli wykres rozrzutu pokazuje liniową zależność, wybieramy model liniowy.\n",
    "- **Dane wykładnicze:** Jeśli zależność jest wykładnicza, wybieramy model wykładniczy.\n",
    "- **Dane cykliczne:** Jeśli dane mają charakter cykliczny (np. sezonowość), wybieramy model sinusoidalny.\n",
    "- **Złożone dane:** Jeśli zależność jest bardzo złożona, wybieramy model nieliniowy (np. sieć neuronową).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Parametry Modelu (Model Parameters)\n",
    "\n",
    "Parametry modelu to **wartości liczbowe**, które definiują konkretną instancję wybranego typu modelu.\n",
    "\n",
    "#### Jak to działa:\n",
    "Każdy typ modelu ma swoje charakterystyczne parametry. Algorytm treningowy znajduje wartości tych parametrów, które najlepiej dopasowują model do danych treningowych.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Model liniowy:** `y = θ₀ + θ₁x` ma parametry θ₀ (przecięcie z osią Y) i θ₁ (nachylenie linii).\n",
    "- **Model kwadratowy:** `y = θ₀ + θ₁x + θ₂x²` ma parametry θ₀, θ₁, θ₂.\n",
    "- **Sieć neuronowa:** Ma tysiące parametrów (wagi i bias) w różnych warstwach.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Funkcja Kosztu (Cost Function)\n",
    "\n",
    "Funkcja kosztu to **miara jakości** modelu, która określa, jak bardzo przewidywania modelu odbiegają od rzeczywistych wartości w danych treningowych.\n",
    "\n",
    "#### Jak to działa:\n",
    "Funkcja kosztu oblicza różnicę między przewidywaniami modelu a rzeczywistymi wartościami. Celem treningu jest **minimalizacja** tej funkcji kosztu.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Mean Squared Error (MSE):** Średnia kwadratów różnic między przewidywaniami a rzeczywistymi wartościami.\n",
    "- **Mean Absolute Error (MAE):** Średnia wartości bezwzględnych różnic.\n",
    "- **Cross-entropy:** Używana w klasyfikacji, mierzy różnicę między rozkładami prawdopodobieństwa.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Trenowanie Modelu (Model Training)\n",
    "\n",
    "Trenowanie modelu to proces **znajdowania optymalnych parametrów** poprzez minimalizację funkcji kosztu.\n",
    "\n",
    "#### Jak to działa:\n",
    "Algorytm treningowy (np. Gradient Descent) iteracyjnie dostosowuje parametry modelu, aby zmniejszyć różnicę między przewidywaniami a rzeczywistymi wartościami.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Regresja liniowa:** Algorytm znajduje θ₀ i θ₁, które minimalizują MSE.\n",
    "- **Sieci neuronowe:** Algorytm backpropagation dostosowuje wagi w sieci.\n",
    "- **Drzewa decyzyjne:** Algorytm znajduje optymalne podziały węzłów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Przewidywanie (Prediction/Inference)\n",
    "\n",
    "Po wytrenowaniu modelu można go używać do **przewidywania wartości** dla nowych przypadków.\n",
    "\n",
    "#### Jak to działa:\n",
    "Nowe dane wejściowe są podawane do wytrenowanego modelu, który oblicza przewidywaną wartość na podstawie wyuczonych parametrów.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Prognozowanie cen:** Podanie powierzchni nowego domu do modelu, który zwraca przewidywaną cenę.\n",
    "- **Klasyfikacja obrazów:** Podanie nowego obrazu do modelu, który zwraca prawdopodobieństwo przynależności do każdej klasy.\n",
    "- **Rekomendacje:** Podanie preferencji użytkownika do modelu, który zwraca ocenę dla różnych produktów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Przykład: Czy pieniądze czynią ludzi szczęśliwymi?\n",
    "\n",
    "Rozważmy przykład z książki, gdzie chcemy zbadać zależność między PKB per capita a poziomem zadowolenia z życia.\n",
    "\n",
    "#### Dane:\n",
    "| Kraj | PKB per capita (USD) | Zadowolenie z życia |\n",
    "|------|---------------------|-------------------|\n",
    "| Węgry | 12,240 | 4.9 |\n",
    "| Korea | 27,195 | 5.8 |\n",
    "| Francja | 37,675 | 6.5 |\n",
    "| Australia | 50,962 | 7.3 |\n",
    "| USA | 55,805 | 7.2 |\n",
    "\n",
    "#### Analiza:\n",
    "Po wykreśleniu danych widzimy **liniową tendencję** - zadowolenie z życia rośnie wraz ze wzrostem PKB per capita.\n",
    "\n",
    "#### Model:\n",
    "Wybieramy **model liniowy**: `zadowolenie_z_życia = θ₀ + θ₁ × PKB_per_capita`\n",
    "\n",
    "#### Trenowanie:\n",
    "Algorytm regresji liniowej znajduje optymalne parametry:\n",
    "- θ₀ = 4.85\n",
    "- θ₁ = 4.91 × 10⁻⁵\n",
    "\n",
    "#### Przewidywanie:\n",
    "Dla Cypru z PKB per capita = $22,587:\n",
    "`zadowolenie_z_życia = 4.85 + 22,587 × 4.91 × 10⁻⁵ = 5.96`\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Porównanie z Uczeniem z Przykładu:\n",
    "\n",
    "| Cecha | Uczenie z Przykładu | Uczenie z Modelu |\n",
    "|-------|-------------------|------------------|\n",
    "| **Przechowywanie danych** | Wszystkie przykłady treningowe | Tylko parametry modelu |\n",
    "| **Przewidywanie** | Porównanie z zapamiętanymi przykładami | Obliczenie na podstawie modelu |\n",
    "| **Pamięć** | Wymaga dużo pamięci | Wymaga mało pamięci |\n",
    "| **Szybkość przewidywania** | Wolne (porównanie z wszystkimi przykładami) | Szybkie (obliczenie matematyczne) |\n",
    "| **Uogólnianie** | Ograniczone do podobnych przypadków | Może przewidywać dla nowych przypadków |\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu (Model-based Learning):\n",
    "1. **Analiza danych** – zbadanie struktury i zależności w danych treningowych.  \n",
    "2. **Wybór modelu** – decyzja o typie funkcji matematycznej (liniowa, wielomianowa, itp.).  \n",
    "3. **Definicja funkcji kosztu** – określenie miary jakości modelu.  \n",
    "4. **Trenowanie modelu** – znalezienie optymalnych parametrów poprzez minimalizację funkcji kosztu.  \n",
    "5. **Walidacja modelu** – sprawdzenie jakości modelu na danych testowych.  \n",
    "6. **Przewidywanie** – użycie wytrenowanego modelu do przewidywania dla nowych przypadków.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Prognozowanie cen nieruchomości** na podstawie powierzchni, lokalizacji i innych cech.\n",
    "- **Klasyfikacja obrazów** – rozpoznawanie obiektów na zdjęciach.\n",
    "- **Systemy rekomendacji** – przewidywanie ocen użytkowników dla produktów.\n",
    "- **Prognozowanie sprzedaży** – przewidywanie popytu na produkty.\n",
    "- **Diagnostyka medyczna** – przewidywanie prawdopodobieństwa chorób na podstawie objawów.\n",
    "- **Analiza sentymentu** – klasyfikacja emocji w tekście.\n",
    "- **Optymalizacja procesów** – znajdowanie optymalnych parametrów procesów przemysłowych.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykład implementacji uczenia z modelu - Regresja liniowa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Tworzenie przykładowych danych (PKB per capita vs zadowolenie z życia)\n",
    "data = {\n",
    "    'Country': ['Hungary', 'Korea', 'France', 'Australia', 'USA'],\n",
    "    'GDP_per_capita': [12240, 27195, 37675, 50962, 55805],\n",
    "    'Life_satisfaction': [4.9, 5.8, 6.5, 7.3, 7.2]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dane treningowe:\")\n",
    "print(df)\n",
    "\n",
    "# Przygotowanie danych\n",
    "X = df[['GDP_per_capita']].values  # Features (cechy)\n",
    "y = df['Life_satisfaction'].values  # Target (cel)\n",
    "\n",
    "print(f\"\\nX (PKB per capita): {X.flatten()}\")\n",
    "print(f\"y (zadowolenie z życia): {y}\")\n",
    "\n",
    "# Wizualizacja danych\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue')\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Zależność między PKB per capita a zadowoleniem z życia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie nazw krajów do punktów\n",
    "for i, country in enumerate(df['Country']):\n",
    "    plt.annotate(country, (X[i][0], y[i]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenowanie modelu regresji liniowej\n",
    "print(\"=== TRENOWANIE MODELU REGRESJI LINIOWEJ ===\")\n",
    "\n",
    "# Wybór modelu\n",
    "model = LinearRegression()\n",
    "\n",
    "# Trenowanie modelu\n",
    "model.fit(X, y)\n",
    "\n",
    "# Wyświetlenie parametrów modelu\n",
    "print(f\"Parametry modelu:\")\n",
    "print(f\"θ₀ (intercept): {model.intercept_:.2f}\")\n",
    "print(f\"θ₁ (slope): {model.coef_[0]:.6f}\")\n",
    "\n",
    "# Równanie modelu\n",
    "print(f\"\\nRównanie modelu:\")\n",
    "print(f\"zadowolenie_z_życia = {model.intercept_:.2f} + {model.coef_[0]:.6f} × PKB_per_capita\")\n",
    "\n",
    "# Przewidywanie dla Cypru (PKB per capita = $22,587)\n",
    "cyprus_gdp = [[22587]]\n",
    "prediction = model.predict(cyprus_gdp)\n",
    "print(f\"\\nPrzewidywanie dla Cypru (PKB per capita = $22,587):\")\n",
    "print(f\"Przewidywane zadowolenie z życia: {prediction[0]:.2f}\")\n",
    "\n",
    "# Wizualizacja modelu\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Wykres rozrzutu danych\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Dane treningowe')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Dodanie nazw krajów\n",
    "for i, country in enumerate(df['Country']):\n",
    "    plt.annotate(country, (X[i][0], y[i]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# Wykres z modelem\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "\n",
    "# Linia regresji\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(X_line)\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=2, label='Model liniowy')\n",
    "\n",
    "# Przewidywanie dla Cypru\n",
    "plt.scatter(cyprus_gdp, prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr: {prediction[0]:.2f}')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Model regresji liniowej')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ocena jakości modelu\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Przewidywania na danych treningowych\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Metryki\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"\\n=== OCENA JAKOŚCI MODELU ===\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.4f}\")\n",
    "\n",
    "# Porównanie rzeczywistych i przewidywanych wartości\n",
    "print(f\"\\nPorównanie rzeczywistych i przewidywanych wartości:\")\n",
    "comparison_df = df.copy()\n",
    "comparison_df['Predicted'] = y_pred\n",
    "comparison_df['Error'] = comparison_df['Life_satisfaction'] - comparison_df['Predicted']\n",
    "print(comparison_df[['Country', 'Life_satisfaction', 'Predicted', 'Error']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6bc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porównanie z uczeniem z przykładu (k-NN)\n",
    "print(\"=== PORÓWNANIE Z UCZENIEM Z PRZYKŁADU (k-NN) ===\")\n",
    "\n",
    "# Model k-NN (uczenie z przykładu)\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_model.fit(X, y)\n",
    "\n",
    "# Przewidywanie dla Cypru\n",
    "knn_prediction = knn_model.predict(cyprus_gdp)\n",
    "print(f\"Przewidywanie k-NN dla Cypru: {knn_prediction[0]:.2f}\")\n",
    "\n",
    "# Porównanie wyników\n",
    "print(f\"\\n=== PORÓWNANIE WYNIKÓW ===\")\n",
    "print(f\"Regresja liniowa (model-based): {prediction[0]:.2f}\")\n",
    "print(f\"k-NN (instance-based): {knn_prediction[0]:.2f}\")\n",
    "print(f\"Różnica: {abs(prediction[0] - knn_prediction[0]):.2f}\")\n",
    "\n",
    "# Wizualizacja porównania\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Wykres 1: Dane i model liniowy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(X_line)\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=2, label='Model liniowy')\n",
    "plt.scatter(cyprus_gdp, prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr: {prediction[0]:.2f}')\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Model-based Learning\\n(Regresja liniowa)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 2: Dane i k-NN\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "\n",
    "# Znalezienie 3 najbliższych sąsiadów dla Cypru\n",
    "distances, indices = knn_model.kneighbors(cyprus_gdp)\n",
    "nearest_neighbors = X[indices[0]]\n",
    "nearest_values = y[indices[0]]\n",
    "\n",
    "# Podświetlenie najbliższych sąsiadów\n",
    "plt.scatter(nearest_neighbors, nearest_values, s=150, color='green', \n",
    "           marker='s', label='Najbliżsi sąsiedzi', alpha=0.8)\n",
    "\n",
    "plt.scatter(cyprus_gdp, knn_prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr: {knn_prediction[0]:.2f}')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Instance-based Learning\\n(k-NN, k=3)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 3: Porównanie obu metod\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X, y, s=100, alpha=0.7, color='blue', label='Dane treningowe')\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=2, label='Model liniowy')\n",
    "plt.scatter(nearest_neighbors, nearest_values, s=150, color='green', \n",
    "           marker='s', label='Najbliżsi sąsiedzi', alpha=0.8)\n",
    "plt.scatter(cyprus_gdp, prediction, s=150, color='red', marker='*', \n",
    "           label=f'Cypr (lin.): {prediction[0]:.2f}')\n",
    "plt.scatter(cyprus_gdp, knn_prediction, s=150, color='orange', marker='^', \n",
    "           label=f'Cypr (k-NN): {knn_prediction[0]:.2f}')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Porównanie metod')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analiza najbliższych sąsiadów\n",
    "print(f\"\\n=== ANALIZA NAJBLIŻSZYCH SĄSIADÓW (k-NN) ===\")\n",
    "print(\"Najbliżsi sąsiedzi Cypru:\")\n",
    "for i, (gdp, satisfaction, country) in enumerate(zip(nearest_neighbors.flatten(), \n",
    "                                                    nearest_values, \n",
    "                                                    df.iloc[indices[0]]['Country'])):\n",
    "    print(f\"{i+1}. {country}: PKB = ${gdp:,.0f}, Zadowolenie = {satisfaction}\")\n",
    "\n",
    "print(f\"\\nŚrednia zadowolenia z życia najbliższych sąsiadów: {nearest_values.mean():.2f}\")\n",
    "print(f\"Przewidywanie k-NN: {knn_prediction[0]:.2f}\")\n",
    "\n",
    "# Porównanie charakterystyk metod\n",
    "print(f\"\\n=== CHARAKTERYSTYKI METOD ===\")\n",
    "print(\"Model-based Learning (Regresja liniowa):\")\n",
    "print(\"- Buduje matematyczny model zależności\")\n",
    "print(\"- Szybkie przewidywania (obliczenie matematyczne)\")\n",
    "print(\"- Może przewidywać dla wartości poza zakresem danych treningowych\")\n",
    "print(\"- Interpretowalny (można zrozumieć zależność)\")\n",
    "\n",
    "print(\"\\nInstance-based Learning (k-NN):\")\n",
    "print(\"- Porównuje z zapamiętanymi przykładami\")\n",
    "print(\"- Wolniejsze przewidywania (obliczanie odległości)\")\n",
    "print(\"- Ograniczony do zakresu danych treningowych\")\n",
    "print(\"- Mniej interpretowalny\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodatkowe przykłady różnych typów modeli\n",
    "print(\"=== RÓŻNE TYPY MODELI W MODEL-BASED LEARNING ===\")\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Generowanie większego zbioru danych dla lepszej demonstracji\n",
    "np.random.seed(42)\n",
    "X_extended = np.linspace(10000, 60000, 50).reshape(-1, 1)\n",
    "y_extended = 4.5 + 0.00005 * X_extended.flatten() + np.random.normal(0, 0.2, 50)\n",
    "\n",
    "# Przygotowanie danych\n",
    "X_train = X_extended[:40]\n",
    "y_train = y_extended[:40]\n",
    "X_test = X_extended[40:]\n",
    "y_test = y_extended[40:]\n",
    "\n",
    "print(f\"Dane treningowe: {len(X_train)} próbek\")\n",
    "print(f\"Dane testowe: {len(X_test)} próbek\")\n",
    "\n",
    "# 1. Regresja liniowa\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "linear_pred = linear_model.predict(X_test)\n",
    "\n",
    "# 2. Regresja wielomianowa (stopień 2)\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "poly_pred = poly_model.predict(X_test_poly)\n",
    "\n",
    "# 3. Drzewo decyzyjne\n",
    "tree_model = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# 4. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Wizualizacja wszystkich modeli\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Wykres 1: Dane i modele\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(X_train, y_train, alpha=0.6, color='blue', label='Dane treningowe')\n",
    "plt.scatter(X_test, y_test, alpha=0.6, color='red', label='Dane testowe')\n",
    "\n",
    "# Linie dla różnych modeli\n",
    "X_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "plt.plot(X_line, linear_model.predict(X_line), 'g-', linewidth=2, label='Regresja liniowa')\n",
    "\n",
    "X_line_poly = poly_features.transform(X_line)\n",
    "plt.plot(X_line, poly_model.predict(X_line_poly), 'm-', linewidth=2, label='Regresja wielomianowa')\n",
    "\n",
    "plt.plot(X_line, tree_model.predict(X_line), 'c-', linewidth=2, label='Drzewo decyzyjne')\n",
    "plt.plot(X_line, rf_model.predict(X_line), 'y-', linewidth=2, label='Random Forest')\n",
    "\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Zadowolenie z życia')\n",
    "plt.title('Porównanie różnych modeli')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 2: Porównanie błędów\n",
    "models = ['Regresja liniowa', 'Regresja wielomianowa', 'Drzewo decyzyjne', 'Random Forest']\n",
    "predictions = [linear_pred, poly_pred, tree_pred, rf_pred]\n",
    "mse_scores = [mean_squared_error(y_test, pred) for pred in predictions]\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "bars = plt.bar(models, mse_scores, color=['green', 'magenta', 'cyan', 'yellow'])\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Porównanie błędów (MSE)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, score in zip(bars, mse_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 3: Rzeczywiste vs przewidywane wartości\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(y_test, linear_pred, alpha=0.6, label='Regresja liniowa')\n",
    "plt.scatter(y_test, poly_pred, alpha=0.6, label='Regresja wielomianowa')\n",
    "plt.scatter(y_test, tree_pred, alpha=0.6, label='Drzewo decyzyjne')\n",
    "plt.scatter(y_test, rf_pred, alpha=0.6, label='Random Forest')\n",
    "\n",
    "# Linia idealna (rzeczywiste = przewidywane)\n",
    "min_val = min(y_test.min(), min(pred.min() for pred in predictions))\n",
    "max_val = max(y_test.max(), max(pred.max() for pred in predictions))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, label='Idealna linia')\n",
    "\n",
    "plt.xlabel('Rzeczywiste wartości')\n",
    "plt.ylabel('Przewidywane wartości')\n",
    "plt.title('Rzeczywiste vs Przewidywane')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Wykres 4: Reszty (błędy)\n",
    "plt.subplot(2, 2, 4)\n",
    "residuals = [y_test - pred for pred in predictions]\n",
    "for i, (residual, model) in enumerate(zip(residuals, models)):\n",
    "    plt.scatter(X_test, residual, alpha=0.6, label=model)\n",
    "\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.8)\n",
    "plt.xlabel('PKB per capita (USD)')\n",
    "plt.ylabel('Reszty (błędy)')\n",
    "plt.title('Analiza reszt')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Podsumowanie wyników\n",
    "print(f\"\\n=== PODSUMOWANIE WYNIKÓW ===\")\n",
    "for model, pred, mse in zip(models, predictions, mse_scores):\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"  MSE: {mse:.4f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "    print(f\"  RMSE: {np.sqrt(mse):.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"=== WNIOSKI ===\")\n",
    "print(\"1. Różne modele mają różne charakterystyki:\")\n",
    "print(\"   - Regresja liniowa: prosta, interpretowalna\")\n",
    "print(\"   - Regresja wielomianowa: może modelować krzywe\")\n",
    "print(\"   - Drzewo decyzyjne: może modelować złożone granice\")\n",
    "print(\"   - Random Forest: łączy wiele drzew, często lepsza wydajność\")\n",
    "print()\n",
    "print(\"2. Wybór modelu zależy od:\")\n",
    "print(\"   - Charakteru danych (liniowe vs nieliniowe)\")\n",
    "print(\"   - Interpretowalności vs wydajności\")\n",
    "print(\"   - Wielkości zbioru danych\")\n",
    "print(\"   - Złożoności problemu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00130c5",
   "metadata": {},
   "source": [
    "# Regresja k-Najbliższych Sąsiadów (k-NN) ze Wzorami Matematycznymi\n",
    "\n",
    "### Wprowadzenie do Regresji k-Najbliższych Sąsiadów\n",
    "\n",
    "Regresja k-najbliższych sąsiadów (k-NN) to prosty i intuicyjny algorytm uczenia maszynowego z nadzorem, który można stosować zarówno do zadań klasyfikacyjnych, jak i regresyjnych. W kontekście regresji, celem jest przewidywanie ciągłej wartości wyjściowej (np. ceny domu, temperatury). Jest to metoda **nieparametryczna**, co oznacza, że nie zakłada żadnej konkretnej formy funkcyjnej dla danych, jak na przykład liniowa zależność w regresji liniowej. K-NN jest również algorytmem \"uczenia się na podstawie instancji\" (instance-based learning), ponieważ nie buduje modelu w fazie trenowania, a zamiast tego przechowuje cały zbiór treningowy i wykonuje obliczenia dopiero w momencie predykcji.\n",
    "\n",
    "Główna idea opiera się na założeniu, że podobne punkty danych istnieją w bliskiej odległości od siebie. Przewidywana wartość dla nowego, nieznanego punktu danych jest obliczana na podstawie wartości jego \"k\" najbliższych sąsiadów ze zbioru treningowego.\n",
    "\n",
    "---\n",
    "\n",
    "### Jak Działa Algorytm Regresji k-NN?\n",
    "\n",
    "Proces predykcji przy użyciu regresji k-NN można podzielić na kilka kluczowych kroków:\n",
    "\n",
    "#### Krok 1: Wybór liczby sąsiadów (k)\n",
    "\n",
    "Pierwszym krokiem jest wybór hiperparametru `k`, który określa, ilu najbliższych sąsiadów zostanie uwzględnionych podczas dokonywania predykcji. Wybór `k` ma kluczowe znaczenie dla działania modelu:\n",
    "*   **Małe `k`** (np. `k=1`): Model jest bardzo elastyczny i podatny na szum w danych, co może prowadzić do niestabilnych predykcji.\n",
    "*   **Duże `k`**: Predykcje stają się bardziej stabilne i wygładzone, ale model może tracić zdolność do wychwytywania lokalnych struktur w danych.\n",
    "\n",
    "Optymalną wartość `k` często wybiera się za pomocą walidacji krzyżowej. Powszechną heurystyką jest wybór `k` w przybliżeniu równego pierwiastkowi kwadratowemu z liczby punktów danych w zbiorze (`k ≈ √n`).\n",
    "\n",
    "#### Krok 2: Obliczenie odległości\n",
    "\n",
    "Aby znaleźć najbliższych sąsiadów dla nowego punktu danych, musimy obliczyć odległość między nim a wszystkimi punktami w zbiorze treningowym. Najczęściej używaną metryką odległości dla zmiennych ciągłych jest **odległość Euklidesowa**.\n",
    "\n",
    "**Wzór na odległość Euklidesową:**\n",
    "\n",
    "Dla dwóch punktów, **p** i **q**, w *n*-wymiarowej przestrzeni cech, gdzie **p** = $(p_1, p_2, ..., p_n)$ i **q** = $(q_1, q_2, ..., q_n)$, odległość Euklidesowa $d(p, q)$ jest definiowana jako:\n",
    "\n",
    "$$\n",
    "d(p, q) = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + ... + (q_n - p_n)^2} = \\sqrt{\\sum_{i=1}^{n} (q_i - p_i)^2}\n",
    "$$\n",
    "\n",
    "Inne popularne metryki odległości to:\n",
    "*   **Odległość Manhattan:** suma bezwzględnych różnic współrzędnych.\n",
    "*   **Odległość Minkowskiego:** uogólnienie odległości Euklidesowej i Manhattan.\n",
    "\n",
    "> **Ważna uwaga:** Algorytm k-NN jest wrażliwy na skalę cech. Jeśli cechy mają różne zakresy wartości (np. wiek w latach i dochód w tysiącach), cecha o większym zakresie będzie dominować w obliczeniach odległości. Dlatego kluczowe jest przeskalowanie danych (np. przez normalizację lub standaryzację) przed zastosowaniem algorytmu.\n",
    "\n",
    "#### Krok 3: Znalezienie k-najbliższych sąsiadów\n",
    "\n",
    "Po obliczeniu odległości do wszystkich punktów treningowych, są one sortowane w porządku rosnącym. Następnie wybierane jest `k` punktów o najmniejszych odległościach od nowego punktu.\n",
    "\n",
    "#### Krok 4: Dokonanie predykcji\n",
    "\n",
    "W standardowej wersji regresji k-NN, przewidywana wartość dla nowego punktu jest prostą **średnią arytmetyczną** wartości docelowych jego `k` najbliższych sąsiadów.\n",
    "\n",
    "**Wzór na predykcję w standardowej regresji k-NN:**\n",
    "\n",
    "Jeśli $y_1, y_2, ..., y_k$ to wartości docelowe `k` najbliższych sąsiadów, to przewidywana wartość $\\hat{y}$ dla nowego punktu jest obliczana jako:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{k} \\sum_{i=1}^{k} y_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Wariant: Ważona Regresja k-NN\n",
    "\n",
    "Standardowe podejście traktuje wszystkich `k` sąsiadów jednakowo. Intuicyjnym ulepszeniem jest przypisanie większej wagi sąsiadom, którzy są bliżej nowego punktu, a mniejszej tym, którzy są dalej. Nazywa się to ważoną regresją k-NN.\n",
    "\n",
    "W tym wariancie, predykcja jest **średnią ważoną**, gdzie wagi są zazwyczaj odwrotnością odległości do sąsiada.\n",
    "\n",
    "**Wzór na wagę:**\n",
    "\n",
    "Waga $w_i$ dla *i*-tego sąsiada może być zdefiniowana jako:\n",
    "\n",
    "$$\n",
    "w_i = \\frac{1}{d_i}\n",
    "$$\n",
    "\n",
    "gdzie $d_i$ to odległość do *i*-tego sąsiada. Należy uważać na przypadek, gdy odległość wynosi zero; aby uniknąć dzielenia przez zero, można dodać małą stałą $\\epsilon$ do mianownika.\n",
    "\n",
    "**Wzór na predykcję w ważonej regresji k-NN:**\n",
    "\n",
    "Przewidywana wartość $\\hat{y}$ jest obliczana jako:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{\\sum_{i=1}^{k} (w_i \\cdot y_i)}{\\sum_{i=1}^{k} w_i}\n",
    "$$\n",
    "\n",
    "Dzięki temu podejściu, wpływ bliższych sąsiadów na ostateczny wynik jest silniejszy, co często prowadzi do dokładniejszych predykcji.\n",
    "\n",
    "---\n",
    "\n",
    "### Podsumowanie\n",
    "\n",
    "| Aspekt | Opis |\n",
    "| :--- | :--- |\n",
    "| **Typ algorytmu** | Uczenie maszynowe z nadzorem, nieparametryczne, oparte na instancjach. |\n",
    "| **Zadanie** | Regresja (przewidywanie wartości ciągłych). |\n",
    "| **Krok 1: Wybór k** | Określenie liczby sąsiadów do uwzględnienia. |\n",
    "| **Krok 2: Metryka odległości** | Najczęściej odległość Euklidesowa do mierzenia podobieństwa. |\n",
    "| **Krok 3: Znalezienie sąsiadów** | Identyfikacja `k` punktów treningowych o najmniejszej odległości. |\n",
    "| **Krok 4: Predykcja (standardowa)** | Średnia arytmetyczna wartości docelowych `k` sąsiadów. |\n",
    "| **Krok 4: Predykcja (ważona)** | Średnia ważona wartości docelowych, gdzie wagi zależą od odległości. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913009e6",
   "metadata": {},
   "source": [
    "# Główne Wyzwania w Uczeniu Maszynowym: Złe Dane i Złe Algorytmy\n",
    "\n",
    "Poniższa notatka podsumowuje kluczowe problemy, na jakie można natrafić podczas budowania systemów uczenia maszynowego, dzieląc je na dwie główne kategorie: problemy z danymi i problemy z algorytmami.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Złe Dane (Bad Data)\n",
    "\n",
    "Jakość i reprezentatywność danych treningowych jest absolutnie kluczowa. Zasada \"śmieci na wejściu, śmieci na wyjściu\" (garbage in, garbage out) jest tu fundamentalna.\n",
    "\n",
    "### A. Błąd Próbkowania (Sampling Bias)\n",
    "\n",
    "> **W skrócie:** Dane treningowe nie są reprezentatywne dla przypadków, które model napotka w rzeczywistości.\n",
    "\n",
    "Model uczy się na podstawie danych, które nie odzwierciedlają prawdziwego rozkładu populacji.\n",
    "\n",
    "*   **Klasyczny przykład: Wybory w USA w 1936 r.**\n",
    "    *   **Problem:** Sondażownia *Literary Digest* przewidziała wygraną Landona, podczas gdy z dużą przewagą wygrał Roosevelt.\n",
    "    *   **Przyczyny błędu:**\n",
    "        1.  **Niereprezentatywne źródła danych:** Adresy do wysyłki ankiet pochodziły z książek telefonicznych i list subskrybentów magazynów. W tamtych czasach posiadanie telefonu czy prenumeraty było domeną ludzi zamożniejszych, którzy częściej głosowali na Republikanów (Landon).\n",
    "        2.  **Błąd braku odpowiedzi (Nonresponse bias):** Mniej niż 25% osób odesłało ankietę. Odpowiedziały głównie osoby silnie zaangażowane politycznie, co również zaburzyło reprezentatywność próby.\n",
    "\n",
    "*   **Współczesny przykład: Wideo z muzyką funk**\n",
    "    *   Jeśli zbiór treningowy zbudujesz, pobierając wyniki wyszukiwania \"funk music\" z YouTube, wyniki będą przechylone w stronę najpopularniejszych artystów i mogą nie reprezentować całego gatunku.\n",
    "\n",
    "### B. Dane Niskiej Jakości (Poor-Quality Data)\n",
    "\n",
    "> **W skrócie:** Dane są pełne błędów, wartości odstających (outlierów) i szumu.\n",
    "\n",
    "Nawet najlepszy algorytm będzie miał problemy, jeśli dane będą \"brudne\". Duża część pracy Data Scientista to właśnie czyszczenie danych.\n",
    "\n",
    "*   **Co robić?**\n",
    "    *   **Wartości odstające (outliers):** Jeśli niektóre instancje są oczywistymi anomaliami, można je usunąć lub spróbować naprawić ręcznie.\n",
    "    *   **Brakujące wartości:** Jeśli w niektórych próbkach brakuje cech (np. 5% klientów nie podało wieku), można:\n",
    "        *   Zignorować całą cechę (atrybut).\n",
    "        *   Zignorować instancje z brakami.\n",
    "        *   Uzupełnić braki (np. medianą lub średnią).\n",
    "        *   Wytrenować jeden model z tą cechą (na danych, które ją mają) i jeden bez niej.\n",
    "\n",
    "### C. Nieistotne Cechy (Irrelevant Features)\n",
    "\n",
    "> **W skrócie:** Zbiór danych zawiera zbyt wiele cech, które nie mają znaczenia dla problemu, a za mało tych, które mają.\n",
    "\n",
    "System będzie w stanie się uczyć tylko, jeśli dane treningowe zawierają wystarczająco dużo **istotnych** cech.\n",
    "\n",
    "*   **Rozwiązanie: Inżynieria Cech (Feature Engineering)**\n",
    "    Jest to proces tworzenia dobrego zestawu cech do trenowania. Składa się z:\n",
    "    1.  **Selekcji cech (Feature Selection):** Wybór najbardziej użytecznych cech spośród już istniejących.\n",
    "    2.  **Ekstrakcji cech (Feature Extraction):** Łączenie istniejących cech w celu stworzenia nowej, bardziej użytecznej (np. za pomocą algorytmów redukcji wymiarowości).\n",
    "    3.  **Tworzenia nowych cech:** Poprzez zbieranie nowych danych.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Złe Algorytmy (Bad Algorithms)\n",
    "\n",
    "Nawet przy idealnych danych, niewłaściwy dobór lub konfiguracja modelu może prowadzić do słabych wyników.\n",
    "\n",
    "### A. Przeuczenie (Overfitting)\n",
    "\n",
    "> **W skrócie:** Model działa świetnie na danych treningowych, ale słabo generalizuje i nie radzi sobie z nowymi, nieznanymi danymi.\n",
    "\n",
    "Model jest zbyt skomplikowany w stosunku do ilości i zaszumienia danych. Uczy się \"na pamięć\" danych treningowych, włączając w to przypadkowy szum, zamiast uczyć się ogólnych wzorców.\n",
    "\n",
    "*   **Intuicyjny przykład:** Taksówkarz oszukał Cię w obcym kraju. Dochodzisz do wniosku, że *wszyscy* taksówkarze w tym kraju to złodzieje. To jest właśnie nadmierna generalizacja na podstawie małej próbki.\n",
    "\n",
    "*   **Przykład techniczny:** Model uczy się, że kraje z literą \"w\" w nazwie mają wskaźnik satysfakcji z życia > 7 (na podstawie danych treningowych). Ten wzorzec jest przypadkowy i nie sprawdzi się dla innych krajów.\n",
    "\n",
    "*   **Rozwiązania:**\n",
    "    1.  **Uprość model:**\n",
    "        *   Wybierz model z mniejszą liczbą parametrów (np. model liniowy zamiast wielomianu wysokiego stopnia).\n",
    "        *   Zredukuj liczbę atrybutów w danych.\n",
    "        *   Nałóż ograniczenia na model (patrz: Regularyzacja).\n",
    "    2.  **Zbierz więcej danych treningowych.**\n",
    "    3.  **Zredukuj szum w danych** (napraw błędy, usuń outliery).\n",
    "\n",
    "*   **Regularyzacja (Regularization):**\n",
    "    *   To technika **nakładania ograniczeń na model, aby go uprościć** i zmniejszyć ryzyko przeuczenia.\n",
    "    *   Steruje się nią za pomocą **hiperparametru**.\n",
    "    *   Przykład: W modelu liniowym można \"zmusić\" algorytm, by utrzymywał nachylenie prostej bliskie zeru. Model nie dopasuje się idealnie do danych treningowych, ale będzie lepiej generalizował.\n",
    "\n",
    "### B. Niedouczenie (Underfitting)\n",
    "\n",
    "> **W skrócie:** Model jest zbyt prosty, aby nauczyć się podstawowej struktury danych. Działa słabo nawet na danych treningowych.\n",
    "\n",
    "Jest to przeciwieństwo przeuczenia. Rzeczywistość jest bardziej złożona niż możliwości modelu.\n",
    "\n",
    "*   **Przykład:** Próba opisania skomplikowanego, nieliniowego zjawiska za pomocą prostej regresji liniowej.\n",
    "\n",
    "*   **Rozwiązania:**\n",
    "    1.  **Wybierz potężniejszy model** (z większą liczbą parametrów).\n",
    "    2.  **Dostarcz lepsze cechy** (inżynieria cech).\n",
    "    3.  **Zmniejsz ograniczenia nałożone na model** (np. zredukuj hiperparametr regularyzacji)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c1675",
   "metadata": {},
   "source": [
    "## Zbiór ucząco rozwojowy \"train-dev\"\n",
    "\n",
    "Zbiór \"train-dev\" jest używany, gdy istnieje ryzyko niedopasowania między danymi treningowymi a danymi używanymi w zbiorach walidacyjnym i testowym (które zawsze powinny być jak najbardziej zbliżone do danych używanych po wdrożeniu modelu do produkcji). Zbiór \"train-dev\" to część zbioru treningowego, która jest odłożona (model nie jest na niej trenowany). Model jest trenowany na pozostałej części zbioru treningowego i oceniany zarówno na zbiorze \"train-dev\", jak i na zbiorze walidacyjnym. Jeśli model dobrze radzi sobie na zbiorze treningowym, ale nie na zbiorze \"train-dev\", to model prawdopodobnie nadmiernie dopasowuje się do zbioru treningowego. Jeśli dobrze radzi sobie zarówno na zbiorze treningowym, jak i na zbiorze \"train-dev\", ale nie na zbiorze walidacyjnym, to prawdopodobnie istnieje znaczne niedopasowanie danych między danymi treningowymi a danymi walidacyjnymi i testowymi, i należy spróbować ulepszyć dane treningowe, aby bardziej przypominały dane walidacyjne i testowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdb2d3",
   "metadata": {},
   "source": [
    "## Parametry a hiperparametry\n",
    "\n",
    "🔹 Parametry\n",
    "Uczy się ich sam model podczas treningu.\n",
    "Są wewnętrzne — model dopasowuje je do danych.\n",
    "Przykłady:\n",
    "w regresji liniowej → współczynniki w i b,\n",
    "w sieci neuronowej → wagi i biasy neuronów.\n",
    "📘 My nie ustawiamy parametrów — model sam je „uczy”.\n",
    "🔹 Hiperparametry\n",
    "Ustawiamy je my (człowiek lub algorytm optymalizacji) przed treningiem.\n",
    "Sterują tym, jak model się uczy.\n",
    "Przykłady:\n",
    "szybkość uczenia (learning rate),\n",
    "liczba warstw lub neuronów,\n",
    "liczba epok,\n",
    "rozmiar batcha,\n",
    "k w k-NN,\n",
    "C w SVM.\n",
    "📘 Hiperparametry → wpływają na proces uczenia, ale nie są przez model uczone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f36d4",
   "metadata": {},
   "source": [
    "## 📘 Zbiory danych w uczeniu maszynowym\n",
    "\n",
    "#### 🔹 Zbiór uczący (treningowy)\n",
    "- Używany do **nauki modelu** — model dopasowuje do niego swoje **parametry**.  \n",
    "- Największa część danych (zwykle ok. 70–80%).  \n",
    "\n",
    "#### 🔹 Zbiór walidacyjny\n",
    "- Używany do **dobierania hiperparametrów** i **oceny jakości** modelu podczas treningu.  \n",
    "- Pomaga wykryć **przeuczenie (overfitting)**.  \n",
    "- Dane z walidacji **nie są używane do uczenia**.  \n",
    "\n",
    "#### 🔹 Zbiór testowy\n",
    "- Używany **na końcu** do **sprawdzenia**, jak dobrze model generalizuje na **nowych danych**.  \n",
    "- Dane testowe **nie mogą być widziane przez model wcześniej**.  \n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Błąd generalizacji\n",
    "- To **różnica między błędem na danych uczących a błędem na danych testowych**.  \n",
    "- Pokazuje, **jak dobrze model radzi sobie z nowymi, nieznanymi danymi**.  \n",
    "- Mały błąd generalizacji → model dobrze **uogólnia**.  \n",
    "- Duży błąd generalizacji → model **przeuczony (overfitting)** lub **niedouczenie (underfitting)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70d23c",
   "metadata": {},
   "source": [
    "## odp. na pytania z 1 rozdzialu\n",
    "\n",
    "Jasne, oto tekst z dodaną numeracją do każdego akapitu:\n",
    "\n",
    "1.  Uczenie maszynowe polega na budowaniu systemów, które potrafią uczyć się na podstawie danych. Uczenie się oznacza stawanie się lepszym w wykonywaniu jakiegoś zadania, przy uwzględnieniu określonej miary wydajności.\n",
    "\n",
    "2.  Uczenie maszynowe jest doskonałe do rozwiązywania złożonych problemów, dla których nie mamy rozwiązania algorytmicznego, do zastępowania długich list ręcznie dostrajanych reguł, do budowania systemów, które dostosowują się do zmieniającego się otoczenia, a wreszcie do pomagania ludziom w uczeniu się (np. eksploracja danych).\n",
    "\n",
    "3.  Oznaczony zbiór treningowy to zbiór treningowy, który zawiera pożądane rozwiązanie (czyli etykietę) dla każdego przypadku.\n",
    "\n",
    "4.  Dwa najczęstsze zadania nadzorowane to regresja i klasyfikacja.\n",
    "\n",
    "5.  Typowe zadania nienadzorowane obejmują klasteryzację, wizualizację, redukcję wymiarowości i uczenie się reguł asocjacyjnych.\n",
    "\n",
    "6.  Uczenie przez wzmacnianie (Reinforcement Learning) prawdopodobnie sprawdzi się najlepiej, jeśli chcemy, aby robot nauczył się chodzić po różnych nieznanych terenach, ponieważ jest to typowy rodzaj problemu, którym zajmuje się uczenie przez wzmacnianie. Możliwe byłoby wyrażenie tego problemu jako problemu uczenia nadzorowanego lub częściowo nadzorowanego, ale byłoby to mniej naturalne.\n",
    "\n",
    "7.  Jeśli nie wiesz, jak zdefiniować grupy, możesz użyć algorytmu klastrowania (uczenie nienadzorowane) do posegmentowania klientów na klastry podobnych klientów. Jeśli jednak wiesz, jakie grupy chciałbyś mieć, możesz dostarczyć wiele przykładów każdej grupy do algorytmu klasyfikacyjnego (uczenie nadzorowane), a on sklasyfikuje wszystkich twoich klientów do tych grup.\n",
    "\n",
    "8.  Wykrywanie spamu to typowy problem uczenia nadzorowanego: algorytm otrzymuje wiele e-maili wraz z ich etykietami (spam lub nie spam).\n",
    "\n",
    "9.  System uczący się online może uczyć się w sposób przyrostowy, w przeciwieństwie do systemu uczącego się wsadowo. Dzięki temu jest w stanie szybko dostosowywać się zarówno do zmieniających się danych, jak i systemów autonomicznych, oraz trenować na bardzo dużych ilościach danych.\n",
    "\n",
    "10. Algorytmy \"out-of-core\" potrafią obsługiwać ogromne ilości danych, które nie mieszczą się w pamięci głównej komputera. Algorytm uczący się \"out-of-core\" dzieli dane na mini-partie i wykorzystuje techniki uczenia online do nauki na podstawie tych mini-partii.\n",
    "\n",
    "11. System uczący się oparty na instancjach (instance-based learning) uczy się danych treningowych na pamięć; następnie, gdy otrzyma nową instancję, używa miary podobieństwa, aby znaleźć najbardziej podobne nauczone instancje i wykorzystuje je do tworzenia prognoz.\n",
    "\n",
    "12. \n",
    "🔹 Parametry\n",
    "Uczy się ich sam model podczas treningu.\n",
    "Są wewnętrzne — model dopasowuje je do danych.\n",
    "Przykłady:\n",
    "w regresji liniowej → współczynniki w i b,\n",
    "w sieci neuronowej → wagi i biasy neuronów.\n",
    "📘 My nie ustawiamy parametrów — model sam je „uczy”.\n",
    "🔹 Hiperparametry\n",
    "Ustawiamy je my (człowiek lub algorytm optymalizacji) przed treningiem.\n",
    "Sterują tym, jak model się uczy.\n",
    "Przykłady:\n",
    "szybkość uczenia (learning rate),\n",
    "liczba warstw lub neuronów,\n",
    "liczba epok,\n",
    "rozmiar batcha,\n",
    "k w k-NN,\n",
    "C w SVM.\n",
    "📘 Hiperparametry → wpływają na proces uczenia, ale nie są przez model uczone.\n",
    "\n",
    "13. Algorytmy uczenia oparte na modelu (model-based learning) poszukują optymalnej wartości dla parametrów modelu, tak aby model dobrze generalizował na nowe instancje. Zazwyczaj trenujemy takie systemy poprzez minimalizację funkcji kosztu, która mierzy, jak słabo system radzi sobie z przewidywaniami na danych treningowych, plus kara za złożoność modelu, jeśli model jest regularyzowany. Aby dokonać predykcji, podajemy cechy nowej instancji do funkcji predykcyjnej modelu, używając wartości parametrów znalezionych przez algorytm uczący.\n",
    "\n",
    "14. Niektóre z głównych wyzwań w uczeniu maszynowym to brak danych, niska jakość danych, niereprezentatywne dane, nieinformacyjne cechy, nadmiernie proste modele, które niedostatecznie dopasowują się do danych treningowych (underfitting), oraz nadmiernie złożone modele, które nadmiernie dopasowują się do danych (overfitting).\n",
    "\n",
    "15. Jeśli model doskonale radzi sobie na danych treningowych, ale słabo generalizuje na nowe instancje, model prawdopodobnie nadmiernie dopasowuje się do danych treningowych (lub mieliśmy wyjątkowe szczęście na danych treningowych). Możliwe rozwiązania problemu nadmiernego dopasowania to pozyskanie większej ilości danych, uproszczenie modelu (wybór prostszego algorytmu, zmniejszenie liczby parametrów lub używanych cech, lub regularyzacja modelu) lub zmniejszenie szumu w danych treningowych.\n",
    "\n",
    "16. Zbiór testowy jest używany do oszacowania błędu generalizacji, jaki model popełni na nowych instancjach, zanim model zostanie wdrożony do produkcji.\n",
    "\n",
    "17. Zbiór walidacyjny jest używany do porównywania modeli. Umożliwia on wybór najlepszego modelu i dostrojenie hiperparametrów.\n",
    "\n",
    "18. Zbiór \"train-dev\" jest używany, gdy istnieje ryzyko niedopasowania między danymi treningowymi a danymi używanymi w zbiorach walidacyjnym i testowym (które zawsze powinny być jak najbardziej zbliżone do danych używanych po wdrożeniu modelu do produkcji). Zbiór \"train-dev\" to część zbioru treningowego, która jest odłożona (model nie jest na niej trenowany). Model jest trenowany na pozostałej części zbioru treningowego i oceniany zarówno na zbiorze \"train-dev\", jak i na zbiorze walidacyjnym. Jeśli model dobrze radzi sobie na zbiorze treningowym, ale nie na zbiorze \"train-dev\", to model prawdopodobnie nadmiernie dopasowuje się do zbioru treningowego. Jeśli dobrze radzi sobie zarówno na zbiorze treningowym, jak i na zbiorze \"train-dev\", ale nie na zbiorze walidacyjnym, to prawdopodobnie istnieje znaczne niedopasowanie danych między danymi treningowymi a danymi walidacyjnymi i testowymi, i należy spróbować ulepszyć dane treningowe, aby bardziej przypominały dane walidacyjne i testowe.\n",
    "\n",
    "19. Jeśli dostrajasz hiperparametry przy użyciu zbioru testowego, ryzykujesz nadmierne dopasowanie do zbioru testowego, a mierzony błąd generalizacji będzie optymistyczny (możesz wdrożyć model, który działa gorzej niż się spodziewasz)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5964b7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
