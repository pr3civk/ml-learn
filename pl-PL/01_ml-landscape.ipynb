{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a86b868",
   "metadata": {},
   "source": [
    "# Kluczowe pojęcia i krótkie opisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1efa3c",
   "metadata": {},
   "source": [
    "- **Machine Learning** – dziedzina nauki dająca komputerom możliwość uczenia się bez konieczności ich jawnego programowania.  \n",
    "\n",
    "- **Training Set (dane uczące)** – przykładowe dane używane do trenowania modelu, składające się z próbek (sample).  \n",
    "\n",
    "- **Accuracy** – konkretna miara wydajności modelu, często stosowana w zadaniach klasyfikacyjnych.  \n",
    "\n",
    "- **Data Mining** – analizowanie zbioru danych w celu poszukiwania ukrytych wzorców.  \n",
    "\n",
    "- **NLP (Natural Language Processing)** – przetwarzanie języka naturalnego; dziedzina AI zajmująca się analizą, rozumieniem i generowaniem ludzkiego języka przez komputery.  \n",
    "\n",
    "- **RNN (Recurrent Neural Network)** – rekurencyjna sieć neuronowa; sieć przetwarzająca dane sekwencyjne (np. tekst, dźwięk) poprzez zapamiętywanie wcześniejszych stanów.  \n",
    "\n",
    "- **CNN (Convolutional Neural Network)** – konwolucyjna sieć neuronowa; model szczególnie skuteczny w rozpoznawaniu obrazów dzięki operacjom splotu.  \n",
    "\n",
    "- **NLU (Natural Language Understanding)** – rozumienie języka naturalnego; poddziedzina NLP skupiająca się na interpretacji znaczenia wypowiedzi.  \n",
    "\n",
    "- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** – algorytm grupowania na podstawie gęstości punktów; wykrywa skupiska danych i odrzuca szum.  \n",
    "\n",
    "- **MNIST (Modified National Institute of Standards and Technology dataset)** – popularny zbiór danych zawierający ręcznie pisane cyfry, używany do trenowania i testowania modeli ML.  \n",
    "\n",
    "- **Transformator (Transformer)** – architektura sieci neuronowych oparta na mechanizmie uwagi (attention); podstawa modeli językowych, takich jak GPT czy BERT.  \n",
    "\n",
    "- **Redukcja wymiarowości (Dimensionality Reduction)** – proces upraszczania danych przez zmniejszenie liczby cech przy zachowaniu najważniejszych informacji.  \n",
    "\n",
    "- **Splot (Convolution)** – operacja matematyczna w CNN, która wyłapuje lokalne wzorce w danych (np. krawędzie na obrazie).  \n",
    "\n",
    "- **Regresja liniowa (Linear Regression)** – metoda przewidywania wartości ciągłych poprzez dopasowanie prostej linii do danych.  \n",
    "\n",
    "- **Regresja wielomianowa (Polynomial Regression)** – rozszerzenie regresji liniowej, w której zależność między zmiennymi jest opisana wielomianem.  \n",
    "\n",
    "- **Random Forest Regression (Regresja lasu losowego)** – metoda oparta na wielu drzewach decyzyjnych, uśredniająca ich wyniki w celu zwiększenia dokładności.  \n",
    "\n",
    "- **Decision Tree** to model uczenia maszynowego używany zarówno w **klasyfikacji**, jak i **regresji**.  Działa podobnie do procesu podejmowania decyzji przez człowieka — zadaje kolejne pytania, aż dojdzie do odpowiedzi.\n",
    "\n",
    "- **SVM (Support Vector Machine)** – maszyna wektorów nośnych; algorytm klasyfikacji i regresji, który znajduje granicę maksymalnie oddzielającą klasy.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251c5f",
   "metadata": {},
   "source": [
    "# Wykorzystanie ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd1ff0",
   "metadata": {},
   "source": [
    "- Problemy, ktore wymagaja czestego dostrajania algorytmu lub korzystanie z dlugich list regul.\n",
    "\n",
    "- Zlozonoe problemy, ktorych nie da sie rozwiazac tradycyjnymi metodami\n",
    "\n",
    "- Zmiennych srodowisk ( `model ml` moze sie dostosowac szybko do nowych danych i byc aktualizowany z latwoscia w dowolnym momencie )\n",
    "\n",
    "- Do analizy ogromnej ilosci danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1b538",
   "metadata": {},
   "source": [
    "# Rodzaje systemów ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bb40a",
   "metadata": {},
   "source": [
    "- **Nadzorowanie w fazie uczenia** - (uczenie nadzorowane, nienadzorowane, półnadzorowane, samonadzorowane, wzmocnienie itd.)\n",
    "\n",
    "- **Uczenie się w czasie rzeczywistym** - (u. przyrostowe, wsadowe)\n",
    "\n",
    "- **Sposób pracy** - proste porównanie nowych punktów danychze znanymi punktami, lub wykrywanie wzorców w `training set` i tworzenie modelu predykcyjnego \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2a8ec",
   "metadata": {},
   "source": [
    "## Uczenie nadzorowane (Supervised Learning)\n",
    "\n",
    "#### Etykieta (Label) i Cel (Target)\n",
    "\n",
    "- **Etykieta (Label)** – to **prawidłowa odpowiedź** w danych uczących, której model używa do nauki.  \n",
    "- **Cel (Target)** – to **wartość, którą model ma przewidzieć** podczas działania na nowych danych.  \n",
    "W praktyce oba pojęcia często oznaczają to samo – wynik, do którego model dąży.\n",
    "\n",
    "#### 🔹 Przykład:\n",
    "\n",
    "| Powierzchnia (m²) | Liczba pokoi | Lokalizacja | **Cena (etykieta / target)** |\n",
    "|--------------------|--------------|--------------|------------------------------|\n",
    "| 60                 | 3            | Centrum      | 520 000 zł                   |\n",
    "\n",
    "➡️ **Cechy (features):** powierzchnia, liczba pokoi, lokalizacja  \n",
    "➡️ **Etykieta / Cel:** czy email jest spamem czy nie -> SPAM / NOT SPAM\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Uczenie nadzorowane to rodzaj uczenia maszynowego, w którym model uczy się na podstawie **danych oznaczonych (z etykietami)**.  \n",
    "Każdy przykład w danych zawiera:\n",
    "- **wejście/cechy (features)** – czyli dane wejściowe, np. liczba pokoi, lokalizacja, temperatura, słowa w zdaniu,  \n",
    "- **wyjście (label lub target value)** – czyli oczekiwany wynik, np. cena domu, gatunek kwiatu, klasa obrazu.  \n",
    "\n",
    "Celem jest nauczenie modelu zależności między wejściem a wyjściem, tak aby mógł **przewidywać etykiety (lub wartości)** dla nowych, nieznanych danych.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Regresja (Regression)\n",
    "\n",
    "Regresja to typ uczenia nadzorowanego, w którym celem jest **przewidywanie wartości liczbowych (ciągłych)** — tzw. **wartości docelowej (target value)**.  \n",
    "Model stara się znaleźć zależność matematyczną między cechami (features) a wartością, którą chcemy przewidzieć.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model analizuje dane wejściowe i dopasowuje funkcję (np. prostą lub krzywą), która najlepiej opisuje zależność między zmiennymi.  \n",
    "Podczas treningu minimalizuje różnicę między przewidywaną a rzeczywistą wartością (np. za pomocą błędu MSE – Mean Squared Error).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Prognozowanie cen nieruchomości** na podstawie powierzchni, lokalizacji i liczby pokoi.  \n",
    "- **Przewidywanie zużycia energii** lub wody w budynkach.  \n",
    "- **Szacowanie przyszłej sprzedaży** produktów lub przychodów firmy.  \n",
    "- **Prognozowanie pogody** – np. temperatury lub opadów.  \n",
    "- **Przewidywanie kursów akcji lub kryptowalut** w czasie.  \n",
    "- **Modelowanie wzrostu populacji** lub trendów gospodarczych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Regresja liniowa (Linear Regression)  \n",
    "- Regresja wielomianowa (Polynomial Regression)  \n",
    "- Random Forest Regression  \n",
    "- Support Vector Regression (SVR)  \n",
    "- Sieci neuronowe (Neural Networks)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Klasyfikacja (Classification)\n",
    "\n",
    "Klasyfikacja to rodzaj uczenia nadzorowanego, w którym celem jest **przypisanie danych do jednej lub wielu kategorii (klas)**.  \n",
    "Model nie przewiduje liczby, lecz **etykietę** — np. „kot” / „pies”, „spam” / „nie spam”.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model uczy się rozróżniać wzorce w danych, tak aby dla nowych przykładów mógł zdecydować, do której klasy należą.  \n",
    "Podczas uczenia minimalizuje liczbę błędnych przypisań (np. za pomocą funkcji strat cross-entropy).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Filtracja spamu** – rozpoznawanie, czy e-mail to spam czy wiadomość prawidłowa.  \n",
    "- **Rozpoznawanie obrazów** – np. identyfikacja obiektów (samochód, człowiek, drzewo).  \n",
    "- **Diagnostyka medyczna** – klasyfikacja, czy pacjent ma daną chorobę na podstawie wyników badań.  \n",
    "- **Analiza nastrojów (sentiment analysis)** – określenie, czy opinia jest pozytywna, neutralna, czy negatywna.  \n",
    "- **Wykrywanie oszustw finansowych** – klasyfikacja transakcji jako prawdziwe lub podejrzane.  \n",
    "- **Rozpoznawanie mowy lub tekstu** – np. komendy głosowe lub analiza języka naturalnego.  \n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Logistic Regression  \n",
    "- Decision Tree  \n",
    "- Random Forest  \n",
    "- k-NN (k-Nearest Neighbors)  \n",
    "- SVM (Support Vector Machine)  \n",
    "- Naive Bayes  \n",
    "- Sieci neuronowe (CNN, RNN)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu:\n",
    "1. **Przygotowanie danych** – zebranie i oznaczenie danych (features + labels).  \n",
    "2. **Podział danych** – na zbiór uczący (*training set*) i testowy (*test set*).  \n",
    "3. **Trenowanie modelu** – model uczy się zależności między wejściami a wyjściami.  \n",
    "4. **Walidacja i testowanie** – sprawdzenie, jak dobrze model działa na nowych danych.  \n",
    "5. **Ewaluacja wyników** – np. przy użyciu metryk: *accuracy, precision, recall, MSE, R²*.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- Systemy rekomendacji (Netflix, Amazon, Spotify).  \n",
    "- Asystenci głosowi (rozumienie mowy i komend).  \n",
    "- Systemy wykrywania oszustw bankowych.  \n",
    "- Ocena ryzyka kredytowego i scoring klientów.  \n",
    "- Wykrywanie defektów w produkcji przemysłowej.  \n",
    "- Automatyczne rozpoznawanie obrazu w kamerach bezpieczeństwa.  \n",
    "- Prognozowanie cen, popytu, trendów i sprzedaży.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55efe9",
   "metadata": {},
   "source": [
    "## Uczenie nienadzorowane (Unsupervised Learning)\n",
    "\n",
    "Uczenie nienadzorowane to rodzaj uczenia maszynowego, w którym model uczy się na podstawie **danych nieoznaczonych (bez etykiet)**.  \n",
    "Celem jest odkrywanie ukrytych wzorców, struktur i zależności w danych wejściowych, bez wcześniejszego informowania modelu, jakie są „prawidłowe” odpowiedzi. Model samodzielnie grupuje, redukuje lub identyfikuje anomalie.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Klastrowanie / Analiza Skupień (Clustering)\n",
    "\n",
    "Klastrowanie, często nazywane **Analizą Skupień**, to typ uczenia nienadzorowanego, w którym celem jest **grupowanie podobnych punktów danych w klastry (grupy)**.  \n",
    "Model samodzielnie identyfikuje wewnętrzne struktury w danych, tak aby punkty w tym samym klastrze były do siebie podobne (wysoka spójność wewnątrzklastrowa), a punkty z różnych klastrów – jak najbardziej różne (niska spójność międzyklastrowa).\n",
    "\n",
    "#### Jak to działa:\n",
    "Algorytmy klastrowania analizują cechy danych i na podstawie ich podobieństwa (często mierzonego odległością w przestrzeni cech, np. odległością euklidesową) przypisują je do grup. Nie potrzebują z góry określonych kategorii czy etykiet. Liczba klastrów może być z góry narzucona (np. K-Means) lub odkryta przez algorytm (np. DBSCAN).\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Segmentacja klientów** – grupowanie klientów na podstawie zachowań zakupowych, danych demograficznych, historii przeglądania. Pozwala to firmom na tworzenie spersonalizowanych kampanii marketingowych i strategii produktowych.\n",
    "- **Analiza danych genetycznych i medycznych** – grupowanie genów, próbek DNA, komórek lub pacjentów, aby odkryć podobieństwa i różnice, które mogą wskazywać na wspólne cechy, podtypy chorób lub reakcje na leczenie.\n",
    "- **Organizacja i eksploracja dokumentów lub artykułów** – automatyczne grupowanie tekstów o podobnej tematyce bez ich wcześniejszego tagowania. Ułatwia to wyszukiwanie, przeglądanie i odkrywanie nowych tematów w dużych zbiorach danych tekstowych.\n",
    "- **Detekcja miast w danych geograficznych** – grupowanie punktów danych lokalizacji (np. z GPS), aby zidentyfikować obszary o wysokim zagęszczeniu, co może odpowiadać miastom lub obszarom miejskim.\n",
    "- **Kompresja i segmentacja obrazów** – grupowanie podobnych pikseli lub obszarów obrazu na podstawie koloru, tekstury czy jasności, co może być wykorzystane do kompresji, analizy obiektów lub edycji obrazu.\n",
    "- **Wstępna analiza danych** – odkrywanie naturalnych grup w zbiorze danych, co może dostarczyć cennych insightów przed zastosowaniem algorytmów nadzorowanych lub w celu lepszego zrozumienia danych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- K-Means\n",
    "- Hierarchical Clustering (klastrowanie hierarchiczne)\n",
    "- DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- Gaussian Mixture Models (GMM)\n",
    "- Agglomerative Clustering\n",
    "- Mean-Shift\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Redukcja Wymiarowości (Dimensionality Reduction)\n",
    "\n",
    "Redukcja wymiarowości to typ uczenia nienadzorowanego, który ma na celu **zmniejszenie liczby cech (zmiennych) w zbiorze danych**, jednocześnie zachowując jak najwięcej istotnych informacji.  \n",
    "Pomaga to w wizualizacji danych, usuwaniu szumu, kompresji danych i przyspieszaniu pracy innych algorytmów.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model znajduje sposoby na reprezentowanie danych w przestrzeni o niższej liczbie wymiarów, tworząc nowe, syntetyczne cechy (tzw. komponenty lub embeddingi), które są kombinacją oryginalnych cech. Metody te mogą być liniowe (np. PCA) lub nieliniowe (np. t-SNE, UMAP), zdolne do wykrywania bardziej złożonych struktur.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wizualizacja danych wielowymiarowych** – przekształcenie danych z setek czy tysięcy wymiarów do 2 lub 3 wymiarów, aby móc je wykreślić i zrozumieć strukturę, dostrzec klastry lub anomalie. Jest to kluczowy krok w eksploracyjnej analizie danych.\n",
    "- **Kompresja obrazów i dźwięku** – redukcja liczby pikseli, kanałów kolorów lub próbek sygnału przy zachowaniu akceptowalnej jakości wizualnej/słuchowej, co zmniejsza wymagania dotyczące przechowywania i przesyłania danych.\n",
    "- **Przygotowanie danych do uczenia nadzorowanego** – zmniejszenie liczby cech wejściowych dla klasyfikatorów lub regresorów, aby zapobiec nadmiernemu dopasowaniu (overfitting), zmniejszyć złożoność obliczeniową i poprawić generalizację modelu.\n",
    "- **Redukcja szumu (denoising)** – usunięcie zbędnych, redundantnych lub mało istotnych cech, które mogą wprowadzać szum do modelu i pogarszać jego wydajność.\n",
    "- **Uczenie embeddingów** – tworzenie niskowymiarowych, gęstych reprezentacji (wektorów) dla złożonych obiektów, takich jak słowa (word embeddings), obrazy czy użytkownicy, które zachowują semantyczne lub strukturalne relacje.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- PCA (Principal Component Analysis – Analiza Składowych Głównych)\n",
    "- t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "- UMAP (Uniform Manifold Approximation and Projection)\n",
    "- Autoenkodery (Autoencoders – w sieciach neuronowych)\n",
    "- NMF (Non-negative Matrix Factorization)\n",
    "- LLE (Locally Linear Embedding)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Wizualizacja (Visualization)\n",
    "\n",
    "Wizualizacja danych w kontekście uczenia nienadzorowanego to proces **graficznego przedstawiania złożonych danych**, aby ułatwić zrozumienie ich struktury, wzorców, klastrów, anomalii i relacji między cechami, często po przeprowadzeniu redukcji wymiarowości. Choć nie jest to algorytm uczenia maszynowego per se, jest to nieodzowne narzędzie do interpretacji wyników nienadzorowanych modeli.\n",
    "\n",
    "#### Jak to działa:\n",
    "Wykorzystuje się różne techniki graficzne (wykresy punktowe, mapy cieplne, dendrogramy, wykresy 3D) do przedstawienia danych w sposób, który jest łatwy do odbioru przez człowieka. Często wizualizacja jest efektem zastosowania metod redukcji wymiarowości, które transformują dane do 2 lub 3 wymiarów, umożliwiając ich wykreślenie.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wizualizacja klastrów** – przedstawienie punktów danych w 2D/3D, gdzie punkty należące do tego samego klastra są oznaczone tym samym kolorem lub kształtem. Pozwala to na ocenę jakości klastrowania i zrozumienie, jakie cechy charakteryzują poszczególne grupy.\n",
    "- **Odkrywanie anomalii** – punkty danych, które są wizualnie odseparowane od głównych skupisk, mogą wskazywać na anomalie.\n",
    "- **Eksploracja danych** – szybkie dostrzeżenie relacji między zmiennymi, wykrycie brakujących danych, obserwacja rozkładów cech czy identyfikacja korelacji.\n",
    "- **Ocena jakości redukcji wymiarowości** – sprawdzenie, czy metoda redukcji wymiarowości skutecznie zachowała strukturę danych, np. czy klastry są nadal dobrze rozdzielone po projekcji na niższe wymiary.\n",
    "- **Komunikacja wyników** – prezentowanie złożonych analiz szerszej publiczności w przystępny i intuicyjny sposób.\n",
    "\n",
    "#### Popularne techniki i narzędzia:\n",
    "- Wykresy punktowe (Scatter Plots)\n",
    "- Macierze wykresów punktowych (Scatter Plot Matrices)\n",
    "- Wykresy 3D\n",
    "- Mapy cieplne (Heatmaps)\n",
    "- Dendrogramy (dla klastrowania hierarchicznego)\n",
    "- Wykresy radarowe\n",
    "- Biblioteki Python: Matplotlib, Seaborn, Plotly, Altair\n",
    "- Narzędzia: Tableau, Power BI, Qlik Sense\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Wykrywanie Anomalii (Anomaly Detection)\n",
    "\n",
    "Wykrywanie anomalii to typ uczenia nienadzorowanego, który ma na celu **identyfikację punktów danych, które znacznie odbiegają od większości danych** (tzw. odstępstw lub outlierów).  \n",
    "Anomalie często wskazują na nietypowe, interesujące lub problematyczne zdarzenia.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model uczy się \"normalnego\" wzorca danych, a następnie identyfikuje punkty, które są na tyle różne od tego wzorca, że można je uznać za anomalie. Nie potrzebuje wcześniejszych etykiet anomalii (choć może być wspierane przez nadzór). Podejścia obejmują metody statystyczne, oparte na gęstości, odległości czy modelach uczenia maszynowego.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wykrywanie oszustw finansowych** – identyfikacja nietypowych transakcji kartą kredytową, które mogą wskazywać na oszustwo, lub podejrzanych roszczeń ubezpieczeniowych.\n",
    "- **Monitorowanie sieci komputerowych** – wykrywanie nietypowego ruchu sieciowego, który może sygnalizować atak hakerski, złośliwe oprogramowanie lub naruszenie bezpieczeństwa.\n",
    "- **Diagnostyka usterek maszyn i konserwacja predykcyjna** – monitorowanie danych z sensorów maszyn (np. wibracje, temperatura, zużycie energii) w celu wykrycia nietypowych wzorców wskazujących na zbliżającą się awarię lub potrzebę serwisu.\n",
    "- **Kontrola jakości w produkcji przemysłowej** – automatyczna identyfikacja produktów z wadami, które odbiegają od normy, na podstawie danych z kamer lub sensorów.\n",
    "- **Monitorowanie zdrowia pacjentów** – wykrywanie nietypowych odczytów z urządzeń medycznych (np. EKG, glukometr, smartwatche), które mogą wskazywać na nagły problem zdrowotny lub pogorszenie stanu.\n",
    "- **Analiza danych z sensorów IoT** – wykrywanie nieprawidłowości w odczytach z czujników w inteligentnych domach, miastach czy rolnictwie, np. awarii sprzętu czy nietypowych warunków środowiskowych.\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Isolation Forest\n",
    "- One-Class SVM (Support Vector Machine dla jednej klasy)\n",
    "- Local Outlier Factor (LOF)\n",
    "- DBSCAN (może być używany do wykrywania punktów nieprzypisanych do klastrów)\n",
    "- Autoenkodery (wersje do wykrywania anomalii, gdzie duży błąd rekonstrukcji wskazuje na anomalię)\n",
    "- K-Nearest Neighbors (k-NN) na podstawie odległości do sąsiadów\n",
    "- Statystyczne metody: 3-Sigma Rule, Box Plots\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie Reguł Asocjacyjnych (Association Rule Learning)\n",
    "\n",
    "Uczenie reguł asocjacyjnych to typ uczenia nienadzorowanego, który ma na celu **odkrywanie interesujących relacji i zależności między zmiennymi w dużych zbiorach danych**, często w kontekście danych transakcyjnych.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model szuka często występujących razem zestawów elementów (np. produktów w koszyku zakupowym) i na ich podstawie generuje reguły typu \"Jeśli kupiono X, to prawdopodobnie kupiono też Y\". Mierzy się wsparcie (support), ufność (confidence) i lift, aby ocenić istotność tych reguł.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Analiza koszyka zakupowego (Market Basket Analysis)** – identyfikacja produktów, które często są kupowane razem (np. \"Klienci, którzy kupują pieluchy, często kupują też piwo\", \"Jeśli klient kupi kawę i cukier, prawdopodobnie kupi też mleko\"). Pomaga to w układaniu towarów w sklepach, ofertach promocyjnych, cross-sellingu czy rekomendacjach online.\n",
    "- **Optymalizacja układu sklepu internetowego lub fizycznego** – umieszczanie często kupowanych razem produktów w pobliżu siebie w celu zwiększenia sprzedaży.\n",
    "- **Systemy rekomendacji** – sugerowanie produktów na podstawie tego, co inni klienci z podobnymi preferencjami kupili (np. \"Często kupowane razem z tym produktem\").\n",
    "- **Analiza danych medycznych** – odkrywanie powiązań między objawami, diagnozami, wynikami badań i lekami, które mogą wspierać badania medyczne i decyzje kliniczne.\n",
    "- **Zarządzanie zapasami** – przewidywanie popytu na produkty komplementarne, aby zoptymalizować stany magazynowe.\n",
    "- **Wykrywanie wzorców w danych sekwencyjnych** – znajdowanie często występujących sekwencji zdarzeń lub czynności (np. w logach systemowych).\n",
    "\n",
    "#### Popularne algorytmy:\n",
    "- Apriori\n",
    "- FP-Growth (Frequent Pattern Growth)\n",
    "- ECLAT\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu nienadzorowanego:\n",
    "1. **Przygotowanie danych** – zebranie, wstępne oczyszczenie i ewentualne przekształcenie danych (bez etykiet).  \n",
    "2. **Wybór algorytmu** – w zależności od celu (klastrowanie, redukcja, anomalia, reguły asocjacyjne).  \n",
    "3. **Trenowanie modelu** – model samodzielnie odkrywa struktury i wzorce w danych.  \n",
    "4. **Ocena, interpretacja i wizualizacja wyników** – analiza odkrytych wzorców (np. wizualizacja klastrów, analiza komponentów, identyfikacja anomalii, interpretacja reguł).  \n",
    "5. **Dostosowanie parametrów** – iteracyjne poprawianie modelu i algorytmu w celu uzyskania optymalnych i sensownych wyników.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- Segmentacja rynku i personalizacja ofert marketingowych.\n",
    "- Wizualizacja i eksploracja złożonych zbiorów danych dla lepszego zrozumienia.\n",
    "- Kompresja danych, optymalizacja przechowywania i przesyłania.\n",
    "- Wykrywanie oszustw, błędów, usterek i zagrożeń bezpieczeństwa.\n",
    "- Ulepszanie systemów rekomendacyjnych poprzez odkrywanie ukrytych powiązań.\n",
    "- Uczenie się cech (feature learning) dla innych modeli nadzorowanych (jako pre-processing).\n",
    "- Wstępne badanie danych i generowanie hipotez przed zastosowaniem bardziej zaawansowanych technik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57260d4",
   "metadata": {},
   "source": [
    "## Uczenie Pół-nadzorowane (Semi-supervised Learning)\n",
    "\n",
    "Uczenie pół-nadzorowane to rodzaj uczenia maszynowego, który łączy w sobie elementy **uczenia nadzorowanego** i **nienadzorowanego**. Model uczy się na podstawie **niewielkiej ilości danych oznaczonych (z etykietami)** oraz **dużej ilości danych nieoznaczonych (bez etykiet)**.  \n",
    "Jest to szczególnie przydatne w sytuacjach, gdy etykietowanie danych jest kosztowne, czasochłonne lub wymaga specjalistycznej wiedzy.\n",
    "\n",
    "#### Dlaczego Semi-supervised Learning?\n",
    "- **Ograniczone etykiety:** Wiele realnych problemów ma dostęp do dużej ilości danych, ale tylko niewielka ich część jest etykietowana.\n",
    "- **Wykorzystanie nieoznaczonych danych:** Dane nieoznaczone zawierają cenne informacje o strukturze rozkładu danych, które mogą pomóc modelowi lepiej uogólniać.\n",
    "- **Zmniejszenie kosztów:** Redukuje potrzebę ręcznego etykietowania ogromnych zbiorów danych.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na spójności (Consistency Regularization / Self-training)\n",
    "\n",
    "Uczenie oparte na spójności to podejście, w którym model jest trenowany tak, aby jego przewidywania dla danych nieoznaczonych były **spójne** nawet po niewielkich perturbacjach danych wejściowych lub samego modelu. Self-training jest pokrewną techniką, gdzie model \"etykietuje\" dane nieoznaczone.\n",
    "\n",
    "#### Jak to działa:\n",
    "1.  **Self-training:** Model jest początkowo trenowany na małym zbiorze danych oznaczonych. Następnie używa się go do przewidywania etykiet dla danych nieoznaczonych. Te \"pseudo-etykiety\" są dodawane do zbioru treningowego (często z wysoką pewnością), a model jest ponownie trenowany. Proces może być iteracyjny.\n",
    "2.  **Consistency Regularization:** Model jest trenowany tak, aby jego wyjścia dla nieoznaczonych danych były podobne, nawet jeśli te dane zostaną lekko zmienione (np. dodanie szumu, drobne transformacje obrazu). Dodaje się człon regularyzacyjny do funkcji straty, który karze za niespójne przewidywania.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Klasyfikacja obrazów z ograniczonymi etykietami** – np. rozpoznawanie gatunków zwierząt, gdzie mamy tylko kilka zdjęć z etykietami, ale tysiące nieoznaczonych. Model uczy się na etykietowanych, a następnie generuje pseudo-etykiety dla reszty.\n",
    "- **Analiza tekstu (NLP)** – klasyfikacja sentymentu, wykrywanie spamu, gdzie dostępnych jest wiele nieoznaczonych tekstów, ale etykietowanie jest kosztowne.\n",
    "- **Rozpoznawanie mowy** – poprawa dokładności modeli rozpoznawania mowy poprzez wykorzystanie dużych zbiorów nieoznaczonych nagrań audio.\n",
    "- **Diagnostyka medyczna** – wspomaganie klasyfikacji chorób na podstawie obrazów medycznych (np. MRI, RTG), gdzie etykietowanie wymaga ekspertów.\n",
    "- **Systemy rekomendacji** – wykorzystanie nieoznaczonych danych o interakcjach użytkowników do poprawy rekomendacji.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Pseudo-Labeling\n",
    "- Mean Teacher\n",
    "- Pi-Model\n",
    "- Temporal Ensembling\n",
    "- MixMatch, FixMatch (zaawansowane techniki consistency regularization)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na grafach (Graph-based Semi-supervised Learning)\n",
    "\n",
    "Uczenie oparte na grafach wykorzystuje strukturę grafu, gdzie punkty danych są wierzchołkami, a krawędzie reprezentują podobieństwo między nimi. Informacje z etykietowanych wierzchołków są \"rozprzestrzeniane\" na nieoznaczone wierzchołki wzdłuż krawędzi grafu.\n",
    "\n",
    "#### Jak to działa:\n",
    "Tworzy się graf, w którym każdy punkt danych jest węzłem. Krawędzie łączą podobne punkty danych, a ich wagi odzwierciedlają stopień podobieństwa. Etykiety z nielicznych oznaczonych węzłów są propagowane przez graf do nieoznaczonych węzłów, zakładając, że podobne węzły powinny mieć podobne etykiety.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Klasyfikacja dokumentów** – tworzenie grafu, gdzie dokumenty są węzłami, a krawędzie łączą podobne dokumenty. Etykiety z kilku oznaczonych dokumentów są propagowane na resztę.\n",
    "- **Analiza sieci społecznościowych** – klasyfikacja użytkowników (np. identyfikacja botów, segmentacja grup interesu) na podstawie ich połączeń i aktywności, gdzie tylko niewielka część użytkowników jest etykietowana.\n",
    "- **Bioinformatyka** – klasyfikacja białek lub genów na podstawie ich interakcji i podobieństwa sekwencji.\n",
    "- **Wykrywanie oszustw** – budowanie grafu transakcji lub użytkowników i propagowanie informacji o znanych oszustwach na powiązane, nieoznaczone węzły.\n",
    "- **Segmentacja obrazów** – tworzenie grafu z pikseli lub superpikseli obrazu i propagowanie etykiet z kilku oznaczonych regionów na resztę.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Label Propagation (Propagacja etykiet)\n",
    "- Label Spreading\n",
    "- Graph Convolutional Networks (GCNs) – w kontekście głębokiego uczenia na grafach\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na modelach generatywnych (Generative Models for Semi-supervised Learning)\n",
    "\n",
    "Uczenie oparte na modelach generatywnych zakłada, że dane pochodzą z pewnego rozkładu, który można modelować. Modele te próbują nauczyć się tego rozkładu, co pozwala im wykorzystać zarówno dane oznaczone, jak i nieoznaczone.\n",
    "\n",
    "#### Jak to działa:\n",
    "Model generatywny (np. GMM, VAE, GAN) uczy się wspólnego rozkładu prawdopodobieństwa dla danych wejściowych i etykiet. Dane nieoznaczone pomagają modelowi lepiej zrozumieć strukturę danych wejściowych, co z kolei poprawia jego zdolność do klasyfikacji danych oznaczonych.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Klasyfikacja obrazów** – wykorzystanie VAE lub GAN do nauczenia się reprezentacji obrazów, co pomaga w klasyfikacji nawet z ograniczonymi etykietami.\n",
    "- **Rozpoznawanie wzorców** – budowanie modelu, który potrafi generować nowe przykłady danych, co świadczy o zrozumieniu ich struktury.\n",
    "- **Segmentacja obrazów** – modele generatywne mogą pomóc w nauczeniu się, jak wyglądają różne regiony obrazu, nawet jeśli tylko niewielka ich część jest etykietowana.\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Gaussian Mixture Models (GMM)\n",
    "- Variational Autoencoders (VAEs)\n",
    "- Generative Adversarial Networks (GANs) w trybie pół-nadzorowanym (SGAN)\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Uczenie oparte na redukcji wymiarowości (Dimensionality Reduction for Semi-supervised Learning)\n",
    "\n",
    "Chociaż redukcja wymiarowości jest techniką nienadzorowaną, może być wykorzystana w kontekście pół-nadzorowanym, aby znaleźć reprezentację danych, która jest optymalna zarówno dla struktury danych (nienadzorowane), jak i dla zadania klasyfikacji (nadzorowane).\n",
    "\n",
    "#### Jak to działa:\n",
    "Niektóre algorytmy redukcji wymiarowości mogą uwzględniać dostępne etykiety, aby znaleźć projekcję, która nie tylko zmniejsza wymiarowość, ale także maksymalizuje separację klas. Inne metody nienadzorowane (np. PCA) mogą być użyte jako pre-processing, a następnie na zredukowanych danych stosuje się techniki pół-nadzorowane.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Wizualizacja danych z etykietami i bez** – użycie t-SNE lub UMAP do wizualizacji danych, gdzie punkty z etykietami są wyróżnione, co pomaga w ocenie, czy struktura danych wspiera separację klas.\n",
    "- **Poprawa wydajności klasyfikatorów** – redukcja wymiarowości danych wejściowych przed zastosowaniem algorytmu pół-nadzorowanego lub nadzorowanego, co może zmniejszyć szum i poprawić generalizację.\n",
    "- **Uczenie reprezentacji** – tworzenie niskowymiarowych embeddingów, które są użyteczne zarówno dla zadań nienadzorowanych (np. klastrowanie), jak i nadzorowanych (np. klasyfikacja).\n",
    "\n",
    "#### Popularne algorytmy/techniki:\n",
    "- Semi-supervised PCA (SSPCA)\n",
    "- Linear Discriminant Analysis (LDA) – choć głównie nadzorowane, może być adaptowane\n",
    "- Manifold Learning (np. Isomap, LLE) w połączeniu z etykietami\n",
    "- Autoenkodery z dodatkową funkcją straty dla etykiet\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu pół-nadzorowanego:\n",
    "1. **Przygotowanie danych** – zebranie danych, podział na mały zbiór oznaczony i duży zbiór nieoznaczony.  \n",
    "2. **Wybór algorytmu** – w zależności od dostępnych danych i problemu (np. self-training, graph-based).  \n",
    "3. **Trenowanie modelu** – model uczy się, wykorzystując zarówno etykiety, jak i strukturę danych nieoznaczonych.  \n",
    "4. **Walidacja i testowanie** – ocena modelu na zbiorze testowym (z etykietami).  \n",
    "5. **Ewaluacja wyników** – przy użyciu metryk klasyfikacji (accuracy, precision, recall, F1-score).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Rozpoznawanie obrazów i wideo** – klasyfikacja obiektów, segmentacja, detekcja twarzy, gdzie etykietowanie każdego piksela jest niemożliwe.\n",
    "- **Przetwarzanie języka naturalnego (NLP)** – klasyfikacja tekstu, analiza sentymentu, rozpoznawanie encji, gdzie dostępnych jest wiele nieoznaczonych tekstów.\n",
    "- **Bioinformatyka** – klasyfikacja danych genetycznych, analiza ekspresji genów, gdzie etykietowanie próbek jest kosztowne.\n",
    "- **Diagnostyka medyczna** – wspomaganie klasyfikacji chorób na podstawie obrazów medycznych lub danych pacjentów.\n",
    "- **Wykrywanie oszustw i anomalii** – wykorzystanie nieoznaczonych danych do lepszego zrozumienia \"normalnego\" zachowania i skuteczniejszego wykrywania odstępstw.\n",
    "- **Personalizacja i systemy rekomendacji** – wykorzystanie nieoznaczonych danych o zachowaniach użytkowników do poprawy rekomendacji.\n",
    "- **Uczenie robotów** – roboty mogą uczyć się na podstawie niewielkiej liczby demonstracji (etykiet) i dużej liczby nieoznaczonych interakcji ze środowiskiem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3948247",
   "metadata": {},
   "source": [
    "## Uczenie Samonadzorowane (Self-supervised Learning - SSL)\n",
    "\n",
    "Uczenie samonadzorowane to rodzaj uczenia maszynowego, w którym model uczy się na podstawie **danych nieoznaczonych**, ale generuje **własne \"pseudo-etykiety\"** z tych danych, aby rozwiązać tzw. **zadanie pretekstowe (pretext task)**.  \n",
    "Celem nie jest rozwiązanie samego zadania pretekstowego, lecz nauczenie modelu **ogólnych, użytecznych reprezentacji (embeddingów)** danych, które mogą być następnie wykorzystane do rozwiązywania innych, bardziej złożonych zadań (tzw. **zadań downstream**), często z użyciem uczenia nadzorowanego.\n",
    "\n",
    "#### Dlaczego Self-supervised Learning?\n",
    "- **Brak etykiet:** Podobnie jak w uczeniu nienadzorowanym, SSL nie wymaga ręcznie etykietowanych danych.\n",
    "- **Bogatsze reprezentacje:** W przeciwieństwie do tradycyjnego uczenia nienadzorowanego (np. klastrowania), SSL często prowadzi do nauki bardziej semantycznie bogatych i ogólnych reprezentacji, które są bardzo skuteczne w transfer learningu.\n",
    "- **Skalowalność:** Możliwość wykorzystania ogromnych, nieoznaczonych zbiorów danych (np. miliardów obrazów, terabajtów tekstu) do wstępnego trenowania.\n",
    "- **Most między unsupervised a supervised:** Umożliwia wykorzystanie nienadzorowanych danych do \"rozgrzania\" modelu, który następnie jest dostrajany (fine-tuned) na małym zbiorze danych oznaczonych.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zadania Pretekstowe (Pretext Tasks)\n",
    "\n",
    "Zadania pretekstowe to specjalnie zaprojektowane zadania, które model rozwiązuje na danych nieoznaczonych, aby nauczyć się użytecznych reprezentacji. Model generuje własne etykiety dla tych zadań.\n",
    "\n",
    "#### Jak to działa:\n",
    "Dane wejściowe są modyfikowane w kontrolowany sposób (np. maskowanie części obrazu, tasowanie zdań), a model jest trenowany, aby przewidzieć oryginalny stan lub brakującą część. Rozwiązując te \"sztuczne\" problemy, model uczy się rozumieć strukturę, kontekst i semantykę danych.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Przewidywanie brakujących fragmentów obrazu (Image Inpainting/Context Prediction):** Model otrzymuje obraz z zamaskowanym fragmentem i musi przewidzieć, co się tam znajdowało. Uczy się relacji przestrzennych i semantycznych obiektów.\n",
    "- **Przewidywanie względnej pozycji fragmentów obrazu (Relative Patch Prediction):** Model otrzymuje centralny fragment obrazu i kilka innych fragmentów, a jego zadaniem jest przewidzenie, gdzie te inne fragmenty znajdowały się względem centralnego. Uczy się relacji przestrzennych.\n",
    "- **Kolorowanie obrazów czarno-białych (Colorization):** Model otrzymuje obraz czarno-biały i musi przewidzieć jego kolory. Uczy się rozpoznawać obiekty i ich typowe barwy.\n",
    "- **Generowanie następnego słowa/maskowanie słów (Next Word Prediction/Masked Language Modeling):** W NLP, model otrzymuje sekwencję słów i musi przewidzieć następne słowo (np. GPT) lub zamaskowane słowa w zdaniu (np. BERT). Uczy się gramatyki, składni i semantyki języka.\n",
    "- **Przewidywanie rotacji obrazu (Rotation Prediction):** Model otrzymuje obraz obrócony o losowy kąt i musi przewidzieć ten kąt. Uczy się rozpoznawania obiektów niezależnie od ich orientacji.\n",
    "- **Kontrastowe uczenie się (Contrastive Learning):** Model uczy się, aby podobne przykłady (np. różne augmentacje tego samego obrazu) miały podobne reprezentacje, a niepodobne przykłady – różne. Jest to obecnie jedna z najskuteczniejszych metod SSL.\n",
    "\n",
    "#### Popularne algorytmy/techniki (przykłady zadań pretekstowych):\n",
    "- **Dla obrazów:** Jigsaw Puzzles, Rotation Prediction, Context Prediction, Colorization, SimCLR, MoCo, BYOL (ostatnie trzy to metody kontrastowe).\n",
    "- **Dla tekstu:** Masked Language Modeling (BERT), Next Sentence Prediction (BERT), Next Token Prediction (GPT), ELECTRA.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Transfer Learning (Przenoszenie Wiedzy)\n",
    "\n",
    "Transfer Learning to kluczowy element i główna zaleta uczenia samonadzorowanego. Polega na **przenoszeniu wiedzy (nauczenia się reprezentacji) z jednego zadania (zadania pretekstowego SSL) do innego, często bardziej złożonego zadania (zadania downstream)**.\n",
    "\n",
    "#### Jak to działa:\n",
    "1.  **Pre-training (Wstępne trenowanie):** Model (np. duża sieć neuronowa) jest trenowany na ogromnym zbiorze danych nieoznaczonych, rozwiązując zadanie pretekstowe SSL. W tym etapie model uczy się ogólnych, niskopoziomowych i wysokopoziomowych cech danych (np. krawędzie, tekstury, kształty dla obrazów; gramatyka, semantyka dla tekstu).\n",
    "2.  **Fine-tuning (Dostrajanie):** Nauczenie reprezentacje (wagi i bias sieci) są następnie wykorzystywane jako punkt wyjścia dla nowego zadania (np. klasyfikacji obrazów, analizy sentymentu), które ma dostęp do małego zbioru danych oznaczonych. Zazwyczaj dodaje się nową, małą warstwę wyjściową, która jest trenowana na danych oznaczonych, a reszta modelu jest albo zamrożona, albo trenowana z bardzo małym współczynnikiem uczenia.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Rozpoznawanie obiektów na obrazach medycznych:** Wstępne trenowanie modelu na miliardach ogólnych obrazów (np. ImageNet, ale bez etykiet, używając SSL), a następnie dostrajanie go na małym zbiorze obrazów medycznych (np. RTG klatki piersiowej) z etykietami.\n",
    "- **Klasyfikacja tekstu w rzadkich językach:** Wstępne trenowanie modelu językowego (np. BERT) na ogromnym korpusie tekstu w języku angielskim (lub innym bogatym w dane), a następnie dostrajanie go na małym zbiorze danych w rzadkim języku do zadania klasyfikacji.\n",
    "- **Personalizacja asystentów głosowych:** Wstępne trenowanie modelu na ogólnych danych audio, a następnie dostrajanie go do rozpoznawania mowy konkretnego użytkownika.\n",
    "- **Wykrywanie oszustw:** Wstępne trenowanie modelu na dużej ilości nieoznaczonych danych transakcyjnych, aby nauczyć się \"normalnych\" wzorców, a następnie dostrajanie go do wykrywania oszustw na małym zbiorze etykietowanych transakcji.\n",
    "\n",
    "#### Korzyści z Transfer Learningu w SSL:\n",
    "- **Lepsza wydajność:** Modele osiągają znacznie lepsze wyniki, nawet z małą ilością danych oznaczonych.\n",
    "- **Szybszy trening:** Wstępnie wytrenowany model szybciej konwerguje podczas dostrajania.\n",
    "- **Mniejsze zapotrzebowanie na dane:** Zmniejsza potrzebę posiadania ogromnych, etykietowanych zbiorów danych dla każdego nowego zadania.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Porównanie Self-supervised Learning (SSL) z Unsupervised Learning (UL)\n",
    "\n",
    "Chociaż SSL jest formą uczenia nienadzorowanego, istnieje kluczowa różnica w ich celach i metodologii:\n",
    "\n",
    "| Cecha                  | Uczenie Nienadzorowane (Unsupervised Learning - UL)                               | Uczenie Samonadzorowane (Self-supervised Learning - SSL)                               |\n",
    "| :--------------------- | :-------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------- |\n",
    "| **Cel główny**         | Odkrywanie ukrytych struktur w danych (np. klastry, redukcja wymiarowości).       | Uczenie się ogólnych, użytecznych reprezentacji danych do **transferu wiedzy**.        |\n",
    "| **Etykiety**           | Brak etykiet.                                                                     | Brak ręcznych etykiet. Model **generuje własne \"pseudo-etykiety\"** z danych.            |\n",
    "| **Zadanie**            | Bezpośrednie rozwiązanie problemu (np. klastrowanie klientów).                    | Rozwiązanie **zadania pretekstowego**, które jest środkiem do celu (nauki reprezentacji). |\n",
    "| **Wyjście**            | Klastry, zredukowane wymiary, wykryte anomalie.                                   | **Reprezentacje (embeddingi)** danych, które są wejściem dla kolejnych zadań.          |\n",
    "| **Zastosowanie**       | Segmentacja, wizualizacja, detekcja anomalii, analiza koszyka.                    | **Pre-training** dla zadań nadzorowanych (klasyfikacja, detekcja obiektów, NLP).       |\n",
    "| **Typowe algorytmy**   | K-Means, PCA, DBSCAN, Isolation Forest, Apriori.                                  | BERT, GPT, SimCLR, MoCo, BYOL (często oparte na głębokich sieciach neuronowych).       |\n",
    "| **Złożoność modelu**   | Często prostsze modele, choć mogą być też głębokie autoenkodery.                   | Zazwyczaj **głębokie sieci neuronowe** (transformery, konwolucyjne).                   |\n",
    "\n",
    "**Kluczowa różnica:**\n",
    "UL skupia się na **bezpośrednim odkrywaniu wzorców** w danych. SSL natomiast skupia się na **uczeniu się reprezentacji**, które są tak dobre, że mogą być **przeniesione** do innych zadań, często nadzorowanych, znacząco poprawiając ich wydajność, nawet przy małej ilości etykiet. SSL jest często postrzegane jako sposób na \"rozgrzanie\" dużych modeli głębokiego uczenia, aby były bardziej efektywne w późniejszym dostrajaniu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu samonadzorowanego:\n",
    "1. **Przygotowanie danych** – zebranie dużego zbioru danych nieoznaczonych.  \n",
    "2. **Definicja zadania pretekstowego** – zaprojektowanie zadania, które pozwoli modelowi nauczyć się użytecznych reprezentacji.  \n",
    "3. **Trenowanie modelu (Pre-training)** – model uczy się rozwiązywać zadanie pretekstowe, generując własne pseudo-etykiety.  \n",
    "4. **Ekstrakcja reprezentacji** – po pre-treningu, warstwy modelu (z wyjątkiem warstwy wyjściowej zadania pretekstowego) są wykorzystywane do ekstrakcji embeddingów.  \n",
    "5. **Dostrajanie (Fine-tuning)** – na małym zbiorze danych oznaczonych, model jest dostrajany do właściwego zadania (downstream task).  \n",
    "6. **Ewaluacja wyników** – ocena modelu na zbiorze testowym dla zadania downstream.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Przetwarzanie języka naturalnego (NLP):** Modele takie jak BERT, GPT-3/4, T5 są trenowane samonadzorowanie na ogromnych korpusach tekstu, a następnie dostrajane do tłumaczenia maszynowego, generowania tekstu, analizy sentymentu, odpowiadania na pytania.\n",
    "- **Wizja komputerowa:** Modele trenowane samonadzorowanie (np. SimCLR, MoCo) na miliardach obrazów, a następnie dostrajane do klasyfikacji obrazów, detekcji obiektów, segmentacji, rozpoznawania twarzy, nawet z bardzo małą ilością etykiet.\n",
    "- **Rozpoznawanie mowy:** Wstępne trenowanie na dużych zbiorach audio, a następnie dostrajanie do transkrypcji mowy, identyfikacji mówcy.\n",
    "- **Bioinformatyka:** Uczenie reprezentacji sekwencji DNA/RNA/białek, które mogą być następnie użyte do przewidywania funkcji białek, wykrywania mutacji.\n",
    "- **Robotyka:** Uczenie się reprezentacji środowiska i interakcji na podstawie nieoznaczonych danych z sensorów, co pomaga robotom w nawigacji i manipulacji.\n",
    "- **Medycyna:** Wstępne trenowanie na dużych zbiorach nieoznaczonych obrazów medycznych, a następnie dostrajanie do diagnozy chorób."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72935d52",
   "metadata": {},
   "source": [
    "## Uczenie ze Wzmocnieniem (Reinforcement Learning - RL)\n",
    "\n",
    "Uczenie ze wzmocnieniem to zupełnie inny paradygmat uczenia maszynowego, w którym system uczący, zwany w tym kontekście **agentem**, może **obserwować środowisko**, **wybierać i wykonywać akcje**, a w zamian otrzymuje **nagrody** (lub kary w postaci negatywnych nagród).  \n",
    "Agent musi samodzielnie nauczyć się, jaka jest najlepsza strategia, zwana **polityką (policy)**, aby z czasem uzyskać jak najwięcej nagród. Polityka definiuje, jaką akcję agent powinien wybrać w danej sytuacji.\n",
    "\n",
    "#### Dlaczego Reinforcement Learning?\n",
    "- **Interakcja ze środowiskiem:** RL jest idealne do problemów, gdzie system musi podejmować sekwencję decyzji w dynamicznym środowisku.\n",
    "- **Brak etykiet:** Nie wymaga ręcznie etykietowanych danych wejścia-wyjścia; uczy się na podstawie prób i błędów oraz otrzymywanych nagród.\n",
    "- **Optymalizacja długoterminowa:** Skupia się na maksymalizacji skumulowanej nagrody w czasie, a nie tylko na natychmiastowych korzyściach.\n",
    "- **Autonomiczne systemy:** Umożliwia tworzenie systemów, które uczą się adaptować i optymalizować swoje zachowanie w złożonych scenariuszach.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Agent i Środowisko (Agent and Environment)\n",
    "\n",
    "W uczeniu ze wzmocnieniem, interakcja odbywa się między **agentem** a **środowiskiem**.\n",
    "\n",
    "#### Jak to działa:\n",
    "- **Agent:** To system uczący się, który podejmuje decyzje. Obserwuje stan środowiska, wybiera akcję do wykonania i otrzymuje nagrodę (lub karę) oraz nowy stan środowiska.\n",
    "- **Środowisko:** To świat, w którym działa agent. Reaguje na akcje agenta, zmieniając swój stan i dostarczając nagrody.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Robot kroczący:** Robot (agent) obserwuje swoje położenie i równowagę (stan środowiska), wykonuje ruchy nogami (akcje), a otrzymuje nagrody za utrzymanie równowagi i poruszanie się do przodu, a kary za upadek.\n",
    "- **Gra w Go (AlphaGo):** Program AlphaGo (agent) obserwuje planszę (stan środowiska), wykonuje ruch (akcję), a otrzymuje nagrody za wygrane partie i kary za przegrane.\n",
    "- **Autonomiczny samochód:** Samochód (agent) obserwuje drogę, inne pojazdy, znaki (stan środowiska), wykonuje akcje (przyspieszanie, hamowanie, skręcanie), a otrzymuje nagrody za bezpieczną jazdę i dotarcie do celu, a kary za kolizje czy naruszenia przepisów.\n",
    "- **System zarządzania energią:** System (agent) obserwuje zużycie energii, ceny, prognozy pogody (stan środowiska), podejmuje decyzje o włączeniu/wyłączeniu urządzeń (akcje), a otrzymuje nagrody za oszczędności i kary za przekroczenie limitów.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Akcje, Stany i Nagrody (Actions, States, and Rewards)\n",
    "\n",
    "To podstawowe elementy, które definiują interakcję agenta ze środowiskiem.\n",
    "\n",
    "#### Jak to działa:\n",
    "- **Akcje (Actions):** Decyzje, które agent może podjąć w danym stanie środowiska. Mogą być dyskretne (np. \"idź w lewo\", \"kup\") lub ciągłe (np. \"przyspiesz o 0.5 m/s²\").\n",
    "- **Stany (States):** Reprezentacja aktualnej sytuacji środowiska, którą agent może obserwować. Stan zawiera wszystkie istotne informacje potrzebne agentowi do podjęcia decyzji.\n",
    "- **Nagrody (Rewards):** Sygnał zwrotny od środowiska, który informuje agenta o jakości jego ostatniej akcji. Nagrody są kluczowe dla uczenia się polityki. Celem agenta jest maksymalizacja skumulowanej nagrody w czasie.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Gra w szachy:**\n",
    "    - **Akcje:** Wykonanie ruchu figurą.\n",
    "    - **Stany:** Układ figur na szachownicy.\n",
    "    - **Nagrody:** +1 za wygraną, -1 za przegraną, 0 za remis lub ruchy pośrednie.\n",
    "- **Zarządzanie magazynem:**\n",
    "    - **Akcje:** Zamówienie towaru, wysyłka towaru.\n",
    "    - **Stany:** Poziom zapasów, prognozy popytu.\n",
    "    - **Nagrody:** + za zysk ze sprzedaży, - za koszty magazynowania, - za brak towaru.\n",
    "- **Sterowanie robotem przemysłowym:**\n",
    "    - **Akcje:** Ruch ramienia robota w określonym kierunku.\n",
    "    - **Stany:** Pozycja ramienia, położenie obiektu.\n",
    "    - **Nagrody:** + za prawidłowe chwycenie obiektu, - za upuszczenie obiektu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Polityka (Policy)\n",
    "\n",
    "Polityka to **strategia** agenta, która definiuje, jaką akcję powinien wybrać w danej sytuacji (stanie środowiska). Jest to \"mózg\" agenta, który kieruje jego zachowaniem.\n",
    "\n",
    "#### Jak to działa:\n",
    "Polityka może być deterministyczna (dla danego stanu zawsze wybiera tę samą akcję) lub stochastyczna (dla danego stanu wybiera akcję z pewnym prawdopodobieństwem). Celem uczenia ze wzmocnieniem jest znalezienie optymalnej polityki, która maksymalizuje oczekiwaną skumulowaną nagrodę.\n",
    "\n",
    "#### Przykłady praktyczne:\n",
    "- **Polityka AlphaGo:** AlphaGo nauczyło się swojej zwycięskiej polityki poprzez analizę milionów gier i rozgrywanie wielu gier przeciwko sobie. Polityka ta definiowała, jaki ruch wykonać w każdej możliwej konfiguracji planszy Go.\n",
    "- **Polityka robota kroczącego:** Polityka robota może definiować, jak poruszać nogami w zależności od aktualnego stanu równowagi i prędkości, aby utrzymać się na nogach i iść do przodu.\n",
    "- **Polityka systemu rekomendacji:** Polityka może decydować, jaki produkt zarekomendować użytkownikowi w zależności od jego historii przeglądania i zakupów, aby zmaksymalizować prawdopodobieństwo zakupu.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Proces uczenia modelu (Reinforcement Learning):\n",
    "1. **Definicja środowiska i nagród** – określenie, jak agent będzie wchodził w interakcje ze światem i jakie nagrody będzie otrzymywał.  \n",
    "2. **Inicjalizacja polityki** – początkowa, często losowa, strategia agenta.  \n",
    "3. **Interakcja ze środowiskiem** – agent obserwuje stan, wybiera akcję zgodnie z polityką, wykonuje ją, otrzymuje nagrodę i nowy stan.  \n",
    "4. **Aktualizacja polityki** – na podstawie otrzymanych nagród, agent modyfikuje swoją politykę, aby w przyszłości podejmować lepsze decyzje.  \n",
    "5. **Iteracja** – proces interakcji i aktualizacji powtarza się wielokrotnie, aż agent nauczy się optymalnej polityki.  \n",
    "6. **Zastosowanie polityki** – po nauczeniu, agent stosuje wyuczoną politykę do rozwiązywania problemu (np. AlphaGo stosujące wyuczoną politykę w grze przeciwko mistrzowi).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Zastosowania w realnym świecie:\n",
    "- **Robotyka:** Uczenie robotów chodzenia, manipulacji obiektami, nawigacji w złożonych środowiskach.\n",
    "- **Gry:** Tworzenie agentów AI, którzy potrafią grać w gry (szachy, Go, gry wideo) na poziomie mistrzowskim lub ponadludzkim (np. AlphaGo, AlphaStar, OpenAI Five).\n",
    "- **Autonomiczne pojazdy:** Uczenie samochodów, jak bezpiecznie i efektywnie jeździć, unikać przeszkód, parkować.\n",
    "- **Systemy rekomendacji:** Optymalizacja rekomendacji produktów, filmów czy muzyki w celu maksymalizacji zaangażowania użytkownika.\n",
    "- **Zarządzanie zasobami:** Optymalizacja zużycia energii w centrach danych, zarządzanie ruchem w sieciach telekomunikacyjnych.\n",
    "- **Finanse:** Optymalizacja strategii handlowych, zarządzanie portfelem inwestycyjnym.\n",
    "- **Medycyna:** Optymalizacja planów leczenia, dawkowania leków w czasie."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
