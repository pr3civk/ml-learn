{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb39cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a38f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ced53f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1049d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce681a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ocean_proximity'], dtype='object')\n",
      "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop('median_house_value', axis=1)\n",
    "y = df['median_house_value']\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "print(cat_cols)\n",
    "print(num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd86a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93741f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e30001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model           RMSE  Score R2\n",
      "0           LinearRegression   69791.254856  0.648635\n",
      "1                      Ridge   69791.342795  0.648634\n",
      "2                      Lasso   69791.275312  0.648635\n",
      "3                 ElasticNet   71080.243650  0.635536\n",
      "4      DecisionTreeRegressor   68441.974628  0.662090\n",
      "5      RandomForestRegressor   49373.310084  0.824151\n",
      "6                        SVR  114626.241100  0.052183\n",
      "7  GradientBoostingRegressor   56799.590145  0.767273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = [\n",
    "    (\"LinearRegression\", LinearRegression()),\n",
    "    (\"Ridge\", Ridge(alpha=0.1)),\n",
    "    (\"Lasso\", Lasso(alpha=0.1)),\n",
    "    (\"ElasticNet\", ElasticNet(alpha=0.1, l1_ratio=0.5)),\n",
    "    (\"DecisionTreeRegressor\", DecisionTreeRegressor()),\n",
    "    (\"RandomForestRegressor\", RandomForestRegressor()),\n",
    "    (\"SVR\", SVR(kernel='linear')),\n",
    "    (\"GradientBoostingRegressor\", GradientBoostingRegressor()),\n",
    "]\n",
    "\n",
    "pipelines = []\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", col_transformer),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    pipelines.append((name, rmse, r2))\n",
    "\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\"Model\": name, \"RMSE\": rmse, \"Score R2\": r2, } \n",
    "    for name, rmse, r2 in pipelines\n",
    "])\n",
    "\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8b7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "# from scipy.stats import randint, uniform\n",
    "# import time\n",
    "\n",
    "# # Choose search method: 'grid' or 'randomized'\n",
    "# SEARCH_METHOD = 'randomized'  # Change to 'grid' for GridSearchCV\n",
    "# CV_FOLDS = 5  # Number of cross-validation folds\n",
    "# N_ITER = 50  # For RandomizedSearchCV - number of iterations\n",
    "\n",
    "# # Define parameter grids for GridSearchCV\n",
    "# param_grids = {\n",
    "#     \"Ridge\": {\n",
    "#         \"regressor__alpha\": [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#     },\n",
    "#     \"Lasso\": {\n",
    "#         \"regressor__alpha\": [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#     },\n",
    "#     \"ElasticNet\": {\n",
    "#         \"regressor__alpha\": [0.01, 0.1, 1.0, 10.0],\n",
    "#         \"regressor__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "#     },\n",
    "#     \"DecisionTreeRegressor\": {\n",
    "#         \"regressor__max_depth\": [None, 10, 20, 30, 50],\n",
    "#         \"regressor__min_samples_split\": [2, 5, 10],\n",
    "#         \"regressor__min_samples_leaf\": [1, 2, 4]\n",
    "#     },\n",
    "#     \"RandomForestRegressor\": {\n",
    "#         \"regressor__n_estimators\": [100, 200, 300],\n",
    "#         \"regressor__max_depth\": [None, 10, 20, 30],\n",
    "#         \"regressor__min_samples_split\": [2, 5, 10],\n",
    "#         \"regressor__min_samples_leaf\": [1, 2, 4]\n",
    "#     },\n",
    "#     \"SVR\": {\n",
    "#         \"regressor__C\": [0.1, 1, 10, 100],\n",
    "#         \"regressor__kernel\": ['linear', 'rbf', 'poly'],\n",
    "#         \"regressor__gamma\": ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "#     },\n",
    "#     \"GradientBoostingRegressor\": {\n",
    "#         \"regressor__n_estimators\": [100, 200, 300],\n",
    "#         \"regressor__learning_rate\": [0.01, 0.1, 0.2],\n",
    "#         \"regressor__max_depth\": [3, 5, 7],\n",
    "#         \"regressor__min_samples_split\": [2, 5, 10]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Define parameter distributions for RandomizedSearchCV\n",
    "# param_distributions = {\n",
    "#     \"Ridge\": {\n",
    "#         \"regressor__alpha\": uniform(0.01, 100)\n",
    "#     },\n",
    "#     \"Lasso\": {\n",
    "#         \"regressor__alpha\": uniform(0.01, 100)\n",
    "#     },\n",
    "#     \"ElasticNet\": {\n",
    "#         \"regressor__alpha\": uniform(0.01, 10),\n",
    "#         \"regressor__l1_ratio\": uniform(0.1, 0.9)\n",
    "#     },\n",
    "#     \"DecisionTreeRegressor\": {\n",
    "#         \"regressor__max_depth\": randint(5, 50),\n",
    "#         \"regressor__min_samples_split\": randint(2, 20),\n",
    "#         \"regressor__min_samples_leaf\": randint(1, 10)\n",
    "#     },\n",
    "#     \"RandomForestRegressor\": {\n",
    "#         \"regressor__n_estimators\": randint(100, 500),\n",
    "#         \"regressor__max_depth\": [None] + list(range(10, 50, 10)),\n",
    "#         \"regressor__min_samples_split\": randint(2, 20),\n",
    "#         \"regressor__min_samples_leaf\": randint(1, 10)\n",
    "#     },\n",
    "#     \"SVR\": {\n",
    "#         \"regressor__C\": uniform(0.1, 100),\n",
    "#         \"regressor__kernel\": ['linear', 'rbf', 'poly'],\n",
    "#         \"regressor__gamma\": ['scale', 'auto'] + list(uniform(0.001, 0.1).rvs(3))\n",
    "#     },\n",
    "#     \"GradientBoostingRegressor\": {\n",
    "#         \"regressor__n_estimators\": randint(100, 500),\n",
    "#         \"regressor__learning_rate\": uniform(0.01, 0.3),\n",
    "#         \"regressor__max_depth\": randint(3, 10),\n",
    "#         \"regressor__min_samples_split\": randint(2, 20)\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# optimized_results = []\n",
    "\n",
    "# for name, model in models:\n",
    "#     if name == \"LinearRegression\":\n",
    "#         # LinearRegression doesn't have hyperparameters to tune\n",
    "#         pipe = Pipeline([\n",
    "#             (\"preprocessor\", col_transformer),\n",
    "#             (\"regressor\", model)\n",
    "#         ])\n",
    "#         cv_scores = cross_val_score(pipe, X_train, y_train, \n",
    "#                                    cv=CV_FOLDS, scoring='neg_mean_squared_error')\n",
    "#         rmse_cv = np.sqrt(-cv_scores.mean())\n",
    "        \n",
    "#         pipe.fit(X_train, y_train)\n",
    "#         y_pred = pipe.predict(X_test)\n",
    "#         rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "#         optimized_results.append({\n",
    "#             \"Model\": name,\n",
    "#             \"RMSE_CV\": rmse_cv,\n",
    "#             \"RMSE_Test\": rmse_test,\n",
    "#             \"R2_Score\": r2,\n",
    "#             \"Best_Params\": \"No hyperparameters\"\n",
    "#         })\n",
    "#         continue\n",
    "    \n",
    "#     if name not in param_grids:\n",
    "#         continue\n",
    "    \n",
    "#     pipe = Pipeline([\n",
    "#         (\"preprocessor\", col_transformer),\n",
    "#         (\"regressor\", model)\n",
    "#     ])\n",
    "    \n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Optimizing {name}...\")\n",
    "#     print(f\"{'='*60}\")\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     if SEARCH_METHOD == 'grid':\n",
    "#         search = GridSearchCV(\n",
    "#             pipe,\n",
    "#             param_grids[name],\n",
    "#             cv=CV_FOLDS,\n",
    "#             scoring='neg_mean_squared_error',\n",
    "#             n_jobs=-1,\n",
    "#             verbose=1\n",
    "#         )\n",
    "#     else:  # randomized\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipe,\n",
    "#             param_distributions[name],\n",
    "#             n_iter=N_ITER,\n",
    "#             cv=CV_FOLDS,\n",
    "#             scoring='neg_mean_squared_error',\n",
    "#             n_jobs=-1,\n",
    "#             verbose=1,\n",
    "#             random_state=42\n",
    "#         )\n",
    "    \n",
    "#     search.fit(X_train, y_train)\n",
    "    \n",
    "#     elapsed_time = time.time() - start_time\n",
    "    \n",
    "#     # Get best model and evaluate on test set\n",
    "#     best_pipe = search.best_estimator_\n",
    "#     y_pred = best_pipe.predict(X_test)\n",
    "    \n",
    "#     rmse_cv = np.sqrt(-search.best_score_)\n",
    "#     rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "#     optimized_results.append({\n",
    "#         \"Model\": name,\n",
    "#         \"RMSE_CV\": rmse_cv,\n",
    "#         \"RMSE_Test\": rmse_test,\n",
    "#         \"R2_Score\": r2,\n",
    "#         \"Best_Params\": str(search.best_params_),\n",
    "#         \"Time_Seconds\": round(elapsed_time, 2)\n",
    "#     })\n",
    "    \n",
    "#     print(f\"Best CV RMSE: {rmse_cv:.2f}\")\n",
    "#     print(f\"Test RMSE: {rmse_test:.2f}\")\n",
    "#     print(f\"Best Parameters: {search.best_params_}\")\n",
    "\n",
    "# # Create results dataframe\n",
    "# optimized_results_df = pd.DataFrame(optimized_results)\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"OPTIMIZED RESULTS WITH CROSS-VALIDATION\")\n",
    "# print(\"=\"*80)\n",
    "# print(optimized_results_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
